{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a7b856e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0e7770a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebec8c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model for pred_1\n",
      "Training episode 0\n",
      "Episodic Return: [  -30.260006   559.        -665.       -1468.      ]\n",
      " YOU CAN ADD CODE TO SAVE CHECKPOINTS HERE\n",
      " make sure the rewards are defined well in parallel.py\n",
      "Smoothed Returns for pred_1: -30.260005950927734\n",
      "Smoothed Returns for pred_2: 559.0\n",
      "Smoothed Returns for hider_1: -665.0\n",
      "Smoothed Returns for hider_2: -1468.0\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1.92185378074646\n",
      "Policy Loss: 1.9783073663711548\n",
      "Old Approx KL: 0.003401569090783596\n",
      "Approx KL: 0.00024190971453208476\n",
      "Clip Fraction: 0.0\n",
      "Explained Variance: 0.001246809959411621\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Saved best model for pred_1\n",
      "Training episode 40\n",
      "Episodic Return: [  -26.529995   621.        -754.       -1674.      ]\n",
      " YOU CAN ADD CODE TO SAVE CHECKPOINTS HERE\n",
      " make sure the rewards are defined well in parallel.py\n",
      "Smoothed Returns for pred_1: -24.52651023864746\n",
      "Smoothed Returns for pred_2: 747.25\n",
      "Smoothed Returns for hider_1: -703.7999877929688\n",
      "Smoothed Returns for hider_2: -1361.9000244140625\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 0.6783037781715393\n",
      "Policy Loss: 0.8502640128135681\n",
      "Old Approx KL: -0.002915757242590189\n",
      "Approx KL: 4.717282081401208e-06\n",
      "Clip Fraction: 0.0\n",
      "Explained Variance: 0.0028061866760253906\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Saved best model for pred_1\n",
      "Saved best model for pred_1\n",
      "Training episode 80\n",
      "Episodic Return: [  -26.330008   827.        -784.       -1213.      ]\n",
      " YOU CAN ADD CODE TO SAVE CHECKPOINTS HERE\n",
      " make sure the rewards are defined well in parallel.py\n",
      "Smoothed Returns for pred_1: -24.287511825561523\n",
      "Smoothed Returns for pred_2: 666.5999755859375\n",
      "Smoothed Returns for hider_1: -669.9500122070312\n",
      "Smoothed Returns for hider_2: -1402.4000244140625\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 0.24005916714668274\n",
      "Policy Loss: -0.0852164775133133\n",
      "Old Approx KL: 0.0024456637911498547\n",
      "Approx KL: 4.477160473470576e-05\n",
      "Clip Fraction: 0.0\n",
      "Explained Variance: 0.010158121585845947\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 120\n",
      "Episodic Return: [  -15.24001   701.       -543.      -1551.     ]\n",
      " YOU CAN ADD CODE TO SAVE CHECKPOINTS HERE\n",
      " make sure the rewards are defined well in parallel.py\n",
      "Smoothed Returns for pred_1: -23.84601402282715\n",
      "Smoothed Returns for pred_2: 648.6500244140625\n",
      "Smoothed Returns for hider_1: -637.5499877929688\n",
      "Smoothed Returns for hider_2: -1440.949951171875\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 0.06874262541532516\n",
      "Policy Loss: -0.15674108266830444\n",
      "Old Approx KL: 0.004525968339294195\n",
      "Approx KL: 7.647275924682617e-05\n",
      "Clip Fraction: 0.0\n",
      "Explained Variance: 0.01440894603729248\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 160\n",
      "Episodic Return: [  -33.600006   853.        -575.       -1406.      ]\n",
      " YOU CAN ADD CODE TO SAVE CHECKPOINTS HERE\n",
      " make sure the rewards are defined well in parallel.py\n",
      "Smoothed Returns for pred_1: -24.071014404296875\n",
      "Smoothed Returns for pred_2: 701.7999877929688\n",
      "Smoothed Returns for hider_1: -671.4500122070312\n",
      "Smoothed Returns for hider_2: -1430.8499755859375\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 0.3696574866771698\n",
      "Policy Loss: 0.8447446227073669\n",
      "Old Approx KL: -0.006666353903710842\n",
      "Approx KL: 0.00013956002658233047\n",
      "Clip Fraction: 0.0\n",
      "Explained Variance: 0.004315078258514404\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Saved best model for pred_1\n",
      "Saved best model for pred_1\n",
      "Saved best model for pred_1\n",
      "Saved best model for pred_1\n",
      "Saved best model for pred_1\n",
      "Saved best model for pred_1\n",
      "Saved best model for pred_1\n",
      "Saved best model for pred_1\n",
      "Saved best model for pred_1\n",
      "Saved best model for pred_1\n",
      "Saved best model for pred_1\n",
      "Saved best model for pred_1\n",
      "Saved best model for pred_1\n",
      "Training episode 200\n",
      "Episodic Return: [  -19.440014   725.        -771.       -1946.      ]\n",
      " YOU CAN ADD CODE TO SAVE CHECKPOINTS HERE\n",
      " make sure the rewards are defined well in parallel.py\n",
      "Smoothed Returns for pred_1: -17.580013275146484\n",
      "Smoothed Returns for pred_2: 650.6500244140625\n",
      "Smoothed Returns for hider_1: -710.0\n",
      "Smoothed Returns for hider_2: -1369.75\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 0.0846271887421608\n",
      "Policy Loss: 0.21328513324260712\n",
      "Old Approx KL: 0.0350504107773304\n",
      "Approx KL: 0.0016092659207060933\n",
      "Clip Fraction: 0.08612351243694623\n",
      "Explained Variance: 0.0021233558654785156\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Saved best model for pred_1\n",
      "Saved best model for pred_1\n",
      "Saved best model for pred_1\n",
      "Saved best model for pred_1\n",
      "Saved best model for pred_1\n",
      "Saved best model for pred_1\n",
      "Saved best model for pred_1\n",
      "Saved best model for pred_1\n",
      "Saved best model for pred_1\n",
      "Saved best model for pred_1\n",
      "Saved best model for pred_1\n",
      "Training episode 240\n",
      "Episodic Return: [  -16.110018   804.        -853.       -1424.      ]\n",
      " YOU CAN ADD CODE TO SAVE CHECKPOINTS HERE\n",
      " make sure the rewards are defined well in parallel.py\n",
      "Smoothed Returns for pred_1: -15.363012313842773\n",
      "Smoothed Returns for pred_2: 711.2000122070312\n",
      "Smoothed Returns for hider_1: -704.9000244140625\n",
      "Smoothed Returns for hider_2: -1397.75\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 0.03132983297109604\n",
      "Policy Loss: 0.0077551137655973434\n",
      "Old Approx KL: -0.020973922684788704\n",
      "Approx KL: 0.0016432575648650527\n",
      "Clip Fraction: 0.2793898830811183\n",
      "Explained Variance: -0.06014108657836914\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Saved best model for pred_1\n",
      "Saved best model for pred_1\n",
      "Saved best model for pred_1\n",
      "Saved best model for pred_1\n",
      "Saved best model for pred_1\n",
      "Training episode 280\n",
      "Episodic Return: [  -12.030019   822.        -475.       -1332.      ]\n",
      " YOU CAN ADD CODE TO SAVE CHECKPOINTS HERE\n",
      " make sure the rewards are defined well in parallel.py\n",
      "Smoothed Returns for pred_1: -13.809514999389648\n",
      "Smoothed Returns for pred_2: 644.0999755859375\n",
      "Smoothed Returns for hider_1: -697.4500122070312\n",
      "Smoothed Returns for hider_2: -1406.800048828125\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 0.06336893886327744\n",
      "Policy Loss: -0.11197958886623383\n",
      "Old Approx KL: 0.014451572671532631\n",
      "Approx KL: 0.003391214879229665\n",
      "Clip Fraction: 0.292038694024086\n",
      "Explained Variance: 0.01221233606338501\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 320\n",
      "Episodic Return: [  -12.840013   854.        -731.       -1343.      ]\n",
      " YOU CAN ADD CODE TO SAVE CHECKPOINTS HERE\n",
      " make sure the rewards are defined well in parallel.py\n",
      "Smoothed Returns for pred_1: -15.094017028808594\n",
      "Smoothed Returns for pred_2: 734.0499877929688\n",
      "Smoothed Returns for hider_1: -714.0\n",
      "Smoothed Returns for hider_2: -1376.550048828125\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 0.051313843578100204\n",
      "Policy Loss: -0.14109207689762115\n",
      "Old Approx KL: 0.13007037341594696\n",
      "Approx KL: 0.014083249494433403\n",
      "Clip Fraction: 0.3216145895421505\n",
      "Explained Variance: -0.008102178573608398\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Saved best model for pred_1\n",
      "Saved best model for pred_1\n",
      "Saved best model for pred_1\n",
      "Saved best model for pred_1\n",
      "Saved best model for pred_1\n",
      "Saved best model for pred_1\n",
      "Training episode 360\n",
      "Episodic Return: [  -11.860005   865.        -805.       -1047.      ]\n",
      " YOU CAN ADD CODE TO SAVE CHECKPOINTS HERE\n",
      " make sure the rewards are defined well in parallel.py\n",
      "Smoothed Returns for pred_1: -13.147516250610352\n",
      "Smoothed Returns for pred_2: 696.5999755859375\n",
      "Smoothed Returns for hider_1: -700.5\n",
      "Smoothed Returns for hider_2: -1379.0999755859375\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 0.027527088299393654\n",
      "Policy Loss: -0.09377836436033249\n",
      "Old Approx KL: 0.0002687147934921086\n",
      "Approx KL: 0.00977182388305664\n",
      "Clip Fraction: 0.2630208395421505\n",
      "Explained Variance: 0.08719855546951294\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 400\n",
      "Episodic Return: [  -12.530016   955.        -634.       -1540.      ]\n",
      " YOU CAN ADD CODE TO SAVE CHECKPOINTS HERE\n",
      " make sure the rewards are defined well in parallel.py\n",
      "Smoothed Returns for pred_1: -14.291516304016113\n",
      "Smoothed Returns for pred_2: 749.8499755859375\n",
      "Smoothed Returns for hider_1: -712.5499877929688\n",
      "Smoothed Returns for hider_2: -1438.0999755859375\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 0.02503613382577896\n",
      "Policy Loss: -0.18973498046398163\n",
      "Old Approx KL: 0.026290740817785263\n",
      "Approx KL: 0.0013191445032134652\n",
      "Clip Fraction: 0.3869047661622365\n",
      "Explained Variance: 0.04746556282043457\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 440\n",
      "Episodic Return: [  -19.850014   737.        -703.       -1359.      ]\n",
      " YOU CAN ADD CODE TO SAVE CHECKPOINTS HERE\n",
      " make sure the rewards are defined well in parallel.py\n",
      "Smoothed Returns for pred_1: -15.941014289855957\n",
      "Smoothed Returns for pred_2: 693.9000244140625\n",
      "Smoothed Returns for hider_1: -704.5499877929688\n",
      "Smoothed Returns for hider_2: -1400.75\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 0.05105629935860634\n",
      "Policy Loss: 0.20635442435741425\n",
      "Old Approx KL: 0.039787448942661285\n",
      "Approx KL: 0.0022245305590331554\n",
      "Clip Fraction: 0.3087797686457634\n",
      "Explained Variance: 0.079764723777771\n",
      "\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training episode 480\n",
      "Episodic Return: [  -19.180014   636.        -499.       -1533.      ]\n",
      " YOU CAN ADD CODE TO SAVE CHECKPOINTS HERE\n",
      " make sure the rewards are defined well in parallel.py\n",
      "Smoothed Returns for pred_1: -15.099515914916992\n",
      "Smoothed Returns for pred_2: 647.9000244140625\n",
      "Smoothed Returns for hider_1: -643.2000122070312\n",
      "Smoothed Returns for hider_2: -1396.699951171875\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 0.06125690042972565\n",
      "Policy Loss: 0.21717849373817444\n",
      "Old Approx KL: 0.04546266049146652\n",
      "Approx KL: 0.0015447650803253055\n",
      "Clip Fraction: 0.2310267873108387\n",
      "Explained Variance: 0.07434576749801636\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 520\n",
      "Episodic Return: [  -18.610008   516.        -546.       -1514.      ]\n",
      " YOU CAN ADD CODE TO SAVE CHECKPOINTS HERE\n",
      " make sure the rewards are defined well in parallel.py\n",
      "Smoothed Returns for pred_1: -14.035016059875488\n",
      "Smoothed Returns for pred_2: 744.7000122070312\n",
      "Smoothed Returns for hider_1: -728.0499877929688\n",
      "Smoothed Returns for hider_2: -1426.6500244140625\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 0.05642538517713547\n",
      "Policy Loss: 0.21893982589244843\n",
      "Old Approx KL: 0.04364180937409401\n",
      "Approx KL: 0.0021796822547912598\n",
      "Clip Fraction: 0.20777529974778494\n",
      "Explained Variance: 0.13937443494796753\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 560\n",
      "Episodic Return: [  -10.300018   681.        -578.       -1208.      ]\n",
      " YOU CAN ADD CODE TO SAVE CHECKPOINTS HERE\n",
      " make sure the rewards are defined well in parallel.py\n",
      "Smoothed Returns for pred_1: -16.06151580810547\n",
      "Smoothed Returns for pred_2: 688.1500244140625\n",
      "Smoothed Returns for hider_1: -702.7999877929688\n",
      "Smoothed Returns for hider_2: -1346.0999755859375\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 0.010122276842594147\n",
      "Policy Loss: 0.054577749222517014\n",
      "Old Approx KL: 0.006484253332018852\n",
      "Approx KL: 0.005315721500664949\n",
      "Clip Fraction: 0.1778273843228817\n",
      "Explained Variance: 0.12259519100189209\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 600\n",
      "Episodic Return: [ -15.080015  580.       -743.       -985.      ]\n",
      " YOU CAN ADD CODE TO SAVE CHECKPOINTS HERE\n",
      " make sure the rewards are defined well in parallel.py\n",
      "Smoothed Returns for pred_1: -15.927019119262695\n",
      "Smoothed Returns for pred_2: 734.9500122070312\n",
      "Smoothed Returns for hider_1: -770.0\n",
      "Smoothed Returns for hider_2: -1358.550048828125\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 0.036620475351810455\n",
      "Policy Loss: -0.22601482272148132\n",
      "Old Approx KL: 0.057583998888731\n",
      "Approx KL: 0.0019959297496825457\n",
      "Clip Fraction: 0.2912946455180645\n",
      "Explained Variance: 0.02608543634414673\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 640\n",
      "Episodic Return: [  -19.02002   888.       -946.      -1170.     ]\n",
      " YOU CAN ADD CODE TO SAVE CHECKPOINTS HERE\n",
      " make sure the rewards are defined well in parallel.py\n",
      "Smoothed Returns for pred_1: -15.374516487121582\n",
      "Smoothed Returns for pred_2: 765.4500122070312\n",
      "Smoothed Returns for hider_1: -746.3499755859375\n",
      "Smoothed Returns for hider_2: -1416.5\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 0.006387558300048113\n",
      "Policy Loss: -0.0028281116392463446\n",
      "Old Approx KL: 0.04445035383105278\n",
      "Approx KL: 0.002242820803076029\n",
      "Clip Fraction: 0.19066220397750536\n",
      "Explained Variance: 0.15341907739639282\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 680\n",
      "Episodic Return: [  -11.71001   797.       -969.      -1266.     ]\n",
      " YOU CAN ADD CODE TO SAVE CHECKPOINTS HERE\n",
      " make sure the rewards are defined well in parallel.py\n",
      "Smoothed Returns for pred_1: -15.448016166687012\n",
      "Smoothed Returns for pred_2: 660.0\n",
      "Smoothed Returns for hider_1: -707.0999755859375\n",
      "Smoothed Returns for hider_2: -1328.199951171875\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 0.01589209958910942\n",
      "Policy Loss: -0.1205914244055748\n",
      "Old Approx KL: 0.03832026943564415\n",
      "Approx KL: 0.0015369654865935445\n",
      "Clip Fraction: 0.1997767873108387\n",
      "Explained Variance: -0.28674280643463135\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 720\n",
      "Episodic Return: [  -11.040014   739.        -793.       -1782.      ]\n",
      " YOU CAN ADD CODE TO SAVE CHECKPOINTS HERE\n",
      " make sure the rewards are defined well in parallel.py\n",
      "Smoothed Returns for pred_1: -15.526013374328613\n",
      "Smoothed Returns for pred_2: 701.8499755859375\n",
      "Smoothed Returns for hider_1: -692.6500244140625\n",
      "Smoothed Returns for hider_2: -1435.4000244140625\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 0.0021123148035258055\n",
      "Policy Loss: -0.023480871692299843\n",
      "Old Approx KL: 0.03498290479183197\n",
      "Approx KL: 0.003781088860705495\n",
      "Clip Fraction: 0.2745535758634408\n",
      "Explained Variance: -0.3946373462677002\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 760\n",
      "Episodic Return: [  -15.7300205   833.         -626.        -1538.       ]\n",
      " YOU CAN ADD CODE TO SAVE CHECKPOINTS HERE\n",
      " make sure the rewards are defined well in parallel.py\n",
      "Smoothed Returns for pred_1: -17.581012725830078\n",
      "Smoothed Returns for pred_2: 708.4000244140625\n",
      "Smoothed Returns for hider_1: -668.25\n",
      "Smoothed Returns for hider_2: -1497.3499755859375\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 0.006948682479560375\n",
      "Policy Loss: 0.04362932965159416\n",
      "Old Approx KL: 0.012837274000048637\n",
      "Approx KL: 0.0023439782671630383\n",
      "Clip Fraction: 0.14248512064417204\n",
      "Explained Variance: 0.25162434577941895\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 800\n",
      "Episodic Return: [  -25.870018   727.        -502.       -1210.      ]\n",
      " YOU CAN ADD CODE TO SAVE CHECKPOINTS HERE\n",
      " make sure the rewards are defined well in parallel.py\n",
      "Smoothed Returns for pred_1: -17.412517547607422\n",
      "Smoothed Returns for pred_2: 727.9000244140625\n",
      "Smoothed Returns for hider_1: -668.0499877929688\n",
      "Smoothed Returns for hider_2: -1303.5\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 0.0472501702606678\n",
      "Policy Loss: 0.3111337423324585\n",
      "Old Approx KL: 0.017982125282287598\n",
      "Approx KL: 0.002145384205505252\n",
      "Clip Fraction: 0.21335565919677416\n",
      "Explained Variance: 0.14817821979522705\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 840\n",
      "Episodic Return: [  -12.38001   603.       -669.      -1298.     ]\n",
      " YOU CAN ADD CODE TO SAVE CHECKPOINTS HERE\n",
      " make sure the rewards are defined well in parallel.py\n",
      "Smoothed Returns for pred_1: -16.920515060424805\n",
      "Smoothed Returns for pred_2: 701.4500122070312\n",
      "Smoothed Returns for hider_1: -754.5\n",
      "Smoothed Returns for hider_2: -1373.8499755859375\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 0.010782403871417046\n",
      "Policy Loss: 0.09705697745084763\n",
      "Old Approx KL: 0.0030169489327818155\n",
      "Approx KL: 0.002056896686553955\n",
      "Clip Fraction: 0.24200149377187094\n",
      "Explained Variance: 0.2080814242362976\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 880\n",
      "Episodic Return: [  -23.490004   933.        -735.       -1605.      ]\n",
      " YOU CAN ADD CODE TO SAVE CHECKPOINTS HERE\n",
      " make sure the rewards are defined well in parallel.py\n",
      "Smoothed Returns for pred_1: -16.867517471313477\n",
      "Smoothed Returns for pred_2: 693.4500122070312\n",
      "Smoothed Returns for hider_1: -663.5499877929688\n",
      "Smoothed Returns for hider_2: -1342.0\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 0.011146281845867634\n",
      "Policy Loss: 0.0871659591794014\n",
      "Old Approx KL: 0.08125419914722443\n",
      "Approx KL: 0.0037039860617369413\n",
      "Clip Fraction: 0.3253348271052043\n",
      "Explained Variance: 0.008111417293548584\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 920\n",
      "Episodic Return: [  -21.460014   936.        -744.       -1180.      ]\n",
      " YOU CAN ADD CODE TO SAVE CHECKPOINTS HERE\n",
      " make sure the rewards are defined well in parallel.py\n",
      "Smoothed Returns for pred_1: -17.356016159057617\n",
      "Smoothed Returns for pred_2: 688.2000122070312\n",
      "Smoothed Returns for hider_1: -711.6500244140625\n",
      "Smoothed Returns for hider_2: -1469.0\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 0.020692136138677597\n",
      "Policy Loss: 0.004245941527187824\n",
      "Old Approx KL: 0.010183794423937798\n",
      "Approx KL: 0.0033067381009459496\n",
      "Clip Fraction: 0.3390997077027957\n",
      "Explained Variance: 0.13815665245056152\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 960\n",
      "Episodic Return: [  -12.57002   798.       -350.      -1232.     ]\n",
      " YOU CAN ADD CODE TO SAVE CHECKPOINTS HERE\n",
      " make sure the rewards are defined well in parallel.py\n",
      "Smoothed Returns for pred_1: -17.03401756286621\n",
      "Smoothed Returns for pred_2: 682.9500122070312\n",
      "Smoothed Returns for hider_1: -719.2999877929688\n",
      "Smoothed Returns for hider_2: -1413.199951171875\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 0.008561612106859684\n",
      "Policy Loss: -0.08549591898918152\n",
      "Old Approx KL: 0.01951410248875618\n",
      "Approx KL: 0.0012222018558532\n",
      "Clip Fraction: 0.24962797885139784\n",
      "Explained Variance: -1.1039142608642578\n",
      "\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 366\u001b[0m\n\u001b[1;32m    363\u001b[0m                 optimizer \u001b[38;5;241m=\u001b[39m get_optimizer_from_idx(policy_idx)\n\u001b[1;32m    365\u001b[0m                 optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 366\u001b[0m                 \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    367\u001b[0m                 optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    371\u001b[0m y_pred, y_true \u001b[38;5;241m=\u001b[39m b_values\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), b_returns\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/.conda/envs/drl/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/drl/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/drl/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions.categorical import Categorical\n",
    "import movable_wall_parallel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "GRID_SIZE = 8\n",
    "CKPT_PATH = \"/home/bpopper/letsgo/2d_RL_hide_seek/PARALLEL/weights/best_model_pred1.pth\"\n",
    "\n",
    "RANDOM = 3\n",
    "TRAINING = 2\n",
    "\n",
    "NUM_THINGS = 6 # number of things in the grid wall, pred1, pred2, h1, h2, movablewall\n",
    "\n",
    "POLICIES = [\n",
    "    TRAINING, # pred_1\n",
    "    RANDOM,    # pred_2\n",
    "    RANDOM,  # hider_1\n",
    "    RANDOM]    # hider_2\n",
    "# This should be either TRAINING, RANDOM, or a string that is a path to a ckpt for each agent\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Agent(nn.Module):\n",
    "    def __init__(self, num_actions):\n",
    "        super().__init__()\n",
    "\n",
    "        # CNN architecture inspired by DQN for Atari\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(NUM_THINGS, 32, kernel_size=3, stride=1, padding=1),  # Output: 32 x 7 x 7\n",
    "            #nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),  # Output: 64 x 7 x 7\n",
    "            #nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),  # Output: 64 x 7 x 7\n",
    "            #nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),  # Output: 64 * 7 * 7 = 3136\n",
    "        )\n",
    "        self.actor = self._layer_init(nn.Linear(64*GRID_SIZE**2, num_actions), std=0.01)\n",
    "        self.critic = self._layer_init(nn.Linear(64*GRID_SIZE**2, 1))\n",
    "\n",
    "    def _layer_init(self, layer, std=np.sqrt(2), bias_const=0.0):\n",
    "        torch.nn.init.orthogonal_(layer.weight, std)\n",
    "        torch.nn.init.constant_(layer.bias, bias_const)\n",
    "        return layer\n",
    "\n",
    "    def get_value(self, x):\n",
    "        return self.critic(self.network(x / 1.0))  # Normalize input to [0, 1]\n",
    "\n",
    "    def get_action_and_value(self, x, action=None):\n",
    "        hidden = self.network(x / 1.0)  # Normalize input to [0, 1]\n",
    "        \n",
    "        logits = self.actor(hidden)\n",
    "        probs = Categorical(logits=logits)\n",
    "        if action is None:\n",
    "            action = probs.sample()\n",
    "        return action, probs.log_prob(action), probs.entropy(), self.critic(hidden)\n",
    "\n",
    "    \n",
    "\n",
    "def batchify_obs(obs, device):\n",
    "    \"\"\"Converts PZ style observations to batch of torch arrays.\"\"\"\n",
    "    # convert to list of np arrays\n",
    "    obs = np.stack([obs[a] for a in obs], axis=0)\n",
    "    # convert to torch\n",
    "    obs = torch.tensor(obs).to(device)\n",
    "\n",
    "    return obs\n",
    "\n",
    "\n",
    "def batchify(x, device):\n",
    "    \"\"\"Converts PZ style returns to batch of torch arrays.\"\"\"\n",
    "    # convert to list of np arrays\n",
    "    x = np.stack([x[a] for a in x], axis=0)\n",
    "    # convert to torch\n",
    "    x = torch.tensor(x).to(device)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def unbatchify(x, env):\n",
    "    \"\"\"Converts np array to PZ style arguments.\"\"\"\n",
    "    x = x.cpu().numpy()\n",
    "    x = {a: x[i] for i, a in enumerate(env.possible_agents)}\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "    \"\"\"ALGO PARAMS\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    ent_coef = 0.1\n",
    "    vf_coef = 0.4\n",
    "    clip_coef = 0.08\n",
    "    gamma = 0.95\n",
    "    batch_size = 64\n",
    "    max_cycles = 250\n",
    "    total_episodes = 1500\n",
    "\n",
    "    do_train = True\n",
    "\n",
    "    \"\"\" ENV SETUP \"\"\"\n",
    "    env = movable_wall_parallel.parallel_env(grid_size=GRID_SIZE,walls=False)\n",
    "\n",
    "    num_agents = len(env.possible_agents)\n",
    "    num_actions = env.action_space(env.possible_agents[0]).n\n",
    "    observation_size = env.observation_space(env.possible_agents[0]).shape\n",
    "\n",
    "    agent_pred_1 = Agent(num_actions=num_actions).to(device)\n",
    "    optimizer_p1 = optim.Adam(agent_pred_1.parameters(), lr=0.0001, eps=1e-5)\n",
    "    agent_pred_2 = Agent(num_actions=num_actions).to(device)\n",
    "    optimizer_p2 = optim.Adam(agent_pred_2.parameters(), lr=0.0001, eps=1e-5)\n",
    "    agent_hider_1 = Agent(num_actions=num_actions).to(device)\n",
    "    optimizer_h1 = optim.Adam(agent_hider_1.parameters(), lr=0.0001, eps=1e-5)\n",
    "    agent_hider_2 = Agent(num_actions=num_actions).to(device)\n",
    "    optimizer_h2 = optim.Adam(agent_hider_2.parameters(), lr=0.0001, eps=1e-5)\n",
    "\n",
    "    def get_agent_from_idx(idx):\n",
    "        if idx == 0:\n",
    "            return agent_pred_1\n",
    "        elif idx == 1:\n",
    "            return agent_pred_2\n",
    "        elif idx == 2:\n",
    "            return agent_hider_1\n",
    "        elif idx == 3:\n",
    "            return agent_hider_2\n",
    "    \n",
    "    def get_agent_str_from_idx(idx):\n",
    "        if idx == 0:\n",
    "            return \"pred_1\"\n",
    "        elif idx == 1:\n",
    "            return \"pred_2\"\n",
    "        elif idx == 2:\n",
    "            return \"hider_1\"\n",
    "        elif idx == 3:\n",
    "            return \"hider_2\"\n",
    "    \n",
    "    def get_agent_idx_from_key(key):\n",
    "        if key == \"pred_1\":\n",
    "            return 0\n",
    "        elif key == \"pred_2\":\n",
    "            return 1\n",
    "        elif key == \"hider_1\":\n",
    "            return 2\n",
    "        elif key == \"hider_2\":\n",
    "            return 3\n",
    "\n",
    "    # load pretrained agents\n",
    "    for i, policy in enumerate(POLICIES):\n",
    "        #if is a string\n",
    "        if isinstance(policy, str):\n",
    "            if i == 0:\n",
    "                agent_pred_1.load_state_dict(torch.load(policy))\n",
    "                #freeze params\n",
    "                for param in agent_pred_1.parameters():\n",
    "                    param.requires_grad = False\n",
    "            elif i == 1:\n",
    "                agent_pred_2.load_state_dict(torch.load(policy))\n",
    "                #freeze params\n",
    "                for param in agent_pred_2.parameters():\n",
    "                    param.requires_grad = False\n",
    "            elif i == 2:\n",
    "                agent_hider_1.load_state_dict(torch.load(policy))\n",
    "                #freeze params\n",
    "                for param in agent_hider_1.parameters():\n",
    "                    param.requires_grad = False\n",
    "            elif i == 3:\n",
    "                agent_hider_2.load_state_dict(torch.load(policy))\n",
    "                #freeze params\n",
    "                for param in agent_hider_2.parameters():\n",
    "                    param.requires_grad = False\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \"\"\" ALGO LOGIC: EPISODE STORAGE\"\"\"\n",
    "    end_step = 0\n",
    "    total_episodic_return = 0\n",
    "    rb_obs = torch.zeros((max_cycles, num_agents, NUM_THINGS,GRID_SIZE,GRID_SIZE)).to(device)\n",
    "    rb_actions = torch.zeros((max_cycles, num_agents)).to(device)\n",
    "    rb_logprobs = torch.zeros((max_cycles, num_agents)).to(device)\n",
    "    rb_rewards = torch.zeros((max_cycles, num_agents)).to(device)\n",
    "    rb_terms = torch.zeros((max_cycles, num_agents)).to(device)\n",
    "    rb_values = torch.zeros((max_cycles, num_agents)).to(device)\n",
    "\n",
    "\n",
    "    if do_train:\n",
    "        \"\"\" TRAINING LOGIC \"\"\"\n",
    "        \n",
    "        # train for n number of episodes\n",
    "        best_smoothed_return = -10000\n",
    "        all_returnspred1 = []\n",
    "        all_returnspred2 = []\n",
    "        all_returnshider1 = []\n",
    "        all_returnshider2 = []\n",
    "        best_pred1 = - 10000\n",
    "        for episode in range(total_episodes):\n",
    "            # collect an episode\n",
    "            with torch.no_grad():\n",
    "                # collect observations and convert to batch of torch tensors\n",
    "                next_obs, info = env.reset(seed=None)\n",
    "                # reset the episodic return\n",
    "                total_episodic_return = 0\n",
    "\n",
    "                # each episode has num_steps\n",
    "                for step in range(0, max_cycles):\n",
    "                    # rollover the observation\n",
    "                    \n",
    "                    obs = next_obs.copy()\n",
    "                    # get action for first agent from the trained agent\n",
    "                    # get random actions for other agents\n",
    "                    actions = torch.zeros(num_agents, dtype=torch.long).to(device)\n",
    "                    logprobs = torch.zeros(num_agents).to(device)\n",
    "                    values = torch.zeros(num_agents).to(device)\n",
    "\n",
    "                    for i in range(0, num_agents):\n",
    "                        if POLICIES[i] == TRAINING:\n",
    "                            actions[i], logprobs[i], _, values[i] = get_agent_from_idx(i).get_action_and_value(torch.tensor(obs[get_agent_str_from_idx(i)]).unsqueeze(0).to(device))\n",
    "                        elif POLICIES[i] == RANDOM:\n",
    "                            actions[i] = torch.randint(0, num_actions, (1,)).to(device)\n",
    "                            logprobs[i] = torch.log(torch.tensor(1.0/num_actions))\n",
    "                            values[i] = 0.0\n",
    "\n",
    "            \n",
    "                    # execute the environment and log data\n",
    "                    next_obs, rewards, terms, truncs, infos = env.step(\n",
    "                        unbatchify(actions, env)\n",
    "                    )\n",
    "\n",
    "                    # add to episode storage\n",
    "                    for key in [\"pred_1\", \"pred_2\", \"hider_1\", \"hider_2\"]:\n",
    "\n",
    "                        rb_obs[step,get_agent_idx_from_key(key)] = torch.tensor(obs[key]).unsqueeze(0).to(device)\n",
    "\n",
    "                    rb_rewards[step] = batchify(rewards, device)\n",
    "                    rb_terms[step] = batchify(terms, device)\n",
    "                    rb_actions[step] = actions\n",
    "                    rb_logprobs[step] = logprobs\n",
    "                    rb_values[step] = values\n",
    "\n",
    "                    # compute episodic return\n",
    "                    total_episodic_return += rb_rewards[step].cpu().numpy()\n",
    "\n",
    "                    # if we reach termination or truncation, end\n",
    "                    if any([terms[a] for a in terms]) or any([truncs[a] for a in truncs]):\n",
    "                        end_step = step\n",
    "                        break\n",
    "\n",
    "        \n",
    "            with torch.no_grad():\n",
    "    \n",
    "                rb_advantages = torch.zeros_like(rb_rewards).to(device)\n",
    "                for policy_idx in range(num_agents):\n",
    "                    if POLICIES[policy_idx] == TRAINING:\n",
    "                        \n",
    "                        for t in reversed(range(end_step)):\n",
    "                            delta = (\n",
    "                                rb_rewards[t, policy_idx]  \n",
    "                                + gamma * rb_values[t + 1, policy_idx] * rb_terms[t + 1, policy_idx]\n",
    "                                - rb_values[t, policy_idx]\n",
    "                            )\n",
    "                            rb_advantages[t, policy_idx] = delta + gamma * gamma * rb_advantages[t + 1, policy_idx]\n",
    "\n",
    "                rb_returns = rb_advantages + rb_values\n",
    "\n",
    "            in_training = [POLICIES[i] == TRAINING for i in range(num_agents)]\n",
    "\n",
    "            ordered_training_policies = [i for i in range(num_agents) if POLICIES[i] == TRAINING] \n",
    "            #for example if pred_1 and hider_1 are training, ordered_training_policies = [0,2]\n",
    "\n",
    "            #mapping : takes the original policy idx and returns where it is in the ordered_training_policies\n",
    "            # for example if pred_1 and hider_1 are training, mapping(0) = 0, mapping(2) = 1\n",
    "\n",
    "            def mapping(original_idx):\n",
    "                return ordered_training_policies.index(original_idx)\n",
    "\n",
    "            # convert our episodes to batch of individual transitions (only for the trained agents)\n",
    "            b_obs = rb_obs[:end_step, in_training]\n",
    "            b_logprobs = rb_logprobs[:end_step, in_training]\n",
    "            b_actions = rb_actions[:end_step, in_training]\n",
    "            b_returns = rb_returns[:end_step, in_training]\n",
    "            b_values = rb_values[:end_step, in_training]\n",
    "            b_advantages = rb_advantages[:end_step, in_training]\n",
    "\n",
    "            # Optimizing the policy and value network\n",
    "            b_index = np.arange(len(b_obs))\n",
    "            clip_fracs = []\n",
    "            for repeat in range(3):\n",
    "                # shuffle the indices we use to access the data\n",
    "                np.random.shuffle(b_index)\n",
    "                for start in range(0, len(b_obs), batch_size):\n",
    "                    # select the indices we want to train on\n",
    "                    end = start + batch_size\n",
    "                    batch_index = b_index[start:end]\n",
    "                    for policy_idx in range(num_agents):\n",
    "                        if POLICIES[policy_idx] == TRAINING:\n",
    "\n",
    "                            #print(f'shape of actions {b_actions.long()[batch_index][:,1].shape}')\n",
    "                            \n",
    "                            _, newlogprob, entropy, value = get_agent_from_idx(policy_idx).get_action_and_value(\n",
    "                            b_obs[batch_index][:,mapping(policy_idx),:,:,:], b_actions.long()[batch_index][:,mapping(policy_idx)]\n",
    "                            )\n",
    "                            \n",
    "                            logratio = newlogprob - b_logprobs[batch_index][:,mapping(policy_idx)]\n",
    "                            ratio = logratio.exp()\n",
    "\n",
    "                            with torch.no_grad():\n",
    "                                # calculate approx_kl http://joschu.net/blog/kl-approx.html\n",
    "                                old_approx_kl = (-logratio).mean()\n",
    "                                approx_kl = ((ratio - 1) - logratio).mean()\n",
    "                                clip_fracs += [\n",
    "                                    ((ratio - 1.0).abs() > clip_coef).float().mean().item()\n",
    "                                ]\n",
    "\n",
    "                            # normalize advantages\n",
    "                            advantages = b_advantages[batch_index]\n",
    "                            advantages = (advantages - advantages.mean()) / (\n",
    "                                advantages.std() + 1e-8\n",
    "                            )\n",
    "\n",
    "                            # Policy loss\n",
    "                            pg_loss1 = -b_advantages[batch_index][:,mapping(policy_idx)] * ratio\n",
    "                            pg_loss2 = -b_advantages[batch_index][:,mapping(policy_idx)] * torch.clamp(\n",
    "                                ratio, 1 - clip_coef, 1 + clip_coef\n",
    "                            )\n",
    "                            pg_loss = torch.max(pg_loss1, pg_loss2).mean()\n",
    "\n",
    "                            # Value loss\n",
    "                            value = value.flatten()\n",
    "                            v_loss_unclipped = (value - b_returns[batch_index][:,mapping(policy_idx)]) ** 2\n",
    "                            v_clipped = b_values[batch_index][:,mapping(policy_idx)] + torch.clamp(\n",
    "                                value - b_values[batch_index][:,mapping(policy_idx)],\n",
    "                                -clip_coef,\n",
    "                                clip_coef,\n",
    "                            )\n",
    "                            v_loss_clipped = (v_clipped - b_returns[batch_index][:,mapping(policy_idx)]) ** 2\n",
    "                            v_loss_max = torch.max(v_loss_unclipped, v_loss_clipped)\n",
    "                            v_loss = 0.5 * v_loss_max.mean()\n",
    "\n",
    "                            entropy_loss = entropy.mean()\n",
    "                            loss = pg_loss - ent_coef * entropy_loss + v_loss * vf_coef\n",
    "\n",
    "                            def get_optimizer_from_idx(idx):\n",
    "                                if idx == 0:\n",
    "                                    return optimizer_p1\n",
    "                                elif idx == 1:\n",
    "                                    return optimizer_p2\n",
    "                                elif idx == 2:\n",
    "                                    return optimizer_h1\n",
    "                                elif idx == 3:\n",
    "                                    return optimizer_h2\n",
    "                            \n",
    "                            optimizer = get_optimizer_from_idx(policy_idx)\n",
    "\n",
    "                            optimizer.zero_grad()\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    \n",
    "\n",
    "            y_pred, y_true = b_values.cpu().numpy(), b_returns.cpu().numpy()\n",
    "            var_y = np.var(y_true)\n",
    "            explained_var = np.nan if var_y == 0 else 1 - np.var(y_true - y_pred) / var_y\n",
    "            \n",
    "            \n",
    "            all_returnspred1.append(total_episodic_return[0])\n",
    "            all_returnspred2.append(total_episodic_return[1])\n",
    "            all_returnshider1.append(total_episodic_return[2])\n",
    "            all_returnshider2.append(total_episodic_return[3])\n",
    "\n",
    "            \n",
    "\n",
    "            if best_pred1 < np.mean(all_returnspred1[-20:]):\n",
    "                best_pred1 = np.mean(all_returnspred1[-20:])\n",
    "                torch.save(agent_pred_1.state_dict(), \"./best_pred1_nowalls_6x8x8.pth\")\n",
    "                print(\"Saved best model for pred_1\")\n",
    "            if episode % 40 == 0:\n",
    "                #print smoothed returns average last 20\n",
    "                print(f\"Training episode {episode}\")\n",
    "                print(f\"Episodic Return: {(total_episodic_return)}\")\n",
    "                print(f\" YOU CAN ADD CODE TO SAVE CHECKPOINTS HERE\")\n",
    "                print(f\" make sure the rewards are defined well in parallel.py\")\n",
    "                print(f\"Smoothed Returns for pred_1: {np.mean(all_returnspred1[-20:])}\")\n",
    "                print(f\"Smoothed Returns for pred_2: {np.mean(all_returnspred2[-20:])}\")\n",
    "                print(f\"Smoothed Returns for hider_1: {np.mean(all_returnshider1[-20:])}\")\n",
    "                print(f\"Smoothed Returns for hider_2: {np.mean(all_returnshider2[-20:])}\")\n",
    "                print(f\"Episode Length: {end_step}\")\n",
    "                print(\"\")\n",
    "                print(f\"Value Loss: {v_loss.item()}\")\n",
    "                print(f\"Policy Loss: {pg_loss.item()}\")\n",
    "                print(f\"Old Approx KL: {old_approx_kl.item()}\")\n",
    "                print(f\"Approx KL: {approx_kl.item()}\")\n",
    "                print(f\"Clip Fraction: {np.mean(clip_fracs)}\")\n",
    "                print(f\"Explained Variance: {explained_var.item()}\")\n",
    "                print(\"\\n-------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35e5722d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/ice1/0/4/bpopper3/2d_RL_hide_seek\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d653a704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pred_1': -0.05, 'pred_2': 4, 'hider_1': -6, 'hider_2': -11}\n",
      "{'pred_1': -0.05, 'pred_2': 4, 'hider_1': -6, 'hider_2': -11}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -6, 'hider_2': -11}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -5, 'hider_2': -10}\n",
      "{'pred_1': -0.02, 'pred_2': 6, 'hider_1': -5, 'hider_2': -10}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -5, 'hider_2': -10}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -5, 'hider_2': -10}\n",
      "{'pred_1': -0.02, 'pred_2': 6, 'hider_1': -5, 'hider_2': -9}\n",
      "{'pred_1': -0.04, 'pred_2': 6, 'hider_1': -4, 'hider_2': -10}\n",
      "{'pred_1': -0.04, 'pred_2': 6, 'hider_1': -4, 'hider_2': -9}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -4, 'hider_2': -10}\n",
      "{'pred_1': -0.04, 'pred_2': 6, 'hider_1': -4, 'hider_2': -9}\n",
      "{'pred_1': -0.04, 'pred_2': 6, 'hider_1': -4, 'hider_2': -9}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -4, 'hider_2': -10}\n",
      "{'pred_1': -0.08, 'pred_2': 5, 'hider_1': -4, 'hider_2': -9}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -5, 'hider_2': -9}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -5, 'hider_2': -8}\n",
      "{'pred_1': 0.0, 'pred_2': 5, 'hider_1': -5, 'hider_2': -7}\n",
      "{'pred_1': -0.02, 'pred_2': 4, 'hider_1': -5, 'hider_2': -7}\n",
      "{'pred_1': -0.01, 'pred_2': 4, 'hider_1': -6, 'hider_2': -6}\n",
      "{'pred_1': -0.01, 'pred_2': 4, 'hider_1': -6, 'hider_2': -7}\n",
      "{'pred_1': 0.0, 'pred_2': 3, 'hider_1': -6, 'hider_2': -8}\n",
      "{'pred_1': 0.0, 'pred_2': 3, 'hider_1': -5, 'hider_2': -7}\n",
      "{'pred_1': -0.01, 'pred_2': 3, 'hider_1': -6, 'hider_2': -6}\n",
      "{'pred_1': -0.04, 'pred_2': 4, 'hider_1': -6, 'hider_2': -7}\n",
      "{'pred_1': -0.04, 'pred_2': 4, 'hider_1': -6, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 4, 'hider_1': -6, 'hider_2': -6}\n",
      "{'pred_1': -0.1, 'pred_2': 3, 'hider_1': -6, 'hider_2': -5}\n",
      "{'pred_1': -0.13, 'pred_2': 3, 'hider_1': -6, 'hider_2': -6}\n",
      "{'pred_1': -0.05, 'pred_2': 2, 'hider_1': -6, 'hider_2': -5}\n",
      "{'pred_1': -0.05, 'pred_2': 1, 'hider_1': -6, 'hider_2': -5}\n",
      "{'pred_1': -0.02, 'pred_2': 2, 'hider_1': -6, 'hider_2': -5}\n",
      "{'pred_1': 0.0, 'pred_2': 2, 'hider_1': -5, 'hider_2': -5}\n",
      "{'pred_1': -0.01, 'pred_2': 2, 'hider_1': -5, 'hider_2': -6}\n",
      "{'pred_1': 0.0, 'pred_2': 2, 'hider_1': -5, 'hider_2': -7}\n",
      "{'pred_1': -0.01, 'pred_2': 2, 'hider_1': -5, 'hider_2': -6}\n",
      "{'pred_1': -0.05, 'pred_2': 1, 'hider_1': -5, 'hider_2': -5}\n",
      "{'pred_1': -0.05, 'pred_2': 2, 'hider_1': -6, 'hider_2': -5}\n",
      "{'pred_1': -0.04, 'pred_2': 1, 'hider_1': -6, 'hider_2': -5}\n",
      "{'pred_1': 0.0, 'pred_2': 1, 'hider_1': -5, 'hider_2': -6}\n",
      "{'pred_1': -0.01, 'pred_2': 1, 'hider_1': -5, 'hider_2': -6}\n",
      "{'pred_1': -0.01, 'pred_2': 2, 'hider_1': -5, 'hider_2': -6}\n",
      "{'pred_1': -0.01, 'pred_2': 3, 'hider_1': -5, 'hider_2': -5}\n",
      "{'pred_1': -0.01, 'pred_2': 3, 'hider_1': -5, 'hider_2': -5}\n",
      "{'pred_1': -0.04, 'pred_2': 2, 'hider_1': -4, 'hider_2': -5}\n",
      "{'pred_1': -0.04, 'pred_2': 3, 'hider_1': -3, 'hider_2': -5}\n",
      "{'pred_1': -0.01, 'pred_2': 3, 'hider_1': -4, 'hider_2': -5}\n",
      "{'pred_1': -0.05, 'pred_2': 4, 'hider_1': -3, 'hider_2': -4}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -4, 'hider_2': -5}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -3, 'hider_2': -5}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -3, 'hider_2': -4}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -4, 'hider_2': -4}\n",
      "{'pred_1': 0.0, 'pred_2': 6, 'hider_1': -3, 'hider_2': -4}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -3, 'hider_2': -4}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -2, 'hider_2': -4}\n",
      "{'pred_1': -0.02, 'pred_2': 4, 'hider_1': -2, 'hider_2': -5}\n",
      "{'pred_1': -0.04, 'pred_2': 4, 'hider_1': -3, 'hider_2': -4}\n",
      "{'pred_1': -0.08, 'pred_2': 4, 'hider_1': -3, 'hider_2': -4}\n",
      "{'pred_1': -0.08, 'pred_2': 4, 'hider_1': -4, 'hider_2': -4}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -4, 'hider_2': -5}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -4, 'hider_2': -4}\n",
      "{'pred_1': -0.1, 'pred_2': 5, 'hider_1': -5, 'hider_2': -5}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -4, 'hider_2': -4}\n",
      "{'pred_1': -0.08, 'pred_2': 5, 'hider_1': -5, 'hider_2': -4}\n",
      "{'pred_1': -0.02, 'pred_2': 4, 'hider_1': -5, 'hider_2': -4}\n",
      "{'pred_1': 0.0, 'pred_2': 4, 'hider_1': -4, 'hider_2': -3}\n",
      "{'pred_1': 0.0, 'pred_2': 4, 'hider_1': -4, 'hider_2': -3}\n",
      "{'pred_1': -0.01, 'pred_2': 4, 'hider_1': -4, 'hider_2': -4}\n",
      "{'pred_1': -0.05, 'pred_2': 4, 'hider_1': -5, 'hider_2': -3}\n",
      "{'pred_1': -0.05, 'pred_2': 3, 'hider_1': -5, 'hider_2': -3}\n",
      "{'pred_1': -0.05, 'pred_2': 3, 'hider_1': -4, 'hider_2': -3}\n",
      "{'pred_1': -0.02, 'pred_2': 3, 'hider_1': -4, 'hider_2': -3}\n",
      "{'pred_1': -0.01, 'pred_2': 3, 'hider_1': -4, 'hider_2': -4}\n",
      "{'pred_1': -0.01, 'pred_2': 4, 'hider_1': -3, 'hider_2': -4}\n",
      "{'pred_1': 0.0, 'pred_2': 4, 'hider_1': -3, 'hider_2': -4}\n",
      "{'pred_1': 0.0, 'pred_2': 4, 'hider_1': -2, 'hider_2': -4}\n",
      "{'pred_1': -0.01, 'pred_2': 4, 'hider_1': -3, 'hider_2': -5}\n",
      "{'pred_1': -0.04, 'pred_2': 3, 'hider_1': -4, 'hider_2': -5}\n",
      "{'pred_1': -0.01, 'pred_2': 3, 'hider_1': -3, 'hider_2': -5}\n",
      "{'pred_1': -0.01, 'pred_2': 4, 'hider_1': -3, 'hider_2': -5}\n",
      "{'pred_1': -0.02, 'pred_2': 4, 'hider_1': -3, 'hider_2': -5}\n",
      "{'pred_1': -0.04, 'pred_2': 3, 'hider_1': -3, 'hider_2': -6}\n",
      "{'pred_1': -0.05, 'pred_2': 3, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.08, 'pred_2': 4, 'hider_1': -5, 'hider_2': -6}\n",
      "{'pred_1': -0.04, 'pred_2': 5, 'hider_1': -5, 'hider_2': -5}\n",
      "{'pred_1': -0.02, 'pred_2': 6, 'hider_1': -5, 'hider_2': -6}\n",
      "{'pred_1': 0.0, 'pred_2': 6, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -4, 'hider_2': -6}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -4, 'hider_2': -5}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -5, 'hider_2': -4}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -5, 'hider_2': -5}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -5, 'hider_2': -5}\n",
      "{'pred_1': -0.04, 'pred_2': 6, 'hider_1': -5, 'hider_2': -5}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -5, 'hider_2': -5}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -5, 'hider_2': -4}\n",
      "{'pred_1': -0.02, 'pred_2': 6, 'hider_1': -5, 'hider_2': -4}\n",
      "{'pred_1': -0.02, 'pred_2': 6, 'hider_1': -5, 'hider_2': -5}\n",
      "{'pred_1': -0.08, 'pred_2': 6, 'hider_1': -6, 'hider_2': -4}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -6, 'hider_2': -5}\n",
      "{'pred_1': -0.09, 'pred_2': 6, 'hider_1': -6, 'hider_2': -4}\n",
      "{'pred_1': -0.16, 'pred_2': 6, 'hider_1': -6, 'hider_2': -5}\n",
      "{'pred_1': -0.1, 'pred_2': 6, 'hider_1': -5, 'hider_2': -4}\n",
      "{'pred_1': -0.2, 'pred_2': 6, 'hider_1': -4, 'hider_2': -3}\n",
      "{'pred_1': -0.26, 'pred_2': 6, 'hider_1': -4, 'hider_2': -3}\n",
      "{'pred_1': -0.17, 'pred_2': 6, 'hider_1': -4, 'hider_2': -2}\n",
      "{'pred_1': -0.26, 'pred_2': 6, 'hider_1': -4, 'hider_2': -2}\n",
      "{'pred_1': -0.25, 'pred_2': 6, 'hider_1': -5, 'hider_2': -3}\n",
      "{'pred_1': -0.17, 'pred_2': 6, 'hider_1': -4, 'hider_2': -3}\n",
      "{'pred_1': -0.16, 'pred_2': 6, 'hider_1': -4, 'hider_2': -3}\n",
      "{'pred_1': -0.17, 'pred_2': 5, 'hider_1': -4, 'hider_2': -4}\n",
      "{'pred_1': -0.17, 'pred_2': 5, 'hider_1': -4, 'hider_2': -4}\n",
      "{'pred_1': -0.16, 'pred_2': 4, 'hider_1': -5, 'hider_2': -4}\n",
      "{'pred_1': -0.17, 'pred_2': 3, 'hider_1': -6, 'hider_2': -5}\n",
      "{'pred_1': -0.2, 'pred_2': 4, 'hider_1': -6, 'hider_2': -5}\n",
      "{'pred_1': -0.13, 'pred_2': 4, 'hider_1': -6, 'hider_2': -6}\n",
      "{'pred_1': -0.1, 'pred_2': 5, 'hider_1': -5, 'hider_2': -7}\n",
      "{'pred_1': -0.16, 'pred_2': 5, 'hider_1': -5, 'hider_2': -6}\n",
      "{'pred_1': -0.17, 'pred_2': 5, 'hider_1': -6, 'hider_2': -6}\n",
      "{'pred_1': -0.05, 'pred_2': 4, 'hider_1': -6, 'hider_2': -5}\n",
      "{'pred_1': -0.1, 'pred_2': 3, 'hider_1': -6, 'hider_2': -6}\n",
      "{'pred_1': -0.08, 'pred_2': 3, 'hider_1': -6, 'hider_2': -5}\n",
      "{'pred_1': -0.02, 'pred_2': 3, 'hider_1': -5, 'hider_2': -5}\n",
      "{'pred_1': 0.0, 'pred_2': 3, 'hider_1': -5, 'hider_2': -6}\n",
      "{'pred_1': -0.02, 'pred_2': 2, 'hider_1': -5, 'hider_2': -5}\n",
      "{'pred_1': -0.02, 'pred_2': 2, 'hider_1': -5, 'hider_2': -6}\n",
      "{'pred_1': -0.08, 'pred_2': 1, 'hider_1': -4, 'hider_2': -5}\n",
      "{'pred_1': -0.05, 'pred_2': 2, 'hider_1': -4, 'hider_2': -6}\n",
      "{'pred_1': -0.13, 'pred_2': 2, 'hider_1': -3, 'hider_2': -5}\n",
      "{'pred_1': -0.25, 'pred_2': 2, 'hider_1': -3, 'hider_2': -5}\n",
      "{'pred_1': -0.18, 'pred_2': 2, 'hider_1': -3, 'hider_2': -6}\n",
      "{'pred_1': -0.13, 'pred_2': 2, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.13, 'pred_2': 1, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.13, 'pred_2': 1, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.09, 'pred_2': 2, 'hider_1': -5, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 1, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.04, 'pred_2': 1, 'hider_1': -4, 'hider_2': -7}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pred_1': -0.02, 'pred_2': 1, 'hider_1': -5, 'hider_2': -8}\n",
      "{'pred_1': -0.01, 'pred_2': 1, 'hider_1': -4, 'hider_2': -8}\n",
      "{'pred_1': -0.01, 'pred_2': 1, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.04, 'pred_2': 1, 'hider_1': -2, 'hider_2': -7}\n",
      "{'pred_1': -0.09, 'pred_2': 1, 'hider_1': -2, 'hider_2': -7}\n",
      "{'pred_1': -0.09, 'pred_2': 1, 'hider_1': -2, 'hider_2': -8}\n",
      "{'pred_1': -0.09, 'pred_2': 2, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.1, 'pred_2': 2, 'hider_1': -1, 'hider_2': -9}\n",
      "{'pred_1': -0.16, 'pred_2': 2, 'hider_1': -1, 'hider_2': -9}\n",
      "{'pred_1': -0.16, 'pred_2': 2, 'hider_1': -1, 'hider_2': -9}\n",
      "{'pred_1': -0.09, 'pred_2': 2, 'hider_1': -2, 'hider_2': -8}\n",
      "{'pred_1': -0.13, 'pred_2': 2, 'hider_1': -2, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 3, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 4, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.1, 'pred_2': 4, 'hider_1': -4, 'hider_2': -6}\n",
      "{'pred_1': -0.13, 'pred_2': 4, 'hider_1': -4, 'hider_2': -6}\n",
      "{'pred_1': -0.13, 'pred_2': 4, 'hider_1': -4, 'hider_2': -6}\n",
      "{'pred_1': -0.13, 'pred_2': 5, 'hider_1': -4, 'hider_2': -6}\n",
      "{'pred_1': -0.1, 'pred_2': 5, 'hider_1': -4, 'hider_2': -6}\n",
      "{'pred_1': -0.08, 'pred_2': 5, 'hider_1': -5, 'hider_2': -6}\n",
      "{'pred_1': -0.04, 'pred_2': 4, 'hider_1': -5, 'hider_2': -7}\n",
      "{'pred_1': -0.04, 'pred_2': 5, 'hider_1': -5, 'hider_2': -8}\n",
      "{'pred_1': -0.08, 'pred_2': 5, 'hider_1': -5, 'hider_2': -8}\n",
      "{'pred_1': -0.08, 'pred_2': 6, 'hider_1': -5, 'hider_2': -7}\n",
      "{'pred_1': -0.04, 'pred_2': 5, 'hider_1': -4, 'hider_2': -6}\n",
      "{'pred_1': -0.08, 'pred_2': 5, 'hider_1': -3, 'hider_2': -6}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -4, 'hider_2': -6}\n",
      "{'pred_1': -0.02, 'pred_2': 6, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -4, 'hider_2': -8}\n",
      "{'pred_1': -0.1, 'pred_2': 5, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.08, 'pred_2': 6, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.1, 'pred_2': 6, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.08, 'pred_2': 6, 'hider_1': -3, 'hider_2': -6}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.08, 'pred_2': 6, 'hider_1': -4, 'hider_2': -6}\n",
      "{'pred_1': -0.13, 'pred_2': 5, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.18, 'pred_2': 5, 'hider_1': -3, 'hider_2': -6}\n",
      "{'pred_1': -0.18, 'pred_2': 5, 'hider_1': -3, 'hider_2': -6}\n",
      "{'pred_1': -0.13, 'pred_2': 6, 'hider_1': -3, 'hider_2': -6}\n",
      "{'pred_1': -0.09, 'pred_2': 6, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.13, 'pred_2': 6, 'hider_1': -3, 'hider_2': -8}\n",
      "{'pred_1': -0.13, 'pred_2': 6, 'hider_1': -3, 'hider_2': -8}\n",
      "{'pred_1': -0.08, 'pred_2': 6, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.18, 'pred_2': 6, 'hider_1': -3, 'hider_2': -6}\n",
      "{'pred_1': -0.13, 'pred_2': 5, 'hider_1': -3, 'hider_2': -6}\n",
      "{'pred_1': -0.2, 'pred_2': 5, 'hider_1': -2, 'hider_2': -7}\n",
      "{'pred_1': -0.26, 'pred_2': 5, 'hider_1': -1, 'hider_2': -6}\n",
      "{'pred_1': -0.16, 'pred_2': 5, 'hider_1': -1, 'hider_2': -6}\n",
      "{'pred_1': -0.09, 'pred_2': 5, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.17, 'pred_2': 4, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.17, 'pred_2': 4, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.17, 'pred_2': 3, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.16, 'pred_2': 4, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.16, 'pred_2': 4, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.09, 'pred_2': 5, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.16, 'pred_2': 5, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.17, 'pred_2': 6, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.1, 'pred_2': 6, 'hider_1': -1, 'hider_2': -6}\n",
      "{'pred_1': -0.04, 'pred_2': 6, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': 0.0, 'pred_2': 6, 'hider_1': -2, 'hider_2': -6}\n",
      "{}\n",
      "Episode 0 rewards: {'pred_1': -14.179999999999998, 'pred_2': 830, 'hider_1': -804, 'hider_2': -1208}\n",
      "{'pred_1': -0.04, 'pred_2': 3, 'hider_1': -4, 'hider_2': -2}\n",
      "{'pred_1': -0.05, 'pred_2': 3, 'hider_1': -4, 'hider_2': -2}\n",
      "{'pred_1': -0.13, 'pred_2': 3, 'hider_1': -4, 'hider_2': -3}\n",
      "{'pred_1': -0.05, 'pred_2': 4, 'hider_1': -3, 'hider_2': -4}\n",
      "{'pred_1': -0.04, 'pred_2': 3, 'hider_1': -2, 'hider_2': -3}\n",
      "{'pred_1': -0.02, 'pred_2': 3, 'hider_1': -1, 'hider_2': -4}\n",
      "{'pred_1': -0.1, 'pred_2': 3, 'hider_1': -1, 'hider_2': -3}\n",
      "{'pred_1': -0.04, 'pred_2': 4, 'hider_1': -2, 'hider_2': -4}\n",
      "{'pred_1': -0.01, 'pred_2': 3, 'hider_1': -2, 'hider_2': -3}\n",
      "{'pred_1': -0.05, 'pred_2': 4, 'hider_1': -3, 'hider_2': -3}\n",
      "{'pred_1': -0.04, 'pred_2': 4, 'hider_1': -3, 'hider_2': -3}\n",
      "{'pred_1': -0.04, 'pred_2': 3, 'hider_1': -3, 'hider_2': -3}\n",
      "{'pred_1': -0.01, 'pred_2': 3, 'hider_1': -3, 'hider_2': -4}\n",
      "{'pred_1': -0.05, 'pred_2': 2, 'hider_1': -3, 'hider_2': -5}\n",
      "{'pred_1': -0.05, 'pred_2': 2, 'hider_1': -4, 'hider_2': -6}\n",
      "{'pred_1': -0.01, 'pred_2': 3, 'hider_1': -4, 'hider_2': -6}\n",
      "{'pred_1': -0.01, 'pred_2': 3, 'hider_1': -3, 'hider_2': -6}\n",
      "{'pred_1': -0.02, 'pred_2': 3, 'hider_1': -3, 'hider_2': -5}\n",
      "{'pred_1': -0.05, 'pred_2': 3, 'hider_1': -2, 'hider_2': -6}\n",
      "{'pred_1': -0.05, 'pred_2': 3, 'hider_1': -2, 'hider_2': -5}\n",
      "{'pred_1': -0.09, 'pred_2': 4, 'hider_1': -1, 'hider_2': -4}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -1, 'hider_2': -3}\n",
      "{'pred_1': -0.04, 'pred_2': 5, 'hider_1': -1, 'hider_2': -2}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -1, 'hider_2': -2}\n",
      "{'pred_1': -0.04, 'pred_2': 6, 'hider_1': -1, 'hider_2': -2}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -1, 'hider_2': -3}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -2, 'hider_2': -3}\n",
      "{'pred_1': 0.0, 'pred_2': 6, 'hider_1': -2, 'hider_2': -3}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -2, 'hider_2': -2}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -2, 'hider_2': -3}\n",
      "{'pred_1': -0.08, 'pred_2': 6, 'hider_1': -1, 'hider_2': -3}\n",
      "{'pred_1': -0.08, 'pred_2': 5, 'hider_1': -1, 'hider_2': -3}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -2, 'hider_2': -4}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -2, 'hider_2': -3}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -1, 'hider_2': -3}\n",
      "{'pred_1': -0.02, 'pred_2': 6, 'hider_1': -1, 'hider_2': -2}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -1, 'hider_2': -2}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -1, 'hider_2': -2}\n",
      "{'pred_1': 0.0, 'pred_2': 6, 'hider_1': -1, 'hider_2': -3}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -1, 'hider_2': -3}\n",
      "{'pred_1': 0.0, 'pred_2': 6, 'hider_1': -1, 'hider_2': -3}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -1, 'hider_2': -3}\n",
      "{'pred_1': -0.04, 'pred_2': 6, 'hider_1': -1, 'hider_2': -2}\n",
      "{'pred_1': -0.04, 'pred_2': 6, 'hider_1': -1, 'hider_2': -3}\n",
      "{'pred_1': -0.04, 'pred_2': 6, 'hider_1': -1, 'hider_2': -4}\n",
      "{'pred_1': 0.0, 'pred_2': 6, 'hider_1': -1, 'hider_2': -4}\n",
      "{'pred_1': 0.0, 'pred_2': 6, 'hider_1': -1, 'hider_2': -3}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -1, 'hider_2': -4}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -1, 'hider_2': -5}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -2, 'hider_2': -4}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -3, 'hider_2': -3}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -3, 'hider_2': -2}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -3, 'hider_2': -3}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -3, 'hider_2': -4}\n",
      "{'pred_1': -0.09, 'pred_2': 6, 'hider_1': -2, 'hider_2': -5}\n",
      "{'pred_1': -0.17, 'pred_2': 6, 'hider_1': -2, 'hider_2': -4}\n",
      "{'pred_1': -0.17, 'pred_2': 6, 'hider_1': -3, 'hider_2': -5}\n",
      "{'pred_1': -0.2, 'pred_2': 6, 'hider_1': -4, 'hider_2': -4}\n",
      "{'pred_1': -0.13, 'pred_2': 6, 'hider_1': -4, 'hider_2': -5}\n",
      "{'pred_1': -0.13, 'pred_2': 6, 'hider_1': -5, 'hider_2': -4}\n",
      "{'pred_1': -0.17, 'pred_2': 6, 'hider_1': -6, 'hider_2': -4}\n",
      "{'pred_1': -0.13, 'pred_2': 6, 'hider_1': -6, 'hider_2': -3}\n",
      "{'pred_1': -0.1, 'pred_2': 5, 'hider_1': -6, 'hider_2': -4}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -5, 'hider_2': -5}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -5, 'hider_2': -4}\n",
      "{'pred_1': -0.05, 'pred_2': 4, 'hider_1': -5, 'hider_2': -3}\n",
      "{'pred_1': -0.04, 'pred_2': 4, 'hider_1': -5, 'hider_2': -3}\n",
      "{'pred_1': -0.02, 'pred_2': 4, 'hider_1': -4, 'hider_2': -4}\n",
      "{'pred_1': -0.04, 'pred_2': 4, 'hider_1': -4, 'hider_2': -4}\n",
      "{'pred_1': -0.01, 'pred_2': 3, 'hider_1': -3, 'hider_2': -5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pred_1': 0.0, 'pred_2': 3, 'hider_1': -2, 'hider_2': -6}\n",
      "{'pred_1': -0.04, 'pred_2': 3, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.01, 'pred_2': 3, 'hider_1': -1, 'hider_2': -6}\n",
      "{'pred_1': -0.01, 'pred_2': 3, 'hider_1': -1, 'hider_2': -5}\n",
      "{'pred_1': -0.02, 'pred_2': 3, 'hider_1': -1, 'hider_2': -4}\n",
      "{'pred_1': 0.0, 'pred_2': 3, 'hider_1': -2, 'hider_2': -3}\n",
      "{'pred_1': 0.0, 'pred_2': 4, 'hider_1': -2, 'hider_2': -2}\n",
      "{'pred_1': -0.04, 'pred_2': 3, 'hider_1': -3, 'hider_2': -2}\n",
      "{'pred_1': -0.01, 'pred_2': 3, 'hider_1': -3, 'hider_2': -3}\n",
      "{'pred_1': -0.01, 'pred_2': 4, 'hider_1': -3, 'hider_2': -3}\n",
      "{'pred_1': -0.01, 'pred_2': 3, 'hider_1': -2, 'hider_2': -3}\n",
      "{'pred_1': -0.02, 'pred_2': 3, 'hider_1': -2, 'hider_2': -2}\n",
      "{'pred_1': -0.02, 'pred_2': 3, 'hider_1': -2, 'hider_2': -2}\n",
      "{'pred_1': -0.01, 'pred_2': 3, 'hider_1': -2, 'hider_2': -3}\n",
      "{'pred_1': -0.01, 'pred_2': 4, 'hider_1': -2, 'hider_2': -3}\n",
      "{'pred_1': -0.01, 'pred_2': 4, 'hider_1': -2, 'hider_2': -3}\n",
      "{'pred_1': -0.05, 'pred_2': 4, 'hider_1': -2, 'hider_2': -3}\n",
      "{'pred_1': -0.1, 'pred_2': 4, 'hider_1': -2, 'hider_2': -4}\n",
      "{'pred_1': -0.04, 'pred_2': 3, 'hider_1': -2, 'hider_2': -5}\n",
      "{'pred_1': -0.05, 'pred_2': 3, 'hider_1': -2, 'hider_2': -4}\n",
      "{'pred_1': -0.01, 'pred_2': 4, 'hider_1': -2, 'hider_2': -3}\n",
      "{'pred_1': 0.0, 'pred_2': 4, 'hider_1': -2, 'hider_2': -4}\n",
      "{'pred_1': -0.04, 'pred_2': 4, 'hider_1': -1, 'hider_2': -5}\n",
      "{'pred_1': -0.02, 'pred_2': 4, 'hider_1': -1, 'hider_2': -4}\n",
      "{'pred_1': -0.02, 'pred_2': 4, 'hider_1': -2, 'hider_2': -5}\n",
      "{'pred_1': -0.01, 'pred_2': 3, 'hider_1': -2, 'hider_2': -6}\n",
      "{'pred_1': -0.05, 'pred_2': 4, 'hider_1': -2, 'hider_2': -5}\n",
      "{'pred_1': -0.08, 'pred_2': 4, 'hider_1': -1, 'hider_2': -6}\n",
      "{'pred_1': -0.05, 'pred_2': 4, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.01, 'pred_2': 4, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.01, 'pred_2': 4, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.04, 'pred_2': 4, 'hider_1': -1, 'hider_2': -9}\n",
      "{'pred_1': -0.05, 'pred_2': 4, 'hider_1': -2, 'hider_2': -10}\n",
      "{'pred_1': -0.09, 'pred_2': 5, 'hider_1': -1, 'hider_2': -11}\n",
      "{'pred_1': -0.04, 'pred_2': 5, 'hider_1': -1, 'hider_2': -10}\n",
      "{'pred_1': -0.09, 'pred_2': 6, 'hider_1': -1, 'hider_2': -9}\n",
      "{'pred_1': -0.04, 'pred_2': 6, 'hider_1': -1, 'hider_2': -9}\n",
      "{'pred_1': -0.1, 'pred_2': 6, 'hider_1': -2, 'hider_2': -8}\n",
      "{'pred_1': -0.02, 'pred_2': 6, 'hider_1': -2, 'hider_2': -9}\n",
      "{'pred_1': -0.02, 'pred_2': 6, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -1, 'hider_2': -6}\n",
      "{'pred_1': -0.04, 'pred_2': 6, 'hider_1': -1, 'hider_2': -5}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -1, 'hider_2': -5}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -1, 'hider_2': -5}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -2, 'hider_2': -5}\n",
      "{'pred_1': -0.04, 'pred_2': 6, 'hider_1': -1, 'hider_2': -6}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -1, 'hider_2': -5}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -1, 'hider_2': -5}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -1, 'hider_2': -4}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -1, 'hider_2': -4}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -1, 'hider_2': -5}\n",
      "{'pred_1': -0.05, 'pred_2': 4, 'hider_1': -1, 'hider_2': -6}\n",
      "{'pred_1': -0.05, 'pred_2': 4, 'hider_1': -1, 'hider_2': -5}\n",
      "{'pred_1': -0.01, 'pred_2': 4, 'hider_1': -1, 'hider_2': -6}\n",
      "{'pred_1': -0.05, 'pred_2': 4, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.08, 'pred_2': 4, 'hider_1': -1, 'hider_2': -6}\n",
      "{'pred_1': -0.05, 'pred_2': 4, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 4, 'hider_1': -2, 'hider_2': -7}\n",
      "{'pred_1': -0.1, 'pred_2': 3, 'hider_1': -2, 'hider_2': -8}\n",
      "{'pred_1': -0.09, 'pred_2': 3, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.1, 'pred_2': 4, 'hider_1': -2, 'hider_2': -7}\n",
      "{'pred_1': -0.1, 'pred_2': 3, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.02, 'pred_2': 4, 'hider_1': -1, 'hider_2': -9}\n",
      "{'pred_1': -0.01, 'pred_2': 4, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.02, 'pred_2': 4, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -2, 'hider_2': -8}\n",
      "{'pred_1': -0.02, 'pred_2': 4, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 3, 'hider_1': -3, 'hider_2': -8}\n",
      "{'pred_1': -0.02, 'pred_2': 2, 'hider_1': -3, 'hider_2': -9}\n",
      "{'pred_1': -0.08, 'pred_2': 1, 'hider_1': -3, 'hider_2': -8}\n",
      "{'pred_1': -0.08, 'pred_2': 1, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 1, 'hider_1': -2, 'hider_2': -8}\n",
      "{'pred_1': -0.05, 'pred_2': 1, 'hider_1': -2, 'hider_2': -8}\n",
      "{'pred_1': -0.05, 'pred_2': 1, 'hider_1': -3, 'hider_2': -8}\n",
      "{'pred_1': -0.02, 'pred_2': 2, 'hider_1': -3, 'hider_2': -8}\n",
      "{'pred_1': -0.02, 'pred_2': 1, 'hider_1': -2, 'hider_2': -7}\n",
      "{'pred_1': -0.02, 'pred_2': 2, 'hider_1': -2, 'hider_2': -6}\n",
      "{'pred_1': -0.05, 'pred_2': 3, 'hider_1': -2, 'hider_2': -6}\n",
      "{'pred_1': -0.04, 'pred_2': 4, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.09, 'pred_2': 3, 'hider_1': -3, 'hider_2': -6}\n",
      "{'pred_1': -0.1, 'pred_2': 2, 'hider_1': -3, 'hider_2': -6}\n",
      "{'pred_1': -0.08, 'pred_2': 2, 'hider_1': -2, 'hider_2': -5}\n",
      "{'pred_1': -0.1, 'pred_2': 1, 'hider_1': -3, 'hider_2': -5}\n",
      "{'pred_1': -0.1, 'pred_2': 2, 'hider_1': -3, 'hider_2': -5}\n",
      "{'pred_1': -0.1, 'pred_2': 2, 'hider_1': -3, 'hider_2': -5}\n",
      "{'pred_1': -0.04, 'pred_2': 2, 'hider_1': -4, 'hider_2': -5}\n",
      "{'pred_1': -0.05, 'pred_2': 2, 'hider_1': -5, 'hider_2': -5}\n",
      "{'pred_1': -0.01, 'pred_2': 2, 'hider_1': -4, 'hider_2': -6}\n",
      "{'pred_1': 0.0, 'pred_2': 2, 'hider_1': -4, 'hider_2': -6}\n",
      "{'pred_1': -0.01, 'pred_2': 2, 'hider_1': -4, 'hider_2': -6}\n",
      "{'pred_1': -0.04, 'pred_2': 2, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.04, 'pred_2': 1, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.09, 'pred_2': 1, 'hider_1': -3, 'hider_2': -6}\n",
      "{'pred_1': -0.04, 'pred_2': 1, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 1, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.01, 'pred_2': 2, 'hider_1': -3, 'hider_2': -8}\n",
      "{'pred_1': -0.05, 'pred_2': 2, 'hider_1': -2, 'hider_2': -8}\n",
      "{'pred_1': -0.13, 'pred_2': 2, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.25, 'pred_2': 3, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.2, 'pred_2': 3, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.1, 'pred_2': 3, 'hider_1': -2, 'hider_2': -7}\n",
      "{'pred_1': -0.16, 'pred_2': 3, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.1, 'pred_2': 4, 'hider_1': -4, 'hider_2': -8}\n",
      "{'pred_1': -0.1, 'pred_2': 4, 'hider_1': -5, 'hider_2': -9}\n",
      "{'pred_1': -0.08, 'pred_2': 5, 'hider_1': -6, 'hider_2': -9}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -6, 'hider_2': -9}\n",
      "{'pred_1': -0.04, 'pred_2': 5, 'hider_1': -6, 'hider_2': -9}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -6, 'hider_2': -10}\n",
      "{'pred_1': 0.0, 'pred_2': 5, 'hider_1': -6, 'hider_2': -11}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -5, 'hider_2': -10}\n",
      "{'pred_1': -0.02, 'pred_2': 4, 'hider_1': -5, 'hider_2': -11}\n",
      "{'pred_1': -0.05, 'pred_2': 3, 'hider_1': -5, 'hider_2': -11}\n",
      "{'pred_1': -0.05, 'pred_2': 4, 'hider_1': -5, 'hider_2': -11}\n",
      "{'pred_1': -0.05, 'pred_2': 4, 'hider_1': -5, 'hider_2': -10}\n",
      "{'pred_1': -0.1, 'pred_2': 4, 'hider_1': -5, 'hider_2': -11}\n",
      "{'pred_1': -0.13, 'pred_2': 4, 'hider_1': -4, 'hider_2': -11}\n",
      "{'pred_1': -0.2, 'pred_2': 4, 'hider_1': -4, 'hider_2': -12}\n",
      "{'pred_1': -0.17, 'pred_2': 3, 'hider_1': -5, 'hider_2': -12}\n",
      "{'pred_1': -0.25, 'pred_2': 3, 'hider_1': -5, 'hider_2': -12}\n",
      "{'pred_1': -0.26, 'pred_2': 3, 'hider_1': -5, 'hider_2': -11}\n",
      "{'pred_1': -0.17, 'pred_2': 4, 'hider_1': -5, 'hider_2': -11}\n",
      "{'pred_1': -0.16, 'pred_2': 3, 'hider_1': -5, 'hider_2': -11}\n",
      "{'pred_1': -0.04, 'pred_2': 3, 'hider_1': -5, 'hider_2': -11}\n",
      "{'pred_1': -0.02, 'pred_2': 3, 'hider_1': -6, 'hider_2': -11}\n",
      "{'pred_1': -0.05, 'pred_2': 3, 'hider_1': -6, 'hider_2': -11}\n",
      "{'pred_1': -0.05, 'pred_2': 3, 'hider_1': -6, 'hider_2': -12}\n",
      "{'pred_1': -0.05, 'pred_2': 2, 'hider_1': -6, 'hider_2': -12}\n",
      "{'pred_1': -0.17, 'pred_2': 2, 'hider_1': -6, 'hider_2': -12}\n",
      "{}\n",
      "Episode 1 rewards: {'pred_1': -10.689999999999985, 'pred_2': 795, 'hider_1': -517, 'hider_2': -1167}\n",
      "{'pred_1': -0.25, 'pred_2': 4, 'hider_1': -6, 'hider_2': -10}\n",
      "{'pred_1': -0.09, 'pred_2': 3, 'hider_1': -5, 'hider_2': -9}\n",
      "{'pred_1': -0.13, 'pred_2': 3, 'hider_1': -5, 'hider_2': -8}\n",
      "{'pred_1': -0.08, 'pred_2': 3, 'hider_1': -4, 'hider_2': -9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pred_1': -0.1, 'pred_2': 3, 'hider_1': -5, 'hider_2': -10}\n",
      "{'pred_1': -0.04, 'pred_2': 3, 'hider_1': -4, 'hider_2': -10}\n",
      "{'pred_1': -0.09, 'pred_2': 2, 'hider_1': -4, 'hider_2': -10}\n",
      "{'pred_1': -0.04, 'pred_2': 2, 'hider_1': -3, 'hider_2': -11}\n",
      "{'pred_1': -0.04, 'pred_2': 3, 'hider_1': -3, 'hider_2': -10}\n",
      "{'pred_1': -0.02, 'pred_2': 4, 'hider_1': -2, 'hider_2': -9}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -2, 'hider_2': -8}\n",
      "{'pred_1': -0.04, 'pred_2': 4, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.02, 'pred_2': 4, 'hider_1': -2, 'hider_2': -6}\n",
      "{'pred_1': -0.02, 'pred_2': 4, 'hider_1': -2, 'hider_2': -7}\n",
      "{'pred_1': -0.02, 'pred_2': 4, 'hider_1': -2, 'hider_2': -8}\n",
      "{'pred_1': -0.04, 'pred_2': 4, 'hider_1': -1, 'hider_2': -9}\n",
      "{'pred_1': -0.02, 'pred_2': 4, 'hider_1': -2, 'hider_2': -10}\n",
      "{'pred_1': -0.01, 'pred_2': 4, 'hider_1': -2, 'hider_2': -10}\n",
      "{'pred_1': -0.01, 'pred_2': 4, 'hider_1': -2, 'hider_2': -10}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -2, 'hider_2': -10}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -2, 'hider_2': -10}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -2, 'hider_2': -9}\n",
      "{'pred_1': -0.01, 'pred_2': 4, 'hider_1': -2, 'hider_2': -8}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -2, 'hider_2': -7}\n",
      "{'pred_1': -0.04, 'pred_2': 5, 'hider_1': -2, 'hider_2': -6}\n",
      "{'pred_1': -0.1, 'pred_2': 5, 'hider_1': -2, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 4, 'hider_1': -2, 'hider_2': -8}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -1, 'hider_2': -9}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -1, 'hider_2': -9}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -1, 'hider_2': -10}\n",
      "{'pred_1': -0.04, 'pred_2': 5, 'hider_1': -1, 'hider_2': -11}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -1, 'hider_2': -12}\n",
      "{'pred_1': 0.0, 'pred_2': 5, 'hider_1': -1, 'hider_2': -12}\n",
      "{'pred_1': 0.0, 'pred_2': 4, 'hider_1': -1, 'hider_2': -11}\n",
      "{'pred_1': -0.04, 'pred_2': 3, 'hider_1': -1, 'hider_2': -10}\n",
      "{'pred_1': -0.1, 'pred_2': 3, 'hider_1': -2, 'hider_2': -9}\n",
      "{'pred_1': -0.08, 'pred_2': 3, 'hider_1': -3, 'hider_2': -9}\n",
      "{'pred_1': -0.05, 'pred_2': 3, 'hider_1': -3, 'hider_2': -8}\n",
      "{'pred_1': -0.04, 'pred_2': 3, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.02, 'pred_2': 3, 'hider_1': -3, 'hider_2': -6}\n",
      "{'pred_1': -0.02, 'pred_2': 3, 'hider_1': -3, 'hider_2': -6}\n",
      "{'pred_1': -0.02, 'pred_2': 3, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': 0.0, 'pred_2': 4, 'hider_1': -2, 'hider_2': -6}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -2, 'hider_2': -6}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -2, 'hider_2': -5}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -2, 'hider_2': -4}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -1, 'hider_2': -3}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -1, 'hider_2': -2}\n",
      "{'pred_1': 0.0, 'pred_2': 4, 'hider_1': -1, 'hider_2': -3}\n",
      "{'pred_1': -0.01, 'pred_2': 4, 'hider_1': -2, 'hider_2': -4}\n",
      "{'pred_1': 0.0, 'pred_2': 3, 'hider_1': -1, 'hider_2': -5}\n",
      "{'pred_1': -0.01, 'pred_2': 2, 'hider_1': -1, 'hider_2': -6}\n",
      "{'pred_1': 0.0, 'pred_2': 2, 'hider_1': -1, 'hider_2': -6}\n",
      "{'pred_1': 0.0, 'pred_2': 2, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': 0.0, 'pred_2': 3, 'hider_1': -1, 'hider_2': -6}\n",
      "{'pred_1': 0.0, 'pred_2': 3, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': 0.0, 'pred_2': 4, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.01, 'pred_2': 4, 'hider_1': -1, 'hider_2': -9}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -2, 'hider_2': -8}\n",
      "{'pred_1': 0.0, 'pred_2': 5, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -1, 'hider_2': -6}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -1, 'hider_2': -5}\n",
      "{'pred_1': -0.02, 'pred_2': 6, 'hider_1': -2, 'hider_2': -6}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -2, 'hider_2': -7}\n",
      "{'pred_1': -0.01, 'pred_2': 4, 'hider_1': -2, 'hider_2': -7}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -2, 'hider_2': -6}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -3, 'hider_2': -6}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -2, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.04, 'pred_2': 5, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.04, 'pred_2': 6, 'hider_1': -1, 'hider_2': -6}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': 0.0, 'pred_2': 6, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.02, 'pred_2': 6, 'hider_1': -2, 'hider_2': -7}\n",
      "{'pred_1': 0.0, 'pred_2': 6, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.04, 'pred_2': 6, 'hider_1': -1, 'hider_2': -9}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -2, 'hider_2': -9}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -1, 'hider_2': -9}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -2, 'hider_2': -9}\n",
      "{'pred_1': -0.08, 'pred_2': 5, 'hider_1': -3, 'hider_2': -9}\n",
      "{'pred_1': -0.1, 'pred_2': 4, 'hider_1': -3, 'hider_2': -8}\n",
      "{'pred_1': -0.05, 'pred_2': 4, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.04, 'pred_2': 5, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -3, 'hider_2': -6}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -2, 'hider_2': -7}\n",
      "{'pred_1': -0.09, 'pred_2': 6, 'hider_1': -1, 'hider_2': -6}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -2, 'hider_2': -6}\n",
      "{'pred_1': -0.08, 'pred_2': 6, 'hider_1': -2, 'hider_2': -7}\n",
      "{'pred_1': -0.02, 'pred_2': 6, 'hider_1': -2, 'hider_2': -8}\n",
      "{'pred_1': -0.02, 'pred_2': 6, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.02, 'pred_2': 6, 'hider_1': -1, 'hider_2': -6}\n",
      "{'pred_1': -0.04, 'pred_2': 6, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.09, 'pred_2': 6, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.09, 'pred_2': 6, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.16, 'pred_2': 6, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.17, 'pred_2': 6, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.1, 'pred_2': 5, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.08, 'pred_2': 5, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.08, 'pred_2': 6, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -1, 'hider_2': -6}\n",
      "{'pred_1': -0.02, 'pred_2': 6, 'hider_1': -1, 'hider_2': -5}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -1, 'hider_2': -5}\n",
      "{'pred_1': -0.04, 'pred_2': 4, 'hider_1': -1, 'hider_2': -6}\n",
      "{'pred_1': -0.02, 'pred_2': 4, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.1, 'pred_2': 5, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.1, 'pred_2': 4, 'hider_1': -1, 'hider_2': -6}\n",
      "{'pred_1': -0.1, 'pred_2': 5, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.1, 'pred_2': 6, 'hider_1': -2, 'hider_2': -8}\n",
      "{'pred_1': -0.1, 'pred_2': 6, 'hider_1': -2, 'hider_2': -9}\n",
      "{'pred_1': -0.02, 'pred_2': 6, 'hider_1': -2, 'hider_2': -9}\n",
      "{'pred_1': -0.02, 'pred_2': 6, 'hider_1': -2, 'hider_2': -9}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -3, 'hider_2': -8}\n",
      "{'pred_1': -0.04, 'pred_2': 5, 'hider_1': -4, 'hider_2': -8}\n",
      "{'pred_1': -0.04, 'pred_2': 5, 'hider_1': -4, 'hider_2': -8}\n",
      "{'pred_1': -0.08, 'pred_2': 6, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.08, 'pred_2': 5, 'hider_1': -4, 'hider_2': -6}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.17, 'pred_2': 6, 'hider_1': -5, 'hider_2': -7}\n",
      "{'pred_1': -0.16, 'pred_2': 6, 'hider_1': -5, 'hider_2': -6}\n",
      "{'pred_1': -0.1, 'pred_2': 6, 'hider_1': -4, 'hider_2': -6}\n",
      "{'pred_1': -0.1, 'pred_2': 5, 'hider_1': -4, 'hider_2': -6}\n",
      "{'pred_1': -0.17, 'pred_2': 4, 'hider_1': -5, 'hider_2': -7}\n",
      "{'pred_1': -0.17, 'pred_2': 5, 'hider_1': -5, 'hider_2': -7}\n",
      "{'pred_1': -0.29, 'pred_2': 5, 'hider_1': -6, 'hider_2': -7}\n",
      "{'pred_1': -0.29, 'pred_2': 5, 'hider_1': -6, 'hider_2': -6}\n",
      "{'pred_1': -0.2, 'pred_2': 5, 'hider_1': -6, 'hider_2': -7}\n",
      "{'pred_1': -0.18, 'pred_2': 5, 'hider_1': -6, 'hider_2': -7}\n",
      "{'pred_1': -0.13, 'pred_2': 5, 'hider_1': -6, 'hider_2': -6}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -6, 'hider_2': -6}\n",
      "{'pred_1': -0.04, 'pred_2': 5, 'hider_1': -6, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -6, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -6, 'hider_2': -7}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -6, 'hider_2': -7}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pred_1': -0.04, 'pred_2': 5, 'hider_1': -6, 'hider_2': -7}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -6, 'hider_2': -6}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -6, 'hider_2': -5}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -6, 'hider_2': -6}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -6, 'hider_2': -7}\n",
      "{'pred_1': -0.04, 'pred_2': 6, 'hider_1': -6, 'hider_2': -6}\n",
      "{'pred_1': -0.04, 'pred_2': 6, 'hider_1': -6, 'hider_2': -6}\n",
      "{'pred_1': -0.04, 'pred_2': 6, 'hider_1': -6, 'hider_2': -6}\n",
      "{'pred_1': -0.04, 'pred_2': 5, 'hider_1': -6, 'hider_2': -6}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -6, 'hider_2': -7}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -6, 'hider_2': -6}\n",
      "{'pred_1': -0.04, 'pred_2': 6, 'hider_1': -6, 'hider_2': -6}\n",
      "{'pred_1': -0.02, 'pred_2': 6, 'hider_1': -6, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -6, 'hider_2': -8}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -5, 'hider_2': -7}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -5, 'hider_2': -7}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -6, 'hider_2': -6}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -6, 'hider_2': -7}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -6, 'hider_2': -8}\n",
      "{'pred_1': -0.02, 'pred_2': 6, 'hider_1': -6, 'hider_2': -8}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -6, 'hider_2': -8}\n",
      "{'pred_1': 0.0, 'pred_2': 6, 'hider_1': -5, 'hider_2': -7}\n",
      "{'pred_1': 0.0, 'pred_2': 6, 'hider_1': -6, 'hider_2': -8}\n",
      "{'pred_1': 0.0, 'pred_2': 6, 'hider_1': -6, 'hider_2': -9}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -5, 'hider_2': -8}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.1, 'pred_2': 6, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -4, 'hider_2': -8}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -5, 'hider_2': -7}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -5, 'hider_2': -8}\n",
      "{'pred_1': -0.04, 'pred_2': 6, 'hider_1': -4, 'hider_2': -9}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -5, 'hider_2': -9}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -4, 'hider_2': -10}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -4, 'hider_2': -11}\n",
      "{'pred_1': -0.04, 'pred_2': 6, 'hider_1': -4, 'hider_2': -11}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -4, 'hider_2': -11}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -3, 'hider_2': -11}\n",
      "{'pred_1': -0.04, 'pred_2': 6, 'hider_1': -3, 'hider_2': -10}\n",
      "{'pred_1': -0.02, 'pred_2': 6, 'hider_1': -3, 'hider_2': -10}\n",
      "{'pred_1': -0.02, 'pred_2': 6, 'hider_1': -4, 'hider_2': -9}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -4, 'hider_2': -9}\n",
      "{'pred_1': -0.1, 'pred_2': 5, 'hider_1': -3, 'hider_2': -8}\n",
      "{'pred_1': -0.17, 'pred_2': 4, 'hider_1': -2, 'hider_2': -9}\n",
      "{'pred_1': -0.1, 'pred_2': 4, 'hider_1': -2, 'hider_2': -10}\n",
      "{'pred_1': -0.1, 'pred_2': 3, 'hider_1': -3, 'hider_2': -11}\n",
      "{'pred_1': -0.1, 'pred_2': 2, 'hider_1': -3, 'hider_2': -10}\n",
      "{'pred_1': -0.04, 'pred_2': 2, 'hider_1': -4, 'hider_2': -10}\n",
      "{'pred_1': -0.09, 'pred_2': 2, 'hider_1': -3, 'hider_2': -10}\n",
      "{'pred_1': -0.16, 'pred_2': 1, 'hider_1': -2, 'hider_2': -11}\n",
      "{'pred_1': -0.17, 'pred_2': 1, 'hider_1': -2, 'hider_2': -12}\n",
      "{'pred_1': -0.09, 'pred_2': 1, 'hider_1': -2, 'hider_2': -11}\n",
      "{'pred_1': -0.17, 'pred_2': 1, 'hider_1': -1, 'hider_2': -10}\n",
      "{'pred_1': -0.16, 'pred_2': 2, 'hider_1': -1, 'hider_2': -10}\n",
      "{'pred_1': -0.1, 'pred_2': 2, 'hider_1': -2, 'hider_2': -10}\n",
      "{'pred_1': -0.09, 'pred_2': 2, 'hider_1': -2, 'hider_2': -9}\n",
      "{'pred_1': -0.09, 'pred_2': 3, 'hider_1': -2, 'hider_2': -8}\n",
      "{'pred_1': -0.09, 'pred_2': 3, 'hider_1': -2, 'hider_2': -8}\n",
      "{'pred_1': -0.17, 'pred_2': 3, 'hider_1': -2, 'hider_2': -7}\n",
      "{}\n",
      "Episode 2 rewards: {'pred_1': -10.389999999999983, 'pred_2': 953, 'hider_1': -584, 'hider_2': -1538}\n",
      "{'pred_1': -0.2, 'pred_2': 1, 'hider_1': -2, 'hider_2': -5}\n",
      "{'pred_1': -0.08, 'pred_2': 2, 'hider_1': -2, 'hider_2': -5}\n",
      "{'pred_1': -0.05, 'pred_2': 3, 'hider_1': -3, 'hider_2': -4}\n",
      "{'pred_1': -0.1, 'pred_2': 3, 'hider_1': -3, 'hider_2': -4}\n",
      "{'pred_1': -0.04, 'pred_2': 2, 'hider_1': -3, 'hider_2': -5}\n",
      "{'pred_1': -0.04, 'pred_2': 1, 'hider_1': -3, 'hider_2': -6}\n",
      "{'pred_1': -0.08, 'pred_2': 1, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 1, 'hider_1': -4, 'hider_2': -8}\n",
      "{'pred_1': -0.04, 'pred_2': 1, 'hider_1': -4, 'hider_2': -9}\n",
      "{'pred_1': 0.0, 'pred_2': 1, 'hider_1': -3, 'hider_2': -8}\n",
      "{'pred_1': -0.02, 'pred_2': 1, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.01, 'pred_2': 2, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 2, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.13, 'pred_2': 2, 'hider_1': -2, 'hider_2': -7}\n",
      "{'pred_1': -0.18, 'pred_2': 2, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.1, 'pred_2': 2, 'hider_1': -1, 'hider_2': -9}\n",
      "{'pred_1': -0.05, 'pred_2': 2, 'hider_1': -1, 'hider_2': -10}\n",
      "{'pred_1': -0.13, 'pred_2': 2, 'hider_1': -1, 'hider_2': -9}\n",
      "{'pred_1': -0.25, 'pred_2': 2, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.2, 'pred_2': 1, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.17, 'pred_2': 1, 'hider_1': -1, 'hider_2': -9}\n",
      "{'pred_1': -0.1, 'pred_2': 2, 'hider_1': -1, 'hider_2': -9}\n",
      "{'pred_1': -0.1, 'pred_2': 2, 'hider_1': -1, 'hider_2': -9}\n",
      "{'pred_1': -0.1, 'pred_2': 3, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.04, 'pred_2': 3, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.01, 'pred_2': 3, 'hider_1': -2, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 3, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.08, 'pred_2': 3, 'hider_1': -1, 'hider_2': -9}\n",
      "{'pred_1': -0.04, 'pred_2': 3, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.08, 'pred_2': 3, 'hider_1': -1, 'hider_2': -9}\n",
      "{'pred_1': -0.1, 'pred_2': 2, 'hider_1': -1, 'hider_2': -10}\n",
      "{'pred_1': -0.1, 'pred_2': 2, 'hider_1': -1, 'hider_2': -9}\n",
      "{'pred_1': -0.17, 'pred_2': 2, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.17, 'pred_2': 3, 'hider_1': -1, 'hider_2': -9}\n",
      "{'pred_1': -0.13, 'pred_2': 3, 'hider_1': -1, 'hider_2': -9}\n",
      "{'pred_1': -0.05, 'pred_2': 3, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.05, 'pred_2': 3, 'hider_1': -2, 'hider_2': -9}\n",
      "{'pred_1': -0.1, 'pred_2': 3, 'hider_1': -2, 'hider_2': -9}\n",
      "{'pred_1': -0.13, 'pred_2': 4, 'hider_1': -2, 'hider_2': -10}\n",
      "{'pred_1': -0.08, 'pred_2': 4, 'hider_1': -3, 'hider_2': -9}\n",
      "{'pred_1': -0.05, 'pred_2': 4, 'hider_1': -3, 'hider_2': -8}\n",
      "{'pred_1': -0.05, 'pred_2': 4, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.13, 'pred_2': 5, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.13, 'pred_2': 5, 'hider_1': -3, 'hider_2': -8}\n",
      "{'pred_1': -0.08, 'pred_2': 6, 'hider_1': -3, 'hider_2': -9}\n",
      "{'pred_1': -0.1, 'pred_2': 6, 'hider_1': -4, 'hider_2': -9}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -4, 'hider_2': -10}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -4, 'hider_2': -10}\n",
      "{'pred_1': -0.1, 'pred_2': 6, 'hider_1': -4, 'hider_2': -11}\n",
      "{'pred_1': -0.13, 'pred_2': 5, 'hider_1': -4, 'hider_2': -10}\n",
      "{'pred_1': -0.2, 'pred_2': 5, 'hider_1': -4, 'hider_2': -10}\n",
      "{'pred_1': -0.1, 'pred_2': 4, 'hider_1': -5, 'hider_2': -9}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -5, 'hider_2': -10}\n",
      "{'pred_1': 0.0, 'pred_2': 5, 'hider_1': -6, 'hider_2': -10}\n",
      "{'pred_1': 0.0, 'pred_2': 4, 'hider_1': -5, 'hider_2': -9}\n",
      "{'pred_1': -0.01, 'pred_2': 4, 'hider_1': -5, 'hider_2': -8}\n",
      "{'pred_1': -0.01, 'pred_2': 3, 'hider_1': -5, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 4, 'hider_1': -4, 'hider_2': -8}\n",
      "{'pred_1': -0.05, 'pred_2': 4, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -5, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -5, 'hider_2': -8}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -5, 'hider_2': -7}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -5, 'hider_2': -6}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -5, 'hider_2': -5}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -5, 'hider_2': -4}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -5, 'hider_2': -5}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -6, 'hider_2': -4}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -6, 'hider_2': -4}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -6, 'hider_2': -3}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -6, 'hider_2': -4}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -6, 'hider_2': -4}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -6, 'hider_2': -4}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -6, 'hider_2': -5}\n",
      "{'pred_1': -0.02, 'pred_2': 6, 'hider_1': -5, 'hider_2': -5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pred_1': -0.04, 'pred_2': 6, 'hider_1': -5, 'hider_2': -5}\n",
      "{'pred_1': -0.08, 'pred_2': 6, 'hider_1': -5, 'hider_2': -5}\n",
      "{'pred_1': -0.13, 'pred_2': 5, 'hider_1': -5, 'hider_2': -6}\n",
      "{'pred_1': -0.25, 'pred_2': 5, 'hider_1': -5, 'hider_2': -5}\n",
      "{'pred_1': -0.25, 'pred_2': 4, 'hider_1': -4, 'hider_2': -6}\n",
      "{'pred_1': -0.2, 'pred_2': 4, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.25, 'pred_2': 3, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.25, 'pred_2': 4, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.13, 'pred_2': 3, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.2, 'pred_2': 3, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.26, 'pred_2': 4, 'hider_1': -2, 'hider_2': -7}\n",
      "{'pred_1': -0.17, 'pred_2': 4, 'hider_1': -2, 'hider_2': -7}\n",
      "{'pred_1': -0.17, 'pred_2': 4, 'hider_1': -3, 'hider_2': -6}\n",
      "{'pred_1': -0.29, 'pred_2': 4, 'hider_1': -4, 'hider_2': -6}\n",
      "{'pred_1': -0.25, 'pred_2': 4, 'hider_1': -5, 'hider_2': -5}\n",
      "{'pred_1': -0.41, 'pred_2': 4, 'hider_1': -6, 'hider_2': -4}\n",
      "{'pred_1': -0.25, 'pred_2': 4, 'hider_1': -6, 'hider_2': -5}\n",
      "{'pred_1': -0.2, 'pred_2': 5, 'hider_1': -6, 'hider_2': -4}\n",
      "{'pred_1': -0.13, 'pred_2': 5, 'hider_1': -5, 'hider_2': -4}\n",
      "{'pred_1': -0.13, 'pred_2': 5, 'hider_1': -6, 'hider_2': -4}\n",
      "{'pred_1': -0.13, 'pred_2': 5, 'hider_1': -6, 'hider_2': -4}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -5, 'hider_2': -5}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -5, 'hider_2': -6}\n",
      "{'pred_1': -0.09, 'pred_2': 6, 'hider_1': -5, 'hider_2': -6}\n",
      "{'pred_1': -0.09, 'pred_2': 6, 'hider_1': -5, 'hider_2': -6}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -5, 'hider_2': -7}\n",
      "{'pred_1': -0.08, 'pred_2': 5, 'hider_1': -5, 'hider_2': -8}\n",
      "{'pred_1': -0.1, 'pred_2': 6, 'hider_1': -5, 'hider_2': -9}\n",
      "{'pred_1': -0.17, 'pred_2': 6, 'hider_1': -5, 'hider_2': -8}\n",
      "{'pred_1': -0.1, 'pred_2': 6, 'hider_1': -5, 'hider_2': -7}\n",
      "{'pred_1': -0.1, 'pred_2': 6, 'hider_1': -6, 'hider_2': -6}\n",
      "{'pred_1': -0.1, 'pred_2': 6, 'hider_1': -5, 'hider_2': -6}\n",
      "{'pred_1': -0.16, 'pred_2': 6, 'hider_1': -5, 'hider_2': -6}\n",
      "{'pred_1': -0.16, 'pred_2': 5, 'hider_1': -6, 'hider_2': -6}\n",
      "{'pred_1': -0.17, 'pred_2': 5, 'hider_1': -5, 'hider_2': -7}\n",
      "{'pred_1': -0.1, 'pred_2': 5, 'hider_1': -5, 'hider_2': -6}\n",
      "{'pred_1': -0.1, 'pred_2': 6, 'hider_1': -5, 'hider_2': -6}\n",
      "{'pred_1': -0.02, 'pred_2': 6, 'hider_1': -5, 'hider_2': -5}\n",
      "{'pred_1': -0.02, 'pred_2': 6, 'hider_1': -6, 'hider_2': -5}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -5, 'hider_2': -5}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -4, 'hider_2': -6}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -5, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -5, 'hider_2': -7}\n",
      "{'pred_1': -0.1, 'pred_2': 6, 'hider_1': -5, 'hider_2': -7}\n",
      "{'pred_1': -0.17, 'pred_2': 6, 'hider_1': -5, 'hider_2': -7}\n",
      "{'pred_1': -0.1, 'pred_2': 5, 'hider_1': -5, 'hider_2': -7}\n",
      "{'pred_1': -0.08, 'pred_2': 6, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.04, 'pred_2': 6, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -4, 'hider_2': -8}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -3, 'hider_2': -8}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -4, 'hider_2': -9}\n",
      "{'pred_1': -0.1, 'pred_2': 6, 'hider_1': -4, 'hider_2': -8}\n",
      "{'pred_1': -0.08, 'pred_2': 6, 'hider_1': -4, 'hider_2': -9}\n",
      "{'pred_1': -0.13, 'pred_2': 6, 'hider_1': -3, 'hider_2': -8}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -4, 'hider_2': -8}\n",
      "{'pred_1': -0.13, 'pred_2': 6, 'hider_1': -3, 'hider_2': -8}\n",
      "{'pred_1': -0.18, 'pred_2': 6, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.08, 'pred_2': 6, 'hider_1': -3, 'hider_2': -6}\n",
      "{'pred_1': -0.13, 'pred_2': 5, 'hider_1': -3, 'hider_2': -6}\n",
      "{'pred_1': -0.17, 'pred_2': 5, 'hider_1': -3, 'hider_2': -6}\n",
      "{'pred_1': -0.29, 'pred_2': 4, 'hider_1': -3, 'hider_2': -6}\n",
      "{'pred_1': -0.34, 'pred_2': 4, 'hider_1': -2, 'hider_2': -7}\n",
      "{'pred_1': -0.29, 'pred_2': 4, 'hider_1': -2, 'hider_2': -8}\n",
      "{'pred_1': -0.29, 'pred_2': 5, 'hider_1': -2, 'hider_2': -7}\n",
      "{'pred_1': -0.34, 'pred_2': 5, 'hider_1': -1, 'hider_2': -6}\n",
      "{'pred_1': -0.2, 'pred_2': 4, 'hider_1': -1, 'hider_2': -5}\n",
      "{'pred_1': -0.29, 'pred_2': 4, 'hider_1': -1, 'hider_2': -5}\n",
      "{'pred_1': -0.26, 'pred_2': 3, 'hider_1': -2, 'hider_2': -6}\n",
      "{'pred_1': -0.29, 'pred_2': 3, 'hider_1': -1, 'hider_2': -5}\n",
      "{'pred_1': -0.2, 'pred_2': 3, 'hider_1': -1, 'hider_2': -6}\n",
      "{'pred_1': -0.26, 'pred_2': 3, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.26, 'pred_2': 3, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.17, 'pred_2': 3, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.17, 'pred_2': 4, 'hider_1': -1, 'hider_2': -9}\n",
      "{'pred_1': -0.17, 'pred_2': 5, 'hider_1': -2, 'hider_2': -10}\n",
      "{'pred_1': -0.16, 'pred_2': 4, 'hider_1': -1, 'hider_2': -10}\n",
      "{'pred_1': -0.16, 'pred_2': 5, 'hider_1': -1, 'hider_2': -10}\n",
      "{'pred_1': -0.09, 'pred_2': 5, 'hider_1': -1, 'hider_2': -11}\n",
      "{'pred_1': -0.04, 'pred_2': 4, 'hider_1': -1, 'hider_2': -10}\n",
      "{'pred_1': -0.09, 'pred_2': 4, 'hider_1': -1, 'hider_2': -10}\n",
      "{'pred_1': -0.09, 'pred_2': 3, 'hider_1': -2, 'hider_2': -10}\n",
      "{'pred_1': -0.16, 'pred_2': 2, 'hider_1': -2, 'hider_2': -10}\n",
      "{'pred_1': -0.16, 'pred_2': 2, 'hider_1': -2, 'hider_2': -9}\n",
      "{'pred_1': -0.17, 'pred_2': 3, 'hider_1': -2, 'hider_2': -8}\n",
      "{'pred_1': -0.26, 'pred_2': 4, 'hider_1': -2, 'hider_2': -9}\n",
      "{'pred_1': -0.25, 'pred_2': 5, 'hider_1': -2, 'hider_2': -10}\n",
      "{'pred_1': -0.17, 'pred_2': 6, 'hider_1': -3, 'hider_2': -10}\n",
      "{'pred_1': -0.17, 'pred_2': 6, 'hider_1': -3, 'hider_2': -10}\n",
      "{'pred_1': -0.2, 'pred_2': 6, 'hider_1': -3, 'hider_2': -10}\n",
      "{'pred_1': -0.08, 'pred_2': 6, 'hider_1': -3, 'hider_2': -10}\n",
      "{'pred_1': -0.05, 'pred_2': 6, 'hider_1': -2, 'hider_2': -9}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -3, 'hider_2': -9}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -3, 'hider_2': -9}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -2, 'hider_2': -10}\n",
      "{'pred_1': -0.02, 'pred_2': 6, 'hider_1': -3, 'hider_2': -9}\n",
      "{'pred_1': -0.04, 'pred_2': 6, 'hider_1': -3, 'hider_2': -10}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -3, 'hider_2': -11}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -2, 'hider_2': -12}\n",
      "{'pred_1': -0.02, 'pred_2': 4, 'hider_1': -2, 'hider_2': -12}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -2, 'hider_2': -12}\n",
      "{'pred_1': 0.0, 'pred_2': 4, 'hider_1': -1, 'hider_2': -11}\n",
      "{'pred_1': -0.01, 'pred_2': 4, 'hider_1': -1, 'hider_2': -12}\n",
      "{'pred_1': -0.02, 'pred_2': 4, 'hider_1': -2, 'hider_2': -12}\n",
      "{'pred_1': -0.05, 'pred_2': 4, 'hider_1': -2, 'hider_2': -12}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -1, 'hider_2': -12}\n",
      "{'pred_1': -0.01, 'pred_2': 6, 'hider_1': -1, 'hider_2': -11}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -1, 'hider_2': -11}\n",
      "{'pred_1': 0.0, 'pred_2': 4, 'hider_1': -1, 'hider_2': -10}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -1, 'hider_2': -9}\n",
      "{'pred_1': 0.0, 'pred_2': 5, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.02, 'pred_2': 4, 'hider_1': -2, 'hider_2': -7}\n",
      "{'pred_1': -0.04, 'pred_2': 4, 'hider_1': -1, 'hider_2': -6}\n",
      "{'pred_1': -0.09, 'pred_2': 3, 'hider_1': -1, 'hider_2': -5}\n",
      "{'pred_1': -0.09, 'pred_2': 3, 'hider_1': -1, 'hider_2': -5}\n",
      "{'pred_1': -0.05, 'pred_2': 3, 'hider_1': -2, 'hider_2': -5}\n",
      "{'pred_1': -0.05, 'pred_2': 3, 'hider_1': -2, 'hider_2': -6}\n",
      "{'pred_1': -0.05, 'pred_2': 4, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -2, 'hider_2': -6}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -3, 'hider_2': -6}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -2, 'hider_2': -5}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -2, 'hider_2': -6}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -1, 'hider_2': -6}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -1, 'hider_2': -5}\n",
      "{'pred_1': 0.0, 'pred_2': 6, 'hider_1': -1, 'hider_2': -4}\n",
      "{}\n",
      "Episode 3 rewards: {'pred_1': -20.21000000000002, 'pred_2': 867, 'hider_1': -623, 'hider_2': -1490}\n",
      "{'pred_1': -0.17, 'pred_2': 2, 'hider_1': -5, 'hider_2': -9}\n",
      "{'pred_1': -0.17, 'pred_2': 2, 'hider_1': -5, 'hider_2': -9}\n",
      "{'pred_1': -0.26, 'pred_2': 2, 'hider_1': -5, 'hider_2': -9}\n",
      "{'pred_1': -0.1, 'pred_2': 1, 'hider_1': -5, 'hider_2': -10}\n",
      "{'pred_1': -0.1, 'pred_2': 2, 'hider_1': -5, 'hider_2': -9}\n",
      "{'pred_1': -0.17, 'pred_2': 2, 'hider_1': -5, 'hider_2': -10}\n",
      "{'pred_1': -0.17, 'pred_2': 1, 'hider_1': -5, 'hider_2': -9}\n",
      "{'pred_1': -0.17, 'pred_2': 1, 'hider_1': -5, 'hider_2': -8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pred_1': -0.09, 'pred_2': 1, 'hider_1': -6, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 1, 'hider_1': -5, 'hider_2': -8}\n",
      "{'pred_1': -0.01, 'pred_2': 1, 'hider_1': -6, 'hider_2': -7}\n",
      "{'pred_1': -0.04, 'pred_2': 1, 'hider_1': -6, 'hider_2': -8}\n",
      "{'pred_1': -0.04, 'pred_2': 1, 'hider_1': -6, 'hider_2': -7}\n",
      "{'pred_1': -0.01, 'pred_2': 1, 'hider_1': -6, 'hider_2': -7}\n",
      "{'pred_1': -0.01, 'pred_2': 1, 'hider_1': -6, 'hider_2': -8}\n",
      "{'pred_1': -0.01, 'pred_2': 2, 'hider_1': -6, 'hider_2': -9}\n",
      "{'pred_1': -0.02, 'pred_2': 2, 'hider_1': -6, 'hider_2': -10}\n",
      "{'pred_1': -0.08, 'pred_2': 2, 'hider_1': -6, 'hider_2': -9}\n",
      "{'pred_1': -0.04, 'pred_2': 2, 'hider_1': -5, 'hider_2': -8}\n",
      "{'pred_1': -0.05, 'pred_2': 1, 'hider_1': -5, 'hider_2': -8}\n",
      "{'pred_1': -0.05, 'pred_2': 1, 'hider_1': -5, 'hider_2': -7}\n",
      "{'pred_1': -0.01, 'pred_2': 1, 'hider_1': -5, 'hider_2': -8}\n",
      "{'pred_1': -0.02, 'pred_2': 1, 'hider_1': -5, 'hider_2': -8}\n",
      "{'pred_1': -0.01, 'pred_2': 2, 'hider_1': -5, 'hider_2': -9}\n",
      "{'pred_1': -0.04, 'pred_2': 2, 'hider_1': -4, 'hider_2': -9}\n",
      "{'pred_1': -0.08, 'pred_2': 1, 'hider_1': -4, 'hider_2': -9}\n",
      "{'pred_1': -0.05, 'pred_2': 1, 'hider_1': -5, 'hider_2': -8}\n",
      "{'pred_1': -0.1, 'pred_2': 1, 'hider_1': -5, 'hider_2': -7}\n",
      "{'pred_1': -0.17, 'pred_2': 1, 'hider_1': -5, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 1, 'hider_1': -5, 'hider_2': -6}\n",
      "{'pred_1': -0.09, 'pred_2': 2, 'hider_1': -6, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 2, 'hider_1': -6, 'hider_2': -7}\n",
      "{'pred_1': -0.09, 'pred_2': 2, 'hider_1': -6, 'hider_2': -7}\n",
      "{'pred_1': -0.04, 'pred_2': 2, 'hider_1': -6, 'hider_2': -8}\n",
      "{'pred_1': -0.04, 'pred_2': 2, 'hider_1': -6, 'hider_2': -9}\n",
      "{'pred_1': -0.16, 'pred_2': 2, 'hider_1': -6, 'hider_2': -8}\n",
      "{'pred_1': -0.1, 'pred_2': 2, 'hider_1': -5, 'hider_2': -7}\n",
      "{'pred_1': -0.17, 'pred_2': 2, 'hider_1': -5, 'hider_2': -6}\n",
      "{'pred_1': -0.17, 'pred_2': 2, 'hider_1': -5, 'hider_2': -5}\n",
      "{'pred_1': -0.13, 'pred_2': 2, 'hider_1': -4, 'hider_2': -6}\n",
      "{'pred_1': -0.25, 'pred_2': 2, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.25, 'pred_2': 2, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.25, 'pred_2': 2, 'hider_1': -3, 'hider_2': -8}\n",
      "{'pred_1': -0.29, 'pred_2': 1, 'hider_1': -4, 'hider_2': -8}\n",
      "{'pred_1': -0.17, 'pred_2': 2, 'hider_1': -4, 'hider_2': -9}\n",
      "{'pred_1': -0.25, 'pred_2': 1, 'hider_1': -4, 'hider_2': -8}\n",
      "{'pred_1': -0.17, 'pred_2': 1, 'hider_1': -3, 'hider_2': -8}\n",
      "{'pred_1': -0.17, 'pred_2': 1, 'hider_1': -3, 'hider_2': -8}\n",
      "{'pred_1': -0.1, 'pred_2': 1, 'hider_1': -3, 'hider_2': -8}\n",
      "{'pred_1': -0.02, 'pred_2': 1, 'hider_1': -3, 'hider_2': -8}\n",
      "{'pred_1': 0.0, 'pred_2': 1, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.02, 'pred_2': 1, 'hider_1': -5, 'hider_2': -6}\n",
      "{'pred_1': -0.1, 'pred_2': 1, 'hider_1': -5, 'hider_2': -7}\n",
      "{'pred_1': -0.09, 'pred_2': 1, 'hider_1': -4, 'hider_2': -8}\n",
      "{'pred_1': -0.09, 'pred_2': 1, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.04, 'pred_2': 1, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.04, 'pred_2': 1, 'hider_1': -4, 'hider_2': -8}\n",
      "{'pred_1': -0.1, 'pred_2': 2, 'hider_1': -5, 'hider_2': -7}\n",
      "{'pred_1': -0.16, 'pred_2': 1, 'hider_1': -5, 'hider_2': -8}\n",
      "{'pred_1': -0.2, 'pred_2': 2, 'hider_1': -4, 'hider_2': -8}\n",
      "{'pred_1': -0.17, 'pred_2': 1, 'hider_1': -4, 'hider_2': -9}\n",
      "{'pred_1': -0.1, 'pred_2': 1, 'hider_1': -4, 'hider_2': -8}\n",
      "{'pred_1': -0.16, 'pred_2': 1, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.04, 'pred_2': 1, 'hider_1': -4, 'hider_2': -8}\n",
      "{'pred_1': 0.0, 'pred_2': 2, 'hider_1': -4, 'hider_2': -9}\n",
      "{'pred_1': 0.0, 'pred_2': 3, 'hider_1': -4, 'hider_2': -8}\n",
      "{'pred_1': -0.01, 'pred_2': 2, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.01, 'pred_2': 2, 'hider_1': -4, 'hider_2': -8}\n",
      "{'pred_1': -0.01, 'pred_2': 3, 'hider_1': -4, 'hider_2': -9}\n",
      "{'pred_1': -0.01, 'pred_2': 3, 'hider_1': -3, 'hider_2': -8}\n",
      "{'pred_1': -0.05, 'pred_2': 4, 'hider_1': -3, 'hider_2': -8}\n",
      "{'pred_1': -0.02, 'pred_2': 3, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.04, 'pred_2': 4, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.09, 'pred_2': 4, 'hider_1': -3, 'hider_2': -6}\n",
      "{'pred_1': -0.16, 'pred_2': 3, 'hider_1': -2, 'hider_2': -7}\n",
      "{'pred_1': -0.16, 'pred_2': 3, 'hider_1': -2, 'hider_2': -6}\n",
      "{'pred_1': -0.16, 'pred_2': 4, 'hider_1': -2, 'hider_2': -7}\n",
      "{'pred_1': -0.09, 'pred_2': 4, 'hider_1': -2, 'hider_2': -7}\n",
      "{'pred_1': -0.04, 'pred_2': 5, 'hider_1': -2, 'hider_2': -7}\n",
      "{'pred_1': -0.1, 'pred_2': 6, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.13, 'pred_2': 6, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.18, 'pred_2': 5, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.08, 'pred_2': 5, 'hider_1': -1, 'hider_2': -9}\n",
      "{'pred_1': -0.2, 'pred_2': 5, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.25, 'pred_2': 5, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.18, 'pred_2': 5, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.13, 'pred_2': 5, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.17, 'pred_2': 4, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.17, 'pred_2': 4, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.16, 'pred_2': 4, 'hider_1': -1, 'hider_2': -6}\n",
      "{'pred_1': -0.16, 'pred_2': 4, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.26, 'pred_2': 4, 'hider_1': -2, 'hider_2': -7}\n",
      "{'pred_1': -0.17, 'pred_2': 5, 'hider_1': -2, 'hider_2': -6}\n",
      "{'pred_1': -0.1, 'pred_2': 6, 'hider_1': -2, 'hider_2': -7}\n",
      "{'pred_1': -0.1, 'pred_2': 6, 'hider_1': -2, 'hider_2': -8}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -2, 'hider_2': -9}\n",
      "{'pred_1': -0.01, 'pred_2': 5, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -2, 'hider_2': -9}\n",
      "{'pred_1': -0.05, 'pred_2': 5, 'hider_1': -2, 'hider_2': -8}\n",
      "{'pred_1': -0.01, 'pred_2': 4, 'hider_1': -1, 'hider_2': -9}\n",
      "{'pred_1': -0.04, 'pred_2': 3, 'hider_1': -1, 'hider_2': -9}\n",
      "{'pred_1': -0.04, 'pred_2': 3, 'hider_1': -1, 'hider_2': -9}\n",
      "{'pred_1': -0.09, 'pred_2': 3, 'hider_1': -1, 'hider_2': -9}\n",
      "{'pred_1': -0.09, 'pred_2': 3, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.04, 'pred_2': 2, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 2, 'hider_1': -2, 'hider_2': -8}\n",
      "{'pred_1': -0.04, 'pred_2': 2, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.04, 'pred_2': 3, 'hider_1': -2, 'hider_2': -6}\n",
      "{'pred_1': -0.16, 'pred_2': 4, 'hider_1': -2, 'hider_2': -5}\n",
      "{'pred_1': -0.1, 'pred_2': 4, 'hider_1': -1, 'hider_2': -5}\n",
      "{'pred_1': -0.09, 'pred_2': 3, 'hider_1': -1, 'hider_2': -5}\n",
      "{'pred_1': -0.09, 'pred_2': 2, 'hider_1': -1, 'hider_2': -4}\n",
      "{'pred_1': -0.1, 'pred_2': 2, 'hider_1': -2, 'hider_2': -5}\n",
      "{'pred_1': -0.05, 'pred_2': 3, 'hider_1': -2, 'hider_2': -6}\n",
      "{'pred_1': -0.05, 'pred_2': 3, 'hider_1': -3, 'hider_2': -6}\n",
      "{'pred_1': -0.05, 'pred_2': 3, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.13, 'pred_2': 3, 'hider_1': -3, 'hider_2': -8}\n",
      "{'pred_1': -0.08, 'pred_2': 4, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 4, 'hider_1': -2, 'hider_2': -7}\n",
      "{'pred_1': -0.02, 'pred_2': 4, 'hider_1': -2, 'hider_2': -6}\n",
      "{'pred_1': -0.02, 'pred_2': 4, 'hider_1': -2, 'hider_2': -6}\n",
      "{'pred_1': -0.01, 'pred_2': 3, 'hider_1': -2, 'hider_2': -5}\n",
      "{'pred_1': -0.04, 'pred_2': 3, 'hider_1': -3, 'hider_2': -6}\n",
      "{'pred_1': -0.05, 'pred_2': 4, 'hider_1': -3, 'hider_2': -5}\n",
      "{'pred_1': -0.09, 'pred_2': 3, 'hider_1': -4, 'hider_2': -6}\n",
      "{'pred_1': -0.04, 'pred_2': 3, 'hider_1': -3, 'hider_2': -5}\n",
      "{'pred_1': -0.09, 'pred_2': 4, 'hider_1': -4, 'hider_2': -5}\n",
      "{'pred_1': -0.16, 'pred_2': 3, 'hider_1': -5, 'hider_2': -6}\n",
      "{'pred_1': -0.1, 'pred_2': 3, 'hider_1': -4, 'hider_2': -5}\n",
      "{'pred_1': -0.04, 'pred_2': 4, 'hider_1': -4, 'hider_2': -6}\n",
      "{'pred_1': -0.04, 'pred_2': 4, 'hider_1': -4, 'hider_2': -6}\n",
      "{'pred_1': -0.04, 'pred_2': 3, 'hider_1': -4, 'hider_2': -6}\n",
      "{'pred_1': -0.01, 'pred_2': 3, 'hider_1': -4, 'hider_2': -6}\n",
      "{'pred_1': 0.0, 'pred_2': 2, 'hider_1': -3, 'hider_2': -5}\n",
      "{'pred_1': 0.0, 'pred_2': 2, 'hider_1': -2, 'hider_2': -4}\n",
      "{'pred_1': -0.01, 'pred_2': 3, 'hider_1': -2, 'hider_2': -5}\n",
      "{'pred_1': -0.01, 'pred_2': 3, 'hider_1': -2, 'hider_2': -6}\n",
      "{'pred_1': -0.01, 'pred_2': 4, 'hider_1': -1, 'hider_2': -6}\n",
      "{'pred_1': -0.09, 'pred_2': 4, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.1, 'pred_2': 4, 'hider_1': -1, 'hider_2': -8}\n",
      "{'pred_1': -0.04, 'pred_2': 4, 'hider_1': -1, 'hider_2': -9}\n",
      "{'pred_1': -0.01, 'pred_2': 4, 'hider_1': -1, 'hider_2': -9}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -1, 'hider_2': -8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -1, 'hider_2': -7}\n",
      "{'pred_1': -0.02, 'pred_2': 5, 'hider_1': -2, 'hider_2': -7}\n",
      "{'pred_1': -0.01, 'pred_2': 4, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.01, 'pred_2': 3, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.02, 'pred_2': 2, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': 0.0, 'pred_2': 2, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': -0.01, 'pred_2': 2, 'hider_1': -2, 'hider_2': -6}\n",
      "{'pred_1': -0.01, 'pred_2': 2, 'hider_1': -2, 'hider_2': -6}\n",
      "{'pred_1': 0.0, 'pred_2': 2, 'hider_1': -3, 'hider_2': -7}\n",
      "{'pred_1': 0.0, 'pred_2': 2, 'hider_1': -3, 'hider_2': -8}\n",
      "{'pred_1': -0.02, 'pred_2': 2, 'hider_1': -4, 'hider_2': -8}\n",
      "{'pred_1': -0.02, 'pred_2': 2, 'hider_1': -5, 'hider_2': -8}\n",
      "{'pred_1': -0.05, 'pred_2': 2, 'hider_1': -6, 'hider_2': -9}\n",
      "{'pred_1': -0.01, 'pred_2': 2, 'hider_1': -5, 'hider_2': -10}\n",
      "{'pred_1': -0.02, 'pred_2': 2, 'hider_1': -4, 'hider_2': -11}\n",
      "{'pred_1': -0.05, 'pred_2': 2, 'hider_1': -4, 'hider_2': -11}\n",
      "{'pred_1': -0.05, 'pred_2': 2, 'hider_1': -4, 'hider_2': -10}\n",
      "{'pred_1': -0.02, 'pred_2': 2, 'hider_1': -4, 'hider_2': -10}\n",
      "{'pred_1': -0.04, 'pred_2': 2, 'hider_1': -4, 'hider_2': -10}\n",
      "{'pred_1': -0.04, 'pred_2': 2, 'hider_1': -3, 'hider_2': -10}\n",
      "{'pred_1': -0.05, 'pred_2': 3, 'hider_1': -4, 'hider_2': -11}\n",
      "{'pred_1': -0.04, 'pred_2': 3, 'hider_1': -4, 'hider_2': -11}\n",
      "{'pred_1': -0.09, 'pred_2': 2, 'hider_1': -4, 'hider_2': -10}\n",
      "{'pred_1': -0.01, 'pred_2': 1, 'hider_1': -4, 'hider_2': -9}\n",
      "{'pred_1': -0.02, 'pred_2': 1, 'hider_1': -3, 'hider_2': -8}\n",
      "{'pred_1': -0.04, 'pred_2': 1, 'hider_1': -3, 'hider_2': -9}\n",
      "{'pred_1': -0.05, 'pred_2': 1, 'hider_1': -3, 'hider_2': -8}\n",
      "{'pred_1': -0.05, 'pred_2': 1, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.05, 'pred_2': 1, 'hider_1': -4, 'hider_2': -6}\n",
      "{'pred_1': -0.05, 'pred_2': 2, 'hider_1': -4, 'hider_2': -7}\n",
      "{'pred_1': -0.02, 'pred_2': 1, 'hider_1': -4, 'hider_2': -6}\n",
      "{'pred_1': -0.04, 'pred_2': 1, 'hider_1': -5, 'hider_2': -5}\n",
      "{'pred_1': -0.09, 'pred_2': 1, 'hider_1': -5, 'hider_2': -5}\n",
      "{'pred_1': -0.09, 'pred_2': 1, 'hider_1': -5, 'hider_2': -4}\n",
      "{'pred_1': -0.1, 'pred_2': 1, 'hider_1': -5, 'hider_2': -4}\n",
      "{'pred_1': -0.13, 'pred_2': 1, 'hider_1': -4, 'hider_2': -5}\n",
      "{'pred_1': -0.05, 'pred_2': 1, 'hider_1': -5, 'hider_2': -5}\n",
      "{'pred_1': -0.01, 'pred_2': 1, 'hider_1': -5, 'hider_2': -6}\n",
      "{'pred_1': 0.0, 'pred_2': 1, 'hider_1': -6, 'hider_2': -7}\n",
      "{'pred_1': -0.01, 'pred_2': 1, 'hider_1': -6, 'hider_2': -6}\n",
      "{'pred_1': -0.01, 'pred_2': 1, 'hider_1': -6, 'hider_2': -6}\n",
      "{'pred_1': -0.01, 'pred_2': 1, 'hider_1': -6, 'hider_2': -6}\n",
      "{'pred_1': -0.04, 'pred_2': 1, 'hider_1': -6, 'hider_2': -6}\n",
      "{'pred_1': -0.04, 'pred_2': 1, 'hider_1': -6, 'hider_2': -6}\n",
      "{'pred_1': -0.04, 'pred_2': 1, 'hider_1': -6, 'hider_2': -5}\n",
      "{'pred_1': -0.09, 'pred_2': 1, 'hider_1': -6, 'hider_2': -4}\n",
      "{'pred_1': -0.1, 'pred_2': 1, 'hider_1': -5, 'hider_2': -4}\n",
      "{'pred_1': -0.08, 'pred_2': 1, 'hider_1': -4, 'hider_2': -5}\n",
      "{'pred_1': -0.05, 'pred_2': 2, 'hider_1': -5, 'hider_2': -4}\n",
      "{'pred_1': -0.05, 'pred_2': 1, 'hider_1': -5, 'hider_2': -3}\n",
      "{'pred_1': -0.1, 'pred_2': 1, 'hider_1': -5, 'hider_2': -4}\n",
      "{'pred_1': -0.04, 'pred_2': 1, 'hider_1': -6, 'hider_2': -4}\n",
      "{'pred_1': -0.01, 'pred_2': 1, 'hider_1': -6, 'hider_2': -5}\n",
      "{'pred_1': -0.02, 'pred_2': 1, 'hider_1': -5, 'hider_2': -4}\n",
      "{}\n",
      "Episode 4 rewards: {'pred_1': -14.799999999999981, 'pred_2': 483, 'hider_1': -715, 'hider_2': -1437}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "\n",
    "from PARALLEL import movable_wall_parallel\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "# policies = [\n",
    "#     '/home/bpopper/letsgo/2d_RL_hide_seek/PARALLEL/weights/best_model.pth',\n",
    "#     None,\n",
    "#     '/home/bpopper/letsgo/2d_RL_hide_seek/PARALLEL/best_model_fleee.pth',\n",
    "#     None]\n",
    "\n",
    "#both trained :  approx reward 250 for hider\n",
    "\n",
    "# policies = [\n",
    "#     None,\n",
    "#     None,\n",
    "#     '/home/bpopper/letsgo/2d_RL_hide_seek/PARALLEL/weights/best_model_hider1.pth',\n",
    "#     None]\n",
    "# #ith only trained hider : approx rewared 1800 for hider\n",
    "\n",
    "\n",
    "policies = [\n",
    "    '/storage/ice1/0/4/bpopper3/2d_RL_hide_seek/PARALLEL/best_pred1_nowalls_6x8x8.pth',\n",
    "    None,\n",
    "    None,\n",
    "    None]\n",
    "#with trained seeker : approx 155 reward for hider\n",
    "\n",
    "#either None : random ; or a path\n",
    "\n",
    "GRID_SIZE = 8\n",
    "NUM_THINGS = 6\n",
    "\n",
    "env = movable_wall_parallel.parallel_env(grid_size=GRID_SIZE,render_mode=\"human\",walls=False)\n",
    "\n",
    "class Agent(nn.Module):\n",
    "    def __init__(self, num_actions):\n",
    "        super().__init__()\n",
    "\n",
    "        # CNN architecture inspired by DQN for Atari\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(NUM_THINGS, 32, kernel_size=3, stride=1, padding=1),  # Output: 32 x 7 x 7\n",
    "            #nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),  # Output: 64 x 7 x 7\n",
    "            #nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),  # Output: 64 x 7 x 7\n",
    "            #nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),  # Output: 64 * 7 * 7 = 3136\n",
    "        )\n",
    "        self.actor = self._layer_init(nn.Linear(64*GRID_SIZE**2, num_actions), std=0.01)\n",
    "        self.critic = self._layer_init(nn.Linear(64*GRID_SIZE**2, 1))\n",
    "\n",
    "    def _layer_init(self, layer, std=np.sqrt(2), bias_const=0.0):\n",
    "        torch.nn.init.orthogonal_(layer.weight, std)\n",
    "        torch.nn.init.constant_(layer.bias, bias_const)\n",
    "        return layer\n",
    "\n",
    "    def get_value(self, x):\n",
    "        return self.critic(self.network(x / 1.0))  # Normalize input to [0, 1]\n",
    "\n",
    "    def get_action_and_value(self, x, action=None):\n",
    "        #print(x)\n",
    "        #print(x.shape)\n",
    "        hidden = self.network(x / 1.0)  # Normalize input to [0, 1]\n",
    "        \n",
    "        logits = self.actor(hidden)\n",
    "        #print(f' in get_action_and_valuelogits: {logits}')\n",
    "        probs = Categorical(logits=logits)\n",
    "        if action is None:\n",
    "            action = probs.sample()\n",
    "        #print(f' in get_action_and_value: {action}')\n",
    "        return action, probs.log_prob(action), probs.entropy(), self.critic(hidden)\n",
    "\n",
    "    \n",
    "\n",
    "def batchify_obs(obs, device):\n",
    "    \"\"\"Converts PZ style observations to batch of torch arrays.\"\"\"\n",
    "    # convert to list of np arrays\n",
    "    obs = np.stack([obs[a] for a in obs], axis=0)\n",
    "    # convert to torch\n",
    "    obs = torch.tensor(obs).to(device)\n",
    "\n",
    "    return obs\n",
    "\n",
    "\n",
    "def batchify(x, device):\n",
    "    \"\"\"Converts PZ style returns to batch of torch arrays.\"\"\"\n",
    "    # convert to list of np arrays\n",
    "    x = np.stack([x[a] for a in x], axis=0)\n",
    "    # convert to torch\n",
    "    x = torch.tensor(x).to(device)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def unbatchify(x, env):\n",
    "    \"\"\"Converts np array to PZ style arguments.\"\"\"\n",
    "    x = x.cpu().numpy()\n",
    "    x = {a: x[i] for i, a in enumerate(env.possible_agents)}\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\" ENV SETUP \"\"\"\n",
    "    \n",
    "\n",
    "    num_agents = len(env.possible_agents)\n",
    "    num_actions = env.action_space(env.possible_agents[0]).n\n",
    "    observation_size = env.observation_space(env.possible_agents[0]).shape\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \"\"\" RENDER THE POLICY \"\"\"\n",
    "    \n",
    "\n",
    "    \n",
    "    agent_pred1 = Agent(num_actions=num_actions).to(device)\n",
    "    if policies[0] is not None:\n",
    "        agent_pred1.load_state_dict(torch.load(policies[0]))\n",
    "\n",
    "    agent_pred2 = Agent(num_actions=num_actions).to(device)\n",
    "    if policies[1] is not None:\n",
    "        agent_pred2.load_state_dict(torch.load(policies[1]))\n",
    "\n",
    "    agent_flee1 = Agent(num_actions=num_actions).to(device)\n",
    "    if policies[2] is not None:\n",
    "        agent_flee1.load_state_dict(torch.load(policies[2]))\n",
    "\n",
    "    agent_flee2 = Agent(num_actions=num_actions).to(device)\n",
    "    if policies[3] is not None:\n",
    "        agent_flee2.load_state_dict(torch.load(policies[3]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # render 5 episodes out\n",
    "        for episode in range(5):\n",
    "            obs, infos = env.reset(seed=None)\n",
    "            #obs = batchify_obs(obs, device)\n",
    "            terms = [False]\n",
    "            truncs = [False]\n",
    "            total_ep_rew = {'pred_1':0, 'pred_2':0, 'hider_1':0, 'hider_2':0}\n",
    "            while not any(terms) and not any(truncs):\n",
    "\n",
    "                action_p1, logprob_p1, _, value_p1 = agent_pred1.get_action_and_value(torch.tensor(obs['pred_1']).unsqueeze(0).to(device))\n",
    "                action_p2, logprob_p2, _, value_p2 = agent_pred2.get_action_and_value(torch.tensor(obs['pred_2']).unsqueeze(0).to(device))\n",
    "                action_h1, logprob_h1, _, value_h1 = agent_flee1.get_action_and_value(torch.tensor(obs['hider_1']).unsqueeze(0).to(device))\n",
    "                action_h2, logprob_h2, _, value_h2 = agent_flee2.get_action_and_value(torch.tensor(obs['hider_2']).unsqueeze(0).to(device))\n",
    "\n",
    "                actions = torch.cat([action_p1, action_p2, action_h1, action_h2])\n",
    "                #print(actions)  \n",
    "                \n",
    "                for idx,p in enumerate(policies):\n",
    "                    if p == None:\n",
    "                        actions[idx] = torch.randint(0, num_actions, (1,)).to(device)\n",
    "\n",
    "                #print(actions)\n",
    "                obs, rewards, terms, truncs, infos = env.step(unbatchify(actions, env))\n",
    "                #obs = batchify_obs(obs, device)\n",
    "                terms = [terms[a] for a in terms]\n",
    "                truncs = [truncs[a] for a in truncs]\n",
    "\n",
    "                total_ep_rew['pred_1'] += rewards['pred_1']\n",
    "                total_ep_rew['pred_2'] += rewards['pred_2']\n",
    "                total_ep_rew['hider_1'] += rewards['hider_1']\n",
    "                total_ep_rew['hider_2'] += rewards['hider_2']\n",
    "\n",
    "\n",
    "            print(f\"Episode {episode} rewards: {total_ep_rew}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-drl]",
   "language": "python",
   "name": "conda-env-.conda-drl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
