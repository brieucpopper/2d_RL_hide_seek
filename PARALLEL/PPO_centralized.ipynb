{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31ea5077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "import parallel\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5747b48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Super_Agent(nn.Module):\n",
    "    #Common agent class for all hiders/seekers\n",
    "    \n",
    "    def __init__(self, num_actions, num_agents):\n",
    "        super().__init__()\n",
    "\n",
    "        # CNN architecture inspired by DQN for Atari\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(5, 32, kernel_size=3, stride=1, padding=1),  # Output: 32 x 7 x 7\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),  # Output: 64 x 7 x 7\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),  # Output: 64 x 7 x 7\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),  # Output: 64 * 7 * 7 = 3136\n",
    "        )\n",
    "        self.actor = self._layer_init(nn.Linear(3136, num_actions), std=0.01)\n",
    "        self.critic = self._layer_init(nn.Linear(3136, 1))\n",
    "\n",
    "    def _layer_init(self, layer, std=np.sqrt(2), bias_const=0.0):\n",
    "        torch.nn.init.orthogonal_(layer.weight, std)\n",
    "        torch.nn.init.constant_(layer.bias, bias_const)\n",
    "        return layer\n",
    "\n",
    "    def get_value(self, x):\n",
    "        return self.critic(self.network(x / 1.0))  # Normalize input to [0, 1]\n",
    "\n",
    "    def get_action_and_value(self, x, action=None):\n",
    "        hidden = self.network(x / 1.0)  # Normalize input to [0, 1]\n",
    "        \n",
    "        logits = self.actor(hidden)\n",
    "        probs = Categorical(logits=logits)\n",
    "        if action is None:\n",
    "            action = probs.sample()\n",
    "        return action, probs.log_prob(action), probs.entropy(), self.critic(hidden)\n",
    "\n",
    "    \n",
    "\n",
    "def batchify_obs(obs, device):\n",
    "    \"\"\"Converts PZ style observations to batch of torch arrays.\"\"\"\n",
    "    # convert to list of np arrays\n",
    "    obs = np.stack([obs[a] for a in obs], axis=0)\n",
    "    # convert to torch\n",
    "    obs = torch.tensor(obs).to(device)\n",
    "\n",
    "    return obs\n",
    "\n",
    "\n",
    "def batchify(x, device):\n",
    "    \"\"\"Converts PZ style returns to batch of torch arrays.\"\"\"\n",
    "    # convert to list of np arrays\n",
    "    x = np.stack([x[a] for a in x], axis=0)\n",
    "    # convert to torch\n",
    "    x = torch.tensor(x).to(device)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def unbatchify(x, env):\n",
    "    \"\"\"Converts np array to PZ style arguments.\"\"\"\n",
    "    x = x.cpu().numpy()\n",
    "    x = {a: x[i] for i, a in enumerate(env.possible_agents)}\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99ded135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training episode 0\n",
      "Episodic Return: -6.192000389099121\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 38555.921875\n",
      "Policy Loss: 271.5767517089844\n",
      "Old Approx KL: 0.005476261954754591\n",
      "Approx KL: 0.0031052830163389444\n",
      "Clip Fraction: 0.08573717986926055\n",
      "Explained Variance: -2.7894973754882812e-05\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 1\n",
      "Episodic Return: -4.828000068664551\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 30875.853515625\n",
      "Policy Loss: 230.19256591796875\n",
      "Old Approx KL: 0.0395609587430954\n",
      "Approx KL: 0.006656165700405836\n",
      "Clip Fraction: 0.14537545828483042\n",
      "Explained Variance: 3.17692756652832e-05\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 2\n",
      "Episodic Return: -5.500000476837158\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 35231.13671875\n",
      "Policy Loss: 234.8712921142578\n",
      "Old Approx KL: 0.025779733434319496\n",
      "Approx KL: 0.001655459520407021\n",
      "Clip Fraction: 0.3444368134324367\n",
      "Explained Variance: -2.4557113647460938e-05\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 3\n",
      "Episodic Return: -5.184000015258789\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 24528.0234375\n",
      "Policy Loss: 213.15719604492188\n",
      "Old Approx KL: -0.0022514888551086187\n",
      "Approx KL: 0.001687245792709291\n",
      "Clip Fraction: 0.14285714351213896\n",
      "Explained Variance: -6.0558319091796875e-05\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 4\n",
      "Episodic Return: -5.984000205993652\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 39229.89453125\n",
      "Policy Loss: 260.911865234375\n",
      "Old Approx KL: 0.028021320700645447\n",
      "Approx KL: 0.0014476351207122207\n",
      "Clip Fraction: 0.15728022081729692\n",
      "Explained Variance: -0.00015246868133544922\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 5\n",
      "Episodic Return: -6.4800004959106445\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 33641.7890625\n",
      "Policy Loss: 244.69244384765625\n",
      "Old Approx KL: 0.03672218322753906\n",
      "Approx KL: 0.0026295569259673357\n",
      "Clip Fraction: 0.27037545847587097\n",
      "Explained Variance: 1.7821788787841797e-05\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 6\n",
      "Episodic Return: -5.312000274658203\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 11937.982421875\n",
      "Policy Loss: 116.17881774902344\n",
      "Old Approx KL: -0.01627759449183941\n",
      "Approx KL: 0.00938117504119873\n",
      "Clip Fraction: 0.2963598913107163\n",
      "Explained Variance: 0.00016951560974121094\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 7\n",
      "Episodic Return: -6.188000202178955\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 19840.33984375\n",
      "Policy Loss: 150.40757751464844\n",
      "Old Approx KL: -0.011600954458117485\n",
      "Approx KL: 0.004669534508138895\n",
      "Clip Fraction: 0.30105311480852276\n",
      "Explained Variance: -0.0008184909820556641\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 8\n",
      "Episodic Return: -6.812000274658203\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 12502.1162109375\n",
      "Policy Loss: 141.07028198242188\n",
      "Old Approx KL: 0.053960613906383514\n",
      "Approx KL: 0.004676248412579298\n",
      "Clip Fraction: 0.27586996402495945\n",
      "Explained Variance: -0.0010933876037597656\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 9\n",
      "Episodic Return: -7.016000270843506\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 12294.6337890625\n",
      "Policy Loss: 115.47235870361328\n",
      "Old Approx KL: 0.05923106148838997\n",
      "Approx KL: 0.004624009132385254\n",
      "Clip Fraction: 0.3790064117847345\n",
      "Explained Variance: -0.0006866455078125\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 10\n",
      "Episodic Return: -5.164000034332275\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 656.8842163085938\n",
      "Policy Loss: 4.54347038269043\n",
      "Old Approx KL: -0.03646702691912651\n",
      "Approx KL: 0.0020094343926757574\n",
      "Clip Fraction: 0.1319826012238478\n",
      "Explained Variance: 0.00019359588623046875\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 11\n",
      "Episodic Return: -5.4160003662109375\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 829.697021484375\n",
      "Policy Loss: 10.510054588317871\n",
      "Old Approx KL: 0.049190957099199295\n",
      "Approx KL: 0.004435292445123196\n",
      "Clip Fraction: 0.18967490929823655\n",
      "Explained Variance: -0.002091526985168457\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 12\n",
      "Episodic Return: -5.828000068664551\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 4780.6923828125\n",
      "Policy Loss: 78.12673950195312\n",
      "Old Approx KL: 0.03463500738143921\n",
      "Approx KL: 0.003588323248550296\n",
      "Clip Fraction: 0.19677197933197021\n",
      "Explained Variance: 0.00317305326461792\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 13\n",
      "Episodic Return: -5.3480000495910645\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 2771.14794921875\n",
      "Policy Loss: 33.953426361083984\n",
      "Old Approx KL: 0.050778381526470184\n",
      "Approx KL: 0.004044081550091505\n",
      "Clip Fraction: 0.15281593474822167\n",
      "Explained Variance: 0.0001245737075805664\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 14\n",
      "Episodic Return: -7.28000020980835\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 18274.46484375\n",
      "Policy Loss: 158.3184356689453\n",
      "Old Approx KL: 0.07208822667598724\n",
      "Approx KL: 0.016239039599895477\n",
      "Clip Fraction: 0.4900412116295252\n",
      "Explained Variance: 0.0013406872749328613\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 15\n",
      "Episodic Return: -5.432000160217285\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 4454.21044921875\n",
      "Policy Loss: -73.71623992919922\n",
      "Old Approx KL: -0.050415586680173874\n",
      "Approx KL: 0.006237805355340242\n",
      "Clip Fraction: 0.3716804041312291\n",
      "Explained Variance: -0.0007908344268798828\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 16\n",
      "Episodic Return: -7.260000228881836\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 5732.08837890625\n",
      "Policy Loss: 58.905155181884766\n",
      "Old Approx KL: -0.02611788734793663\n",
      "Approx KL: 0.006905036512762308\n",
      "Clip Fraction: 0.4044185005701505\n",
      "Explained Variance: -0.0007735490798950195\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 17\n",
      "Episodic Return: -6.228000164031982\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 799.1749267578125\n",
      "Policy Loss: -10.753697395324707\n",
      "Old Approx KL: -0.008977728895843029\n",
      "Approx KL: 0.003278127871453762\n",
      "Clip Fraction: 0.2694597083788652\n",
      "Explained Variance: -0.0023806095123291016\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 18\n",
      "Episodic Return: -7.580000400543213\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 2061.03564453125\n",
      "Policy Loss: 35.09589385986328\n",
      "Old Approx KL: 0.0719694197177887\n",
      "Approx KL: 0.007014551665633917\n",
      "Clip Fraction: 0.2119963383063292\n",
      "Explained Variance: 0.00864112377166748\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 19\n",
      "Episodic Return: -6.7960004806518555\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 3877.33984375\n",
      "Policy Loss: 20.86115837097168\n",
      "Old Approx KL: 0.0208597369492054\n",
      "Approx KL: 0.007078767288476229\n",
      "Clip Fraction: 0.3009386459986369\n",
      "Explained Variance: -0.004446625709533691\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 20\n",
      "Episodic Return: -8.956000328063965\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 9811.4248046875\n",
      "Policy Loss: 105.08977508544922\n",
      "Old Approx KL: 0.04967884719371796\n",
      "Approx KL: 0.011094051413238049\n",
      "Clip Fraction: 0.43944597244262695\n",
      "Explained Variance: 0.0011238455772399902\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 21\n",
      "Episodic Return: -6.428000450134277\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 7085.66796875\n",
      "Policy Loss: 46.99452590942383\n",
      "Old Approx KL: 0.03177120164036751\n",
      "Approx KL: 0.006568776909261942\n",
      "Clip Fraction: 0.3373397455001489\n",
      "Explained Variance: 0.0024848580360412598\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 22\n",
      "Episodic Return: -5.824000358581543\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 6531.3544921875\n",
      "Policy Loss: -37.97622299194336\n",
      "Old Approx KL: -0.03348900005221367\n",
      "Approx KL: 0.005084770265966654\n",
      "Clip Fraction: 0.38576007500672954\n",
      "Explained Variance: 0.001381218433380127\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 23\n",
      "Episodic Return: -7.0960001945495605\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1277.9437255859375\n",
      "Policy Loss: 9.7680082321167\n",
      "Old Approx KL: 0.026720542460680008\n",
      "Approx KL: 0.007216411177068949\n",
      "Clip Fraction: 0.30116758380944914\n",
      "Explained Variance: 0.0009780526161193848\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 24\n",
      "Episodic Return: -6.2960004806518555\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 4993.3896484375\n",
      "Policy Loss: -38.562599182128906\n",
      "Old Approx KL: 0.0017430612351745367\n",
      "Approx KL: 0.01071951724588871\n",
      "Clip Fraction: 0.3262362648279239\n",
      "Explained Variance: 0.004801750183105469\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 25\n",
      "Episodic Return: -7.4760003089904785\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 5239.32177734375\n",
      "Policy Loss: 44.47706985473633\n",
      "Old Approx KL: 0.07113883644342422\n",
      "Approx KL: 0.015301087871193886\n",
      "Clip Fraction: 0.33276099119430935\n",
      "Explained Variance: 0.007425248622894287\n",
      "\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training episode 26\n",
      "Episodic Return: -6.584000110626221\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 3576.08251953125\n",
      "Policy Loss: -34.164363861083984\n",
      "Old Approx KL: -0.032126106321811676\n",
      "Approx KL: 0.010374759323894978\n",
      "Clip Fraction: 0.29235348105430603\n",
      "Explained Variance: 0.011089205741882324\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 27\n",
      "Episodic Return: -5.988000392913818\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 9773.701171875\n",
      "Policy Loss: 36.202117919921875\n",
      "Old Approx KL: 0.04620013386011124\n",
      "Approx KL: 0.012902784161269665\n",
      "Clip Fraction: 0.37065018446017534\n",
      "Explained Variance: 0.004499197006225586\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 28\n",
      "Episodic Return: -5.5320000648498535\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 6750.55029296875\n",
      "Policy Loss: -94.01605987548828\n",
      "Old Approx KL: -0.0334811732172966\n",
      "Approx KL: 0.020203731954097748\n",
      "Clip Fraction: 0.4080815040148221\n",
      "Explained Variance: -0.00039374828338623047\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 29\n",
      "Episodic Return: -7.192000389099121\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 3072.56103515625\n",
      "Policy Loss: -30.888107299804688\n",
      "Old Approx KL: -0.01924610137939453\n",
      "Approx KL: 0.008168365806341171\n",
      "Clip Fraction: 0.42914377573208934\n",
      "Explained Variance: 0.0030092597007751465\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 30\n",
      "Episodic Return: -4.732000350952148\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 3772.212890625\n",
      "Policy Loss: -80.3261489868164\n",
      "Old Approx KL: -0.08193003386259079\n",
      "Approx KL: 0.013672071509063244\n",
      "Clip Fraction: 0.37992216302798343\n",
      "Explained Variance: -0.009430408477783203\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 31\n",
      "Episodic Return: -5.9120001792907715\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 6882.5908203125\n",
      "Policy Loss: 83.0429916381836\n",
      "Old Approx KL: 0.05780227854847908\n",
      "Approx KL: 0.019112247973680496\n",
      "Clip Fraction: 0.434180403367067\n",
      "Explained Variance: -0.003172755241394043\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 32\n",
      "Episodic Return: -6.724000453948975\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 15083.748046875\n",
      "Policy Loss: 144.1765594482422\n",
      "Old Approx KL: 0.14706094563007355\n",
      "Approx KL: 0.022920358926057816\n",
      "Clip Fraction: 0.40636447072029114\n",
      "Explained Variance: -0.00014472007751464844\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 33\n",
      "Episodic Return: -8.947999954223633\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 15784.35546875\n",
      "Policy Loss: 140.5497283935547\n",
      "Old Approx KL: 0.11166627705097198\n",
      "Approx KL: 0.016770262271165848\n",
      "Clip Fraction: 0.4979395637145409\n",
      "Explained Variance: 0.008851885795593262\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 34\n",
      "Episodic Return: -6.38800048828125\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 3086.001220703125\n",
      "Policy Loss: -37.33985137939453\n",
      "Old Approx KL: -0.02448132261633873\n",
      "Approx KL: 0.008474950678646564\n",
      "Clip Fraction: 0.3331043964777237\n",
      "Explained Variance: -0.014207243919372559\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 35\n",
      "Episodic Return: -9.039999961853027\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 21725.43359375\n",
      "Policy Loss: 171.53335571289062\n",
      "Old Approx KL: 0.08406714349985123\n",
      "Approx KL: 0.013075688853859901\n",
      "Clip Fraction: 0.43978937925436556\n",
      "Explained Variance: -0.0018516778945922852\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 36\n",
      "Episodic Return: -8.736000061035156\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 9413.0771484375\n",
      "Policy Loss: 109.30888366699219\n",
      "Old Approx KL: 0.08430474251508713\n",
      "Approx KL: 0.018183082342147827\n",
      "Clip Fraction: 0.45169414006746733\n",
      "Explained Variance: 0.0009672045707702637\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 37\n",
      "Episodic Return: -5.664000034332275\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 4629.8994140625\n",
      "Policy Loss: -90.37057495117188\n",
      "Old Approx KL: -0.030539104714989662\n",
      "Approx KL: 0.007569739129394293\n",
      "Clip Fraction: 0.31295787600370556\n",
      "Explained Variance: 0.004687786102294922\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 38\n",
      "Episodic Return: -6.3560004234313965\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 6899.5517578125\n",
      "Policy Loss: -11.603160858154297\n",
      "Old Approx KL: 0.029250308871269226\n",
      "Approx KL: 0.009846359491348267\n",
      "Clip Fraction: 0.2556089762693796\n",
      "Explained Variance: -0.001269221305847168\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 39\n",
      "Episodic Return: -5.428000450134277\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1706.11279296875\n",
      "Policy Loss: 3.3875820636749268\n",
      "Old Approx KL: 0.013680245727300644\n",
      "Approx KL: 0.004390721209347248\n",
      "Clip Fraction: 0.2071886454255153\n",
      "Explained Variance: 0.0025118589401245117\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 40\n",
      "Episodic Return: -3.9880001544952393\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 6249.3544921875\n",
      "Policy Loss: -104.49876403808594\n",
      "Old Approx KL: -0.02755158394575119\n",
      "Approx KL: 0.012478211894631386\n",
      "Clip Fraction: 0.3139880964389214\n",
      "Explained Variance: 0.0012614727020263672\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 41\n",
      "Episodic Return: -5.404000282287598\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 404.2340393066406\n",
      "Policy Loss: 17.65315818786621\n",
      "Old Approx KL: 0.021671704947948456\n",
      "Approx KL: 0.004002396948635578\n",
      "Clip Fraction: 0.2074175836184086\n",
      "Explained Variance: -0.01810932159423828\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 42\n",
      "Episodic Return: -6.13200044631958\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 5338.50927734375\n",
      "Policy Loss: 63.34181594848633\n",
      "Old Approx KL: 0.04602723568677902\n",
      "Approx KL: 0.009923156350851059\n",
      "Clip Fraction: 0.2853708809767014\n",
      "Explained Variance: -0.0012296438217163086\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 43\n",
      "Episodic Return: -6.708000183105469\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 8437.13671875\n",
      "Policy Loss: 98.0140151977539\n",
      "Old Approx KL: 0.09470751881599426\n",
      "Approx KL: 0.013406584039330482\n",
      "Clip Fraction: 0.38198260160592884\n",
      "Explained Variance: 0.0026915669441223145\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 44\n",
      "Episodic Return: -7.836000442504883\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 8395.779296875\n",
      "Policy Loss: 106.86428833007812\n",
      "Old Approx KL: 0.15018892288208008\n",
      "Approx KL: 0.01640957221388817\n",
      "Clip Fraction: 0.4586767424375583\n",
      "Explained Variance: -0.009226679801940918\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 45\n",
      "Episodic Return: -6.720000267028809\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 3763.813232421875\n",
      "Policy Loss: -41.653472900390625\n",
      "Old Approx KL: -0.04083174467086792\n",
      "Approx KL: 0.00865637045353651\n",
      "Clip Fraction: 0.29429945273277086\n",
      "Explained Variance: 0.002192080020904541\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 46\n",
      "Episodic Return: -6.332000255584717\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 784.0637817382812\n",
      "Policy Loss: -28.54836654663086\n",
      "Old Approx KL: -0.0771336555480957\n",
      "Approx KL: 0.005213686730712652\n",
      "Clip Fraction: 0.21096611825319436\n",
      "Explained Variance: -0.00412142276763916\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 47\n",
      "Episodic Return: -5.904000282287598\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1264.38525390625\n",
      "Policy Loss: -39.00265121459961\n",
      "Old Approx KL: -0.058257393538951874\n",
      "Approx KL: 0.006842643488198519\n",
      "Clip Fraction: 0.18257783964658394\n",
      "Explained Variance: 0.01310354471206665\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 48\n",
      "Episodic Return: -5.952000141143799\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 3347.711669921875\n",
      "Policy Loss: -24.056123733520508\n",
      "Old Approx KL: -0.003984102513641119\n",
      "Approx KL: 0.007167007774114609\n",
      "Clip Fraction: 0.2467948725590339\n",
      "Explained Variance: -0.0011960268020629883\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 49\n",
      "Episodic Return: -5.568000316619873\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1608.7115478515625\n",
      "Policy Loss: -33.75408172607422\n",
      "Old Approx KL: -0.02266017161309719\n",
      "Approx KL: 0.002845398150384426\n",
      "Clip Fraction: 0.1999771075370984\n",
      "Explained Variance: -0.0052040815353393555\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 50\n",
      "Episodic Return: -7.032000541687012\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 4311.3984375\n",
      "Policy Loss: 50.01023483276367\n",
      "Old Approx KL: 0.057229120284318924\n",
      "Approx KL: 0.014125926420092583\n",
      "Clip Fraction: 0.35451007443360794\n",
      "Explained Variance: -0.0002105236053466797\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 51\n",
      "Episodic Return: -6.504000186920166\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 6643.47216796875\n",
      "Policy Loss: 56.38579559326172\n",
      "Old Approx KL: 0.035681597888469696\n",
      "Approx KL: 0.013641800731420517\n",
      "Clip Fraction: 0.3898809544551067\n",
      "Explained Variance: -0.0006443262100219727\n",
      "\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training episode 52\n",
      "Episodic Return: -7.808000564575195\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 19422.357421875\n",
      "Policy Loss: 154.30563354492188\n",
      "Old Approx KL: 0.12420584261417389\n",
      "Approx KL: 0.026435546576976776\n",
      "Clip Fraction: 0.4693223467239967\n",
      "Explained Variance: 0.004492282867431641\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 53\n",
      "Episodic Return: -7.160000324249268\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 3318.99169921875\n",
      "Policy Loss: 69.24312591552734\n",
      "Old Approx KL: 0.04624566063284874\n",
      "Approx KL: 0.008942400105297565\n",
      "Clip Fraction: 0.4355540306140215\n",
      "Explained Variance: -0.002503514289855957\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 54\n",
      "Episodic Return: -4.760000228881836\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 4128.91015625\n",
      "Policy Loss: -53.21342468261719\n",
      "Old Approx KL: -0.0420396514236927\n",
      "Approx KL: 0.005599145777523518\n",
      "Clip Fraction: 0.300022895137469\n",
      "Explained Variance: -0.0005141496658325195\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 55\n",
      "Episodic Return: -6.672000408172607\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 11269.2763671875\n",
      "Policy Loss: 92.22066497802734\n",
      "Old Approx KL: 0.03011249005794525\n",
      "Approx KL: 0.031448911875486374\n",
      "Clip Fraction: 0.4413919448852539\n",
      "Explained Variance: 0.0029721856117248535\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 56\n",
      "Episodic Return: -5.13200044631958\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 3208.2880859375\n",
      "Policy Loss: -64.31645965576172\n",
      "Old Approx KL: -0.025008339434862137\n",
      "Approx KL: 0.0044525437988340855\n",
      "Clip Fraction: 0.23489011098177004\n",
      "Explained Variance: 0.0033074617385864258\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 57\n",
      "Episodic Return: -8.052000045776367\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 6561.59033203125\n",
      "Policy Loss: 100.21446228027344\n",
      "Old Approx KL: 0.161835715174675\n",
      "Approx KL: 0.021022947505116463\n",
      "Clip Fraction: 0.4442536662786435\n",
      "Explained Variance: 0.0012645721435546875\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 58\n",
      "Episodic Return: -6.284000396728516\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 3076.9521484375\n",
      "Policy Loss: -50.75452423095703\n",
      "Old Approx KL: -0.010643082670867443\n",
      "Approx KL: 0.008410466834902763\n",
      "Clip Fraction: 0.27220696134444994\n",
      "Explained Variance: 0.0064487457275390625\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 59\n",
      "Episodic Return: -7.068000316619873\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 3585.07666015625\n",
      "Policy Loss: -18.913352966308594\n",
      "Old Approx KL: -0.05332733318209648\n",
      "Approx KL: 0.013033760711550713\n",
      "Clip Fraction: 0.3218864481418561\n",
      "Explained Variance: 0.011917650699615479\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 60\n",
      "Episodic Return: -4.4160003662109375\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 3392.305419921875\n",
      "Policy Loss: -77.15083312988281\n",
      "Old Approx KL: -0.08330009877681732\n",
      "Approx KL: 0.008486245758831501\n",
      "Clip Fraction: 0.3518772912331117\n",
      "Explained Variance: -0.011350274085998535\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 61\n",
      "Episodic Return: -3.9680001735687256\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 2209.36083984375\n",
      "Policy Loss: -50.64043426513672\n",
      "Old Approx KL: -0.07838872075080872\n",
      "Approx KL: 0.010421535931527615\n",
      "Clip Fraction: 0.3317307715232556\n",
      "Explained Variance: 0.007969796657562256\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 62\n",
      "Episodic Return: -4.800000190734863\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1232.881591796875\n",
      "Policy Loss: -30.301362991333008\n",
      "Old Approx KL: 0.01161088328808546\n",
      "Approx KL: 0.01547856442630291\n",
      "Clip Fraction: 0.27850274856273943\n",
      "Explained Variance: -0.011907815933227539\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 63\n",
      "Episodic Return: -5.396000385284424\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 804.7020263671875\n",
      "Policy Loss: -10.877559661865234\n",
      "Old Approx KL: -0.05034633353352547\n",
      "Approx KL: 0.0052995216101408005\n",
      "Clip Fraction: 0.24690934194204134\n",
      "Explained Variance: -0.0037474632263183594\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 64\n",
      "Episodic Return: -5.124000072479248\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 2026.701416015625\n",
      "Policy Loss: -7.2804365158081055\n",
      "Old Approx KL: -0.027887780219316483\n",
      "Approx KL: 0.014173687435686588\n",
      "Clip Fraction: 0.349816851126842\n",
      "Explained Variance: -0.010216832160949707\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 65\n",
      "Episodic Return: -6.204000473022461\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 3268.819091796875\n",
      "Policy Loss: 65.08531188964844\n",
      "Old Approx KL: 0.11261467635631561\n",
      "Approx KL: 0.014915922656655312\n",
      "Clip Fraction: 0.3332188668159338\n",
      "Explained Variance: 0.0035477876663208008\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 66\n",
      "Episodic Return: -5.624000072479248\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 4181.1064453125\n",
      "Policy Loss: -23.497411727905273\n",
      "Old Approx KL: -0.01603831723332405\n",
      "Approx KL: 0.022232912480831146\n",
      "Clip Fraction: 0.3646978048177866\n",
      "Explained Variance: -0.01580989360809326\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 67\n",
      "Episodic Return: -5.312000274658203\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1326.3953857421875\n",
      "Policy Loss: -7.853414535522461\n",
      "Old Approx KL: 0.024064116179943085\n",
      "Approx KL: 0.0078818891197443\n",
      "Clip Fraction: 0.31181318752276593\n",
      "Explained Variance: -0.004960298538208008\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 68\n",
      "Episodic Return: -4.004000186920166\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 2219.779052734375\n",
      "Policy Loss: -62.939029693603516\n",
      "Old Approx KL: -0.0854581668972969\n",
      "Approx KL: 0.008012469857931137\n",
      "Clip Fraction: 0.3288690482194607\n",
      "Explained Variance: 0.007655501365661621\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 69\n",
      "Episodic Return: -6.844000339508057\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 6706.1435546875\n",
      "Policy Loss: 65.86016082763672\n",
      "Old Approx KL: 0.08126025646924973\n",
      "Approx KL: 0.015350270085036755\n",
      "Clip Fraction: 0.43086080692517453\n",
      "Explained Variance: -0.027831077575683594\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 70\n",
      "Episodic Return: -7.948000431060791\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 12315.728515625\n",
      "Policy Loss: 74.20068359375\n",
      "Old Approx KL: 0.14289918541908264\n",
      "Approx KL: 0.024858761578798294\n",
      "Clip Fraction: 0.5687957879824516\n",
      "Explained Variance: 0.006516695022583008\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 71\n",
      "Episodic Return: -3.6040000915527344\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 5258.51025390625\n",
      "Policy Loss: -100.10906219482422\n",
      "Old Approx KL: -0.1026255264878273\n",
      "Approx KL: 0.014815722592175007\n",
      "Clip Fraction: 0.42456501951584447\n",
      "Explained Variance: 0.0035170912742614746\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 72\n",
      "Episodic Return: -7.36400032043457\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 11986.1318359375\n",
      "Policy Loss: 118.23933410644531\n",
      "Old Approx KL: 0.2894715368747711\n",
      "Approx KL: 0.04750054329633713\n",
      "Clip Fraction: 0.5863095262111762\n",
      "Explained Variance: 0.012275159358978271\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 73\n",
      "Episodic Return: -3.7680001258850098\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 4530.20263671875\n",
      "Policy Loss: -88.10810089111328\n",
      "Old Approx KL: -0.11656169593334198\n",
      "Approx KL: 0.03483932837843895\n",
      "Clip Fraction: 0.4250228947553879\n",
      "Explained Variance: -0.0032602548599243164\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 74\n",
      "Episodic Return: -5.336000442504883\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 2794.0478515625\n",
      "Policy Loss: 32.93072509765625\n",
      "Old Approx KL: 0.04848643019795418\n",
      "Approx KL: 0.015987157821655273\n",
      "Clip Fraction: 0.31593406658906203\n",
      "Explained Variance: 0.007243514060974121\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 75\n",
      "Episodic Return: -4.984000205993652\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 4316.900390625\n",
      "Policy Loss: -62.05754470825195\n",
      "Old Approx KL: -0.058102015405893326\n",
      "Approx KL: 0.011391074396669865\n",
      "Clip Fraction: 0.32257326138325226\n",
      "Explained Variance: -0.02961146831512451\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 76\n",
      "Episodic Return: -5.688000202178955\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1748.6798095703125\n",
      "Policy Loss: -8.355494499206543\n",
      "Old Approx KL: -0.010498634539544582\n",
      "Approx KL: 0.012017658911645412\n",
      "Clip Fraction: 0.34100274932690156\n",
      "Explained Variance: 0.005735039710998535\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 77\n",
      "Episodic Return: -6.316000461578369\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 2433.76611328125\n",
      "Policy Loss: 2.608690023422241\n",
      "Old Approx KL: -0.0451953262090683\n",
      "Approx KL: 0.017617864534258842\n",
      "Clip Fraction: 0.24908424990299421\n",
      "Explained Variance: 0.002379000186920166\n",
      "\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training episode 78\n",
      "Episodic Return: -4.604000091552734\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 12623.2685546875\n",
      "Policy Loss: -149.57144165039062\n",
      "Old Approx KL: -0.2860981523990631\n",
      "Approx KL: 0.1553158164024353\n",
      "Clip Fraction: 0.5005723467239966\n",
      "Explained Variance: -0.007363557815551758\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 79\n",
      "Episodic Return: -6.372000217437744\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 5359.47021484375\n",
      "Policy Loss: 50.304264068603516\n",
      "Old Approx KL: 0.0940658375620842\n",
      "Approx KL: 0.02214549295604229\n",
      "Clip Fraction: 0.48019688863020676\n",
      "Explained Variance: -0.0038111209869384766\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 80\n",
      "Episodic Return: -6.868000507354736\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 6877.2021484375\n",
      "Policy Loss: 106.48084259033203\n",
      "Old Approx KL: 0.13412266969680786\n",
      "Approx KL: 0.01370516512542963\n",
      "Clip Fraction: 0.4605082441598941\n",
      "Explained Variance: -0.0018982887268066406\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 81\n",
      "Episodic Return: -6.924000263214111\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1784.291015625\n",
      "Policy Loss: 32.591766357421875\n",
      "Old Approx KL: -0.0005783694214187562\n",
      "Approx KL: 0.007189840544015169\n",
      "Clip Fraction: 0.31318681553388256\n",
      "Explained Variance: 0.010306775569915771\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 82\n",
      "Episodic Return: -5.008000373840332\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 6808.91552734375\n",
      "Policy Loss: -110.61463165283203\n",
      "Old Approx KL: -0.08571121841669083\n",
      "Approx KL: 0.02389170043170452\n",
      "Clip Fraction: 0.4695512835796063\n",
      "Explained Variance: 0.01427757740020752\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 83\n",
      "Episodic Return: -6.724000453948975\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 6840.568359375\n",
      "Policy Loss: 81.94351959228516\n",
      "Old Approx KL: 0.1838659644126892\n",
      "Approx KL: 0.03689108043909073\n",
      "Clip Fraction: 0.492673994638981\n",
      "Explained Variance: -0.010658860206604004\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 84\n",
      "Episodic Return: -5.37600040435791\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1234.041015625\n",
      "Policy Loss: -23.806907653808594\n",
      "Old Approx KL: -0.0007969226571731269\n",
      "Approx KL: 0.006061000749468803\n",
      "Clip Fraction: 0.27392399330169726\n",
      "Explained Variance: -0.001649022102355957\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 85\n",
      "Episodic Return: -7.884000301361084\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 824.7112426757812\n",
      "Policy Loss: 29.154359817504883\n",
      "Old Approx KL: 0.06605168431997299\n",
      "Approx KL: 0.005296043120324612\n",
      "Clip Fraction: 0.4043040306140215\n",
      "Explained Variance: 0.0002232193946838379\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 86\n",
      "Episodic Return: -5.884000301361084\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 2206.915771484375\n",
      "Policy Loss: -50.341976165771484\n",
      "Old Approx KL: -0.06900910288095474\n",
      "Approx KL: 0.017443014308810234\n",
      "Clip Fraction: 0.2921245434345343\n",
      "Explained Variance: -0.0008553266525268555\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 87\n",
      "Episodic Return: -6.28000020980835\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1168.94775390625\n",
      "Policy Loss: 1.3304874897003174\n",
      "Old Approx KL: 0.03194204717874527\n",
      "Approx KL: 0.0049751573242247105\n",
      "Clip Fraction: 0.2513736272469545\n",
      "Explained Variance: -0.006449341773986816\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 88\n",
      "Episodic Return: -5.724000453948975\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1436.4964599609375\n",
      "Policy Loss: -28.838642120361328\n",
      "Old Approx KL: -0.045240677893161774\n",
      "Approx KL: 0.0052477167919278145\n",
      "Clip Fraction: 0.2511446896271828\n",
      "Explained Variance: -0.020436525344848633\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 89\n",
      "Episodic Return: -8.568000793457031\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 11505.7978515625\n",
      "Policy Loss: 116.18562316894531\n",
      "Old Approx KL: 0.18307752907276154\n",
      "Approx KL: 0.06508823484182358\n",
      "Clip Fraction: 0.5784111733619983\n",
      "Explained Variance: 0.0062596797943115234\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 90\n",
      "Episodic Return: -7.200000286102295\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1184.2113037109375\n",
      "Policy Loss: 28.475847244262695\n",
      "Old Approx KL: 0.07679303735494614\n",
      "Approx KL: 0.006677721627056599\n",
      "Clip Fraction: 0.3802655686934789\n",
      "Explained Variance: -0.003454923629760742\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 91\n",
      "Episodic Return: -5.560000419616699\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 6445.634765625\n",
      "Policy Loss: -100.38157653808594\n",
      "Old Approx KL: -0.10927993804216385\n",
      "Approx KL: 0.011762125417590141\n",
      "Clip Fraction: 0.3983516486791464\n",
      "Explained Variance: -0.0010390281677246094\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 92\n",
      "Episodic Return: -5.232000350952148\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 958.161865234375\n",
      "Policy Loss: -21.927579879760742\n",
      "Old Approx KL: -0.03877638280391693\n",
      "Approx KL: 0.009424529038369656\n",
      "Clip Fraction: 0.28811813241396195\n",
      "Explained Variance: 0.0014206767082214355\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 93\n",
      "Episodic Return: -4.716000080108643\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 4113.72998046875\n",
      "Policy Loss: -72.53736114501953\n",
      "Old Approx KL: -0.08245078474283218\n",
      "Approx KL: 0.010070201009511948\n",
      "Clip Fraction: 0.3056318687322812\n",
      "Explained Variance: -0.007037043571472168\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 94\n",
      "Episodic Return: -5.436000347137451\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 2931.820556640625\n",
      "Policy Loss: 14.37700366973877\n",
      "Old Approx KL: 0.016295935958623886\n",
      "Approx KL: 0.013192964717745781\n",
      "Clip Fraction: 0.35485348181846815\n",
      "Explained Variance: 0.004161417484283447\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 95\n",
      "Episodic Return: -5.900000095367432\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 9003.1376953125\n",
      "Policy Loss: 28.319826126098633\n",
      "Old Approx KL: 0.01877545565366745\n",
      "Approx KL: 0.013742332346737385\n",
      "Clip Fraction: 0.4591346161487775\n",
      "Explained Variance: -0.007450461387634277\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 96\n",
      "Episodic Return: -5.044000148773193\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 2452.7724609375\n",
      "Policy Loss: 27.79425048828125\n",
      "Old Approx KL: 0.08943735808134079\n",
      "Approx KL: 0.018328774720430374\n",
      "Clip Fraction: 0.3065476192113681\n",
      "Explained Variance: -0.001590728759765625\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 97\n",
      "Episodic Return: -4.456000328063965\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1917.047119140625\n",
      "Policy Loss: -45.40797805786133\n",
      "Old Approx KL: -0.09482662379741669\n",
      "Approx KL: 0.014194497838616371\n",
      "Clip Fraction: 0.29647435935644\n",
      "Explained Variance: 0.004264771938323975\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 98\n",
      "Episodic Return: -5.064000129699707\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1562.9925537109375\n",
      "Policy Loss: -7.1501851081848145\n",
      "Old Approx KL: 0.031812090426683426\n",
      "Approx KL: 0.005615839269012213\n",
      "Clip Fraction: 0.47126831610997516\n",
      "Explained Variance: 0.005067110061645508\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 99\n",
      "Episodic Return: -5.488000392913818\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1970.3868408203125\n",
      "Policy Loss: 25.33196258544922\n",
      "Old Approx KL: 0.06857341527938843\n",
      "Approx KL: 0.01608293130993843\n",
      "Clip Fraction: 0.3226877298110571\n",
      "Explained Variance: -0.017377734184265137\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 100\n",
      "Episodic Return: -4.628000259399414\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1197.74169921875\n",
      "Policy Loss: -11.920467376708984\n",
      "Old Approx KL: -0.014570952393114567\n",
      "Approx KL: 0.0068947081454098225\n",
      "Clip Fraction: 0.20592948870781141\n",
      "Explained Variance: -0.004460692405700684\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 101\n",
      "Episodic Return: -5.904000282287598\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 11496.91796875\n",
      "Policy Loss: -75.93505096435547\n",
      "Old Approx KL: -0.08617325127124786\n",
      "Approx KL: 0.018497055396437645\n",
      "Clip Fraction: 0.49095696210861206\n",
      "Explained Variance: -0.0008391141891479492\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 102\n",
      "Episodic Return: -3.508000135421753\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 2619.088623046875\n",
      "Policy Loss: -71.92292022705078\n",
      "Old Approx KL: -0.09670327603816986\n",
      "Approx KL: 0.010181095451116562\n",
      "Clip Fraction: 0.3328754596221141\n",
      "Explained Variance: 0.006274104118347168\n",
      "\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training episode 103\n",
      "Episodic Return: -4.4079999923706055\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1284.5731201171875\n",
      "Policy Loss: 6.077377796173096\n",
      "Old Approx KL: 0.038817502558231354\n",
      "Approx KL: 0.0304816123098135\n",
      "Clip Fraction: 0.34684066206980974\n",
      "Explained Variance: -0.0047866106033325195\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 104\n",
      "Episodic Return: -5.832000255584717\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 2934.02001953125\n",
      "Policy Loss: 50.58412170410156\n",
      "Old Approx KL: 0.08832858502864838\n",
      "Approx KL: 0.01999724470078945\n",
      "Clip Fraction: 0.34706959892541933\n",
      "Explained Variance: -0.0021696090698242188\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 105\n",
      "Episodic Return: -4.860000133514404\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 533.8305053710938\n",
      "Policy Loss: -0.8403636813163757\n",
      "Old Approx KL: 0.003729607444256544\n",
      "Approx KL: 0.0042157769203186035\n",
      "Clip Fraction: 0.19619963451837882\n",
      "Explained Variance: 0.014272034168243408\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 106\n",
      "Episodic Return: -5.3560004234313965\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 4050.41650390625\n",
      "Policy Loss: 40.78437805175781\n",
      "Old Approx KL: 0.1894935965538025\n",
      "Approx KL: 0.046662621200084686\n",
      "Clip Fraction: 0.41597985457151365\n",
      "Explained Variance: 0.010302901268005371\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 107\n",
      "Episodic Return: -5.324000358581543\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 3234.429443359375\n",
      "Policy Loss: 44.79979705810547\n",
      "Old Approx KL: 0.1249009519815445\n",
      "Approx KL: 0.025586124509572983\n",
      "Clip Fraction: 0.40785256715921253\n",
      "Explained Variance: -0.001982450485229492\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 108\n",
      "Episodic Return: -5.148000240325928\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 2813.677001953125\n",
      "Policy Loss: 9.86670207977295\n",
      "Old Approx KL: 0.045566312968730927\n",
      "Approx KL: 0.015373699367046356\n",
      "Clip Fraction: 0.3948031159547659\n",
      "Explained Variance: -0.006735682487487793\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 109\n",
      "Episodic Return: -4.4760003089904785\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1898.8232421875\n",
      "Policy Loss: 5.381931781768799\n",
      "Old Approx KL: 0.015302522107958794\n",
      "Approx KL: 0.009545667096972466\n",
      "Clip Fraction: 0.33516483620191234\n",
      "Explained Variance: 0.011525630950927734\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 110\n",
      "Episodic Return: -6.284000396728516\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 2462.581787109375\n",
      "Policy Loss: 57.252288818359375\n",
      "Old Approx KL: 0.1192627027630806\n",
      "Approx KL: 0.015264899469912052\n",
      "Clip Fraction: 0.45146520359393877\n",
      "Explained Variance: -0.005722165107727051\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 111\n",
      "Episodic Return: -4.1080002784729\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 4609.26171875\n",
      "Policy Loss: -89.19507598876953\n",
      "Old Approx KL: -0.06348728388547897\n",
      "Approx KL: 0.01615031436085701\n",
      "Clip Fraction: 0.46016483620191234\n",
      "Explained Variance: 0.0004876852035522461\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 112\n",
      "Episodic Return: -5.464000225067139\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1265.5546875\n",
      "Policy Loss: 31.152780532836914\n",
      "Old Approx KL: 0.06792619824409485\n",
      "Approx KL: 0.006522608920931816\n",
      "Clip Fraction: 0.2870879142712324\n",
      "Explained Variance: -0.029458999633789062\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 113\n",
      "Episodic Return: -3.7960002422332764\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1781.7861328125\n",
      "Policy Loss: -47.59022903442383\n",
      "Old Approx KL: -0.05105188116431236\n",
      "Approx KL: 0.009760376065969467\n",
      "Clip Fraction: 0.27529762035761124\n",
      "Explained Variance: 0.013566851615905762\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 114\n",
      "Episodic Return: -5.164000034332275\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 273.67657470703125\n",
      "Policy Loss: -0.11421708017587662\n",
      "Old Approx KL: -0.02131761983036995\n",
      "Approx KL: 0.0009921917226165533\n",
      "Clip Fraction: 0.30643315116564435\n",
      "Explained Variance: 0.01614171266555786\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 115\n",
      "Episodic Return: -5.5320000648498535\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 2162.5146484375\n",
      "Policy Loss: 28.407127380371094\n",
      "Old Approx KL: 0.08487942069768906\n",
      "Approx KL: 0.010657698847353458\n",
      "Clip Fraction: 0.3547390128175418\n",
      "Explained Variance: 0.013599276542663574\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 116\n",
      "Episodic Return: -4.072000026702881\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 895.4035034179688\n",
      "Policy Loss: -31.61247444152832\n",
      "Old Approx KL: -0.034805621951818466\n",
      "Approx KL: 0.003010596614331007\n",
      "Clip Fraction: 0.2813644703382101\n",
      "Explained Variance: -0.02379786968231201\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 117\n",
      "Episodic Return: -5.8560004234313965\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 3595.5224609375\n",
      "Policy Loss: 57.367164611816406\n",
      "Old Approx KL: 0.19657176733016968\n",
      "Approx KL: 0.02328191138803959\n",
      "Clip Fraction: 0.47573260160592884\n",
      "Explained Variance: 0.003725290298461914\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 118\n",
      "Episodic Return: -5.2960004806518555\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1453.295654296875\n",
      "Policy Loss: 23.66814422607422\n",
      "Old Approx KL: 0.06904838234186172\n",
      "Approx KL: 0.009412203915417194\n",
      "Clip Fraction: 0.30711996440704054\n",
      "Explained Variance: 0.008324980735778809\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 119\n",
      "Episodic Return: -3.5480000972747803\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 2454.708251953125\n",
      "Policy Loss: -67.16129302978516\n",
      "Old Approx KL: -0.11253397166728973\n",
      "Approx KL: 0.011414626613259315\n",
      "Clip Fraction: 0.3823260091818296\n",
      "Explained Variance: -0.02047431468963623\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 120\n",
      "Episodic Return: -3.764000177383423\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 698.9700927734375\n",
      "Policy Loss: -33.52709197998047\n",
      "Old Approx KL: -0.07354406267404556\n",
      "Approx KL: 0.007777550723403692\n",
      "Clip Fraction: 0.2131410275514309\n",
      "Explained Variance: -0.006645917892456055\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 121\n",
      "Episodic Return: -3.7080001831054688\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 2973.781494140625\n",
      "Policy Loss: -25.60609245300293\n",
      "Old Approx KL: -0.03619885444641113\n",
      "Approx KL: 0.016685746610164642\n",
      "Clip Fraction: 0.37751831610997516\n",
      "Explained Variance: -0.0073506832122802734\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 122\n",
      "Episodic Return: -4.452000141143799\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 663.7908935546875\n",
      "Policy Loss: 18.066320419311523\n",
      "Old Approx KL: 0.08605740964412689\n",
      "Approx KL: 0.0070592379197478294\n",
      "Clip Fraction: 0.22527472655742597\n",
      "Explained Variance: 0.0016556382179260254\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 123\n",
      "Episodic Return: -4.048000335693359\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 615.2122192382812\n",
      "Policy Loss: -22.21607208251953\n",
      "Old Approx KL: -0.05295979604125023\n",
      "Approx KL: 0.014479833655059338\n",
      "Clip Fraction: 0.27987637428136974\n",
      "Explained Variance: -0.009735465049743652\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 124\n",
      "Episodic Return: -2.944000244140625\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1954.2955322265625\n",
      "Policy Loss: -57.56980895996094\n",
      "Old Approx KL: -0.05314076319336891\n",
      "Approx KL: 0.007921380922198296\n",
      "Clip Fraction: 0.40041208878541606\n",
      "Explained Variance: -0.012264132499694824\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 125\n",
      "Episodic Return: -2.696000099182129\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1226.917724609375\n",
      "Policy Loss: -49.487770080566406\n",
      "Old Approx KL: -0.10298889130353928\n",
      "Approx KL: 0.01005549542605877\n",
      "Clip Fraction: 0.3482142858780347\n",
      "Explained Variance: -0.0330280065536499\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 126\n",
      "Episodic Return: -3.196000099182129\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 829.9094848632812\n",
      "Policy Loss: -7.137767791748047\n",
      "Old Approx KL: -0.0006745883729308844\n",
      "Approx KL: 0.003710908815264702\n",
      "Clip Fraction: 0.21657509223008767\n",
      "Explained Variance: -0.033957600593566895\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 127\n",
      "Episodic Return: -5.5400004386901855\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 9206.634765625\n",
      "Policy Loss: 113.70426940917969\n",
      "Old Approx KL: 0.2191888391971588\n",
      "Approx KL: 0.036050327122211456\n",
      "Clip Fraction: 0.5388049468016013\n",
      "Explained Variance: 0.010431408882141113\n",
      "\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training episode 128\n",
      "Episodic Return: -3.9200000762939453\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 3573.639404296875\n",
      "Policy Loss: -55.365386962890625\n",
      "Old Approx KL: -0.0011268258094787598\n",
      "Approx KL: 0.01001429557800293\n",
      "Clip Fraction: 0.33459249215248305\n",
      "Explained Variance: -0.009222030639648438\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 129\n",
      "Episodic Return: -4.648000240325928\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 2963.62451171875\n",
      "Policy Loss: 32.81934356689453\n",
      "Old Approx KL: 0.14453071355819702\n",
      "Approx KL: 0.01817890629172325\n",
      "Clip Fraction: 0.4758470730903821\n",
      "Explained Variance: -0.008554458618164062\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 130\n",
      "Episodic Return: -4.516000270843506\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 2468.075439453125\n",
      "Policy Loss: 47.795536041259766\n",
      "Old Approx KL: 0.0493476577103138\n",
      "Approx KL: 0.02597481571137905\n",
      "Clip Fraction: 0.4174679502462729\n",
      "Explained Variance: 0.0013760924339294434\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 131\n",
      "Episodic Return: -5.0320000648498535\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 2332.60498046875\n",
      "Policy Loss: 29.00930404663086\n",
      "Old Approx KL: 0.07200273126363754\n",
      "Approx KL: 0.0146928820759058\n",
      "Clip Fraction: 0.37374084423749876\n",
      "Explained Variance: -0.013113617897033691\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 132\n",
      "Episodic Return: -3.436000108718872\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 2565.92626953125\n",
      "Policy Loss: -65.8763427734375\n",
      "Old Approx KL: -0.055178526788949966\n",
      "Approx KL: 0.011964279226958752\n",
      "Clip Fraction: 0.35370879371960956\n",
      "Explained Variance: 0.0049114227294921875\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 133\n",
      "Episodic Return: -3.4040000438690186\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 913.42529296875\n",
      "Policy Loss: -28.14995574951172\n",
      "Old Approx KL: -0.015216777101159096\n",
      "Approx KL: 0.01134320255368948\n",
      "Clip Fraction: 0.2627060442016675\n",
      "Explained Variance: -0.006384730339050293\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 134\n",
      "Episodic Return: -4.544000148773193\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1932.7764892578125\n",
      "Policy Loss: 34.517127990722656\n",
      "Old Approx KL: 0.061961159110069275\n",
      "Approx KL: 0.00802767276763916\n",
      "Clip Fraction: 0.38003663145578825\n",
      "Explained Variance: 0.009752810001373291\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 135\n",
      "Episodic Return: -5.688000202178955\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 5558.48681640625\n",
      "Policy Loss: 74.67772674560547\n",
      "Old Approx KL: 0.16423872113227844\n",
      "Approx KL: 0.08334240317344666\n",
      "Clip Fraction: 0.4805402954419454\n",
      "Explained Variance: 0.014038681983947754\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 136\n",
      "Episodic Return: -4.672000408172607\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1617.87646484375\n",
      "Policy Loss: -18.039363861083984\n",
      "Old Approx KL: -0.021550187841057777\n",
      "Approx KL: 0.013426129706203938\n",
      "Clip Fraction: 0.33791208878541606\n",
      "Explained Variance: 0.014701902866363525\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 137\n",
      "Episodic Return: -4.784000396728516\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 655.257080078125\n",
      "Policy Loss: 4.656584739685059\n",
      "Old Approx KL: -0.00030383895500563085\n",
      "Approx KL: 0.008484194055199623\n",
      "Clip Fraction: 0.2937271067729363\n",
      "Explained Variance: -0.014516234397888184\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 138\n",
      "Episodic Return: -6.104000091552734\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1699.078369140625\n",
      "Policy Loss: 6.617559909820557\n",
      "Old Approx KL: -0.04118280112743378\n",
      "Approx KL: 0.00945769902318716\n",
      "Clip Fraction: 0.45982142977225476\n",
      "Explained Variance: -0.003705620765686035\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 139\n",
      "Episodic Return: -3.2760002613067627\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 3909.523681640625\n",
      "Policy Loss: -43.17918395996094\n",
      "Old Approx KL: 0.023463208228349686\n",
      "Approx KL: 0.06094498187303543\n",
      "Clip Fraction: 0.4159798553356758\n",
      "Explained Variance: 0.0031815767288208008\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 140\n",
      "Episodic Return: -4.548000335693359\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 2405.392578125\n",
      "Policy Loss: 34.3000373840332\n",
      "Old Approx KL: 0.031474389135837555\n",
      "Approx KL: 0.019634656608104706\n",
      "Clip Fraction: 0.2921245438166154\n",
      "Explained Variance: 0.00690150260925293\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 141\n",
      "Episodic Return: -6.100000381469727\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 8963.396484375\n",
      "Policy Loss: 93.77104949951172\n",
      "Old Approx KL: 0.09732133895158768\n",
      "Approx KL: 0.02615535818040371\n",
      "Clip Fraction: 0.5209478040536245\n",
      "Explained Variance: 0.00889045000076294\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 142\n",
      "Episodic Return: -5.064000129699707\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1133.502685546875\n",
      "Policy Loss: 32.551910400390625\n",
      "Old Approx KL: 0.05414698272943497\n",
      "Approx KL: 0.011748255230486393\n",
      "Clip Fraction: 0.3858745434345343\n",
      "Explained Variance: 0.006172299385070801\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 143\n",
      "Episodic Return: -5.584000110626221\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 2775.954833984375\n",
      "Policy Loss: 15.789685249328613\n",
      "Old Approx KL: 0.03621160238981247\n",
      "Approx KL: 0.016208399087190628\n",
      "Clip Fraction: 0.3494734450792655\n",
      "Explained Variance: 0.016624271869659424\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 144\n",
      "Episodic Return: -4.584000110626221\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1268.060546875\n",
      "Policy Loss: -1.4278892278671265\n",
      "Old Approx KL: -0.004419488832354546\n",
      "Approx KL: 0.007044375408440828\n",
      "Clip Fraction: 0.3925137374645624\n",
      "Explained Variance: -0.0046149492263793945\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 145\n",
      "Episodic Return: -5.456000328063965\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 697.9564819335938\n",
      "Policy Loss: 17.42873191833496\n",
      "Old Approx KL: 0.06598710268735886\n",
      "Approx KL: 0.0062666707672178745\n",
      "Clip Fraction: 0.2477106234202018\n",
      "Explained Variance: -0.01767253875732422\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 146\n",
      "Episodic Return: -5.448000431060791\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 999.0947265625\n",
      "Policy Loss: 27.641822814941406\n",
      "Old Approx KL: 0.04537181556224823\n",
      "Approx KL: 0.005481102969497442\n",
      "Clip Fraction: 0.22424450593116957\n",
      "Explained Variance: 0.023289859294891357\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 147\n",
      "Episodic Return: -4.052000045776367\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1391.389892578125\n",
      "Policy Loss: -43.2662467956543\n",
      "Old Approx KL: -0.0761500746011734\n",
      "Approx KL: 0.008215985260903835\n",
      "Clip Fraction: 0.2769001842691348\n",
      "Explained Variance: 0.008040547370910645\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 148\n",
      "Episodic Return: -3.7840001583099365\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 4913.2548828125\n",
      "Policy Loss: -76.46280670166016\n",
      "Old Approx KL: -0.12564417719841003\n",
      "Approx KL: 0.024438323453068733\n",
      "Clip Fraction: 0.3883928595445095\n",
      "Explained Variance: -0.0076673030853271484\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 149\n",
      "Episodic Return: -4.064000129699707\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 728.3429565429688\n",
      "Policy Loss: -2.7506916522979736\n",
      "Old Approx KL: 0.022856976836919785\n",
      "Approx KL: 0.011866600252687931\n",
      "Clip Fraction: 0.23820970761470306\n",
      "Explained Variance: 0.01638108491897583\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 150\n",
      "Episodic Return: -4.628000259399414\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 516.9949340820312\n",
      "Policy Loss: -3.322136163711548\n",
      "Old Approx KL: -0.016674596816301346\n",
      "Approx KL: 0.005177340470254421\n",
      "Clip Fraction: 0.20249542192770884\n",
      "Explained Variance: -0.01420295238494873\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 151\n",
      "Episodic Return: -3.4640002250671387\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 716.0075073242188\n",
      "Policy Loss: -26.971742630004883\n",
      "Old Approx KL: -0.03100196085870266\n",
      "Approx KL: 0.009560172446072102\n",
      "Clip Fraction: 0.27735805931763774\n",
      "Explained Variance: -0.029905200004577637\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 152\n",
      "Episodic Return: -3.7800002098083496\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 504.824462890625\n",
      "Policy Loss: -11.846704483032227\n",
      "Old Approx KL: 0.03627214580774307\n",
      "Approx KL: 0.002151927910745144\n",
      "Clip Fraction: 0.19150641082953185\n",
      "Explained Variance: -0.026221871376037598\n",
      "\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training episode 153\n",
      "Episodic Return: -5.88800048828125\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 7576.42333984375\n",
      "Policy Loss: 101.3913803100586\n",
      "Old Approx KL: 0.17155934870243073\n",
      "Approx KL: 0.036002710461616516\n",
      "Clip Fraction: 0.5700549483299255\n",
      "Explained Variance: -0.0011593103408813477\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 154\n",
      "Episodic Return: -4.212000370025635\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1649.1275634765625\n",
      "Policy Loss: 14.579275131225586\n",
      "Old Approx KL: 0.09604661166667938\n",
      "Approx KL: 0.015752797946333885\n",
      "Clip Fraction: 0.318566851126842\n",
      "Explained Variance: 0.016584038734436035\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 155\n",
      "Episodic Return: -5.644000053405762\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 4755.97998046875\n",
      "Policy Loss: 57.01995086669922\n",
      "Old Approx KL: 0.035743750631809235\n",
      "Approx KL: 0.016276288777589798\n",
      "Clip Fraction: 0.44837454496285856\n",
      "Explained Variance: -0.0030862092971801758\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 156\n",
      "Episodic Return: -5.368000030517578\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 4007.629638671875\n",
      "Policy Loss: -6.564758777618408\n",
      "Old Approx KL: 0.11383483558893204\n",
      "Approx KL: 0.025007309392094612\n",
      "Clip Fraction: 0.4405906613056476\n",
      "Explained Variance: -0.004377245903015137\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 157\n",
      "Episodic Return: -4.63200044631958\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 2795.799072265625\n",
      "Policy Loss: -55.52799987792969\n",
      "Old Approx KL: 0.001552632893435657\n",
      "Approx KL: 0.013874433934688568\n",
      "Clip Fraction: 0.3300137374645624\n",
      "Explained Variance: 0.010953009128570557\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 158\n",
      "Episodic Return: -5.664000034332275\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 3238.929443359375\n",
      "Policy Loss: 50.5676155090332\n",
      "Old Approx KL: 0.04455626383423805\n",
      "Approx KL: 0.02068127505481243\n",
      "Clip Fraction: 0.4081959732067891\n",
      "Explained Variance: 0.008503139019012451\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 159\n",
      "Episodic Return: -5.260000228881836\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 961.8468627929688\n",
      "Policy Loss: 30.35526466369629\n",
      "Old Approx KL: 0.10818786174058914\n",
      "Approx KL: 0.009321639314293861\n",
      "Clip Fraction: 0.42055861002359635\n",
      "Explained Variance: -0.0034346580505371094\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 160\n",
      "Episodic Return: -6.428000450134277\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 7274.71630859375\n",
      "Policy Loss: 92.79267120361328\n",
      "Old Approx KL: 0.19974641501903534\n",
      "Approx KL: 0.03717835247516632\n",
      "Clip Fraction: 0.46726190738188916\n",
      "Explained Variance: 0.0022905468940734863\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 161\n",
      "Episodic Return: -5.4160003662109375\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 6462.93212890625\n",
      "Policy Loss: -62.64643478393555\n",
      "Old Approx KL: -0.024501843377947807\n",
      "Approx KL: 0.019433166831731796\n",
      "Clip Fraction: 0.48408883045881224\n",
      "Explained Variance: 0.010474205017089844\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 162\n",
      "Episodic Return: -5.564000129699707\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 300.98394775390625\n",
      "Policy Loss: -0.6051862239837646\n",
      "Old Approx KL: 0.006109816953539848\n",
      "Approx KL: 0.016168786212801933\n",
      "Clip Fraction: 0.29361263853617203\n",
      "Explained Variance: -0.006687045097351074\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 163\n",
      "Episodic Return: -3.8440001010894775\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 2058.0517578125\n",
      "Policy Loss: -59.915863037109375\n",
      "Old Approx KL: -0.10136790573596954\n",
      "Approx KL: 0.01833769679069519\n",
      "Clip Fraction: 0.41197344469718444\n",
      "Explained Variance: -0.012868523597717285\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 164\n",
      "Episodic Return: -6.016000270843506\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1971.317626953125\n",
      "Policy Loss: 24.730480194091797\n",
      "Old Approx KL: -0.014510112814605236\n",
      "Approx KL: 0.01043294183909893\n",
      "Clip Fraction: 0.37660256563088834\n",
      "Explained Variance: -0.0078887939453125\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 165\n",
      "Episodic Return: -5.604000091552734\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 4080.72998046875\n",
      "Policy Loss: 21.969409942626953\n",
      "Old Approx KL: 0.05118657276034355\n",
      "Approx KL: 0.008242079988121986\n",
      "Clip Fraction: 0.3735119054714839\n",
      "Explained Variance: -0.0030478239059448242\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 166\n",
      "Episodic Return: -4.4760003089904785\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 3443.34716796875\n",
      "Policy Loss: -82.56329345703125\n",
      "Old Approx KL: -0.15335705876350403\n",
      "Approx KL: 0.025114865973591805\n",
      "Clip Fraction: 0.42307692536940944\n",
      "Explained Variance: -0.010596752166748047\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 167\n",
      "Episodic Return: -8.624000549316406\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 18352.646484375\n",
      "Policy Loss: 154.6136932373047\n",
      "Old Approx KL: 0.19248606264591217\n",
      "Approx KL: 0.03492340072989464\n",
      "Clip Fraction: 0.6165293057759603\n",
      "Explained Variance: 0.006281733512878418\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 168\n",
      "Episodic Return: -5.38800048828125\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1883.6693115234375\n",
      "Policy Loss: 21.807994842529297\n",
      "Old Approx KL: 0.031000623479485512\n",
      "Approx KL: 0.012450972571969032\n",
      "Clip Fraction: 0.35485348105430603\n",
      "Explained Variance: 0.0019695162773132324\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 169\n",
      "Episodic Return: -5.7920002937316895\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 4737.3427734375\n",
      "Policy Loss: 12.312753677368164\n",
      "Old Approx KL: 0.12259230017662048\n",
      "Approx KL: 0.040881454944610596\n",
      "Clip Fraction: 0.3509615399898627\n",
      "Explained Variance: 0.007447481155395508\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 170\n",
      "Episodic Return: -4.519999980926514\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1969.9866943359375\n",
      "Policy Loss: -48.08595657348633\n",
      "Old Approx KL: -0.1016349345445633\n",
      "Approx KL: 0.016101714223623276\n",
      "Clip Fraction: 0.40064102716934985\n",
      "Explained Variance: -0.009988188743591309\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 171\n",
      "Episodic Return: -6.256000518798828\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 8949.3515625\n",
      "Policy Loss: 101.72305297851562\n",
      "Old Approx KL: 0.07454951852560043\n",
      "Approx KL: 0.04968617856502533\n",
      "Clip Fraction: 0.5145375468792059\n",
      "Explained Variance: -0.002509593963623047\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 172\n",
      "Episodic Return: -5.3520002365112305\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 2215.482421875\n",
      "Policy Loss: 1.1543972492218018\n",
      "Old Approx KL: -0.01755201816558838\n",
      "Approx KL: 0.005127979442477226\n",
      "Clip Fraction: 0.3836996345183788\n",
      "Explained Variance: -0.0014293193817138672\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 173\n",
      "Episodic Return: -5.180000305175781\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 770.0718994140625\n",
      "Policy Loss: 2.545877456665039\n",
      "Old Approx KL: 0.004358402453362942\n",
      "Approx KL: 0.007971866056323051\n",
      "Clip Fraction: 0.36515567852900577\n",
      "Explained Variance: -0.003935337066650391\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 174\n",
      "Episodic Return: -6.100000381469727\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 3819.27880859375\n",
      "Policy Loss: 47.74496078491211\n",
      "Old Approx KL: 0.10392690449953079\n",
      "Approx KL: 0.02250596135854721\n",
      "Clip Fraction: 0.4000686827378395\n",
      "Explained Variance: 0.015928447246551514\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 175\n",
      "Episodic Return: -4.872000217437744\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 8720.921875\n",
      "Policy Loss: -75.08590698242188\n",
      "Old Approx KL: -0.08830137550830841\n",
      "Approx KL: 0.07223483920097351\n",
      "Clip Fraction: 0.5499084270917453\n",
      "Explained Variance: -0.0013842582702636719\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 176\n",
      "Episodic Return: -3.620000123977661\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 7308.51318359375\n",
      "Policy Loss: -112.38497924804688\n",
      "Old Approx KL: -0.11627227813005447\n",
      "Approx KL: 0.028597407042980194\n",
      "Clip Fraction: 0.46256868350200164\n",
      "Explained Variance: -0.011405587196350098\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 177\n",
      "Episodic Return: -3.0360002517700195\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 6232.43994140625\n",
      "Policy Loss: -95.02732849121094\n",
      "Old Approx KL: -0.08384581655263901\n",
      "Approx KL: 0.0313655249774456\n",
      "Clip Fraction: 0.458791210101201\n",
      "Explained Variance: -0.01602637767791748\n",
      "\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training episode 178\n",
      "Episodic Return: -4.776000022888184\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1169.6859130859375\n",
      "Policy Loss: -28.396875381469727\n",
      "Old Approx KL: -0.005278230179101229\n",
      "Approx KL: 0.0036788457073271275\n",
      "Clip Fraction: 0.30689102716934985\n",
      "Explained Variance: -0.021791934967041016\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 179\n",
      "Episodic Return: -5.336000442504883\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 2120.249755859375\n",
      "Policy Loss: 51.92646408081055\n",
      "Old Approx KL: 0.060091692954301834\n",
      "Approx KL: 0.025374243035912514\n",
      "Clip Fraction: 0.2656822355511861\n",
      "Explained Variance: 0.03380537033081055\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 180\n",
      "Episodic Return: -3.8480002880096436\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 4841.841796875\n",
      "Policy Loss: -30.369577407836914\n",
      "Old Approx KL: 0.003857084782794118\n",
      "Approx KL: 0.035748984664678574\n",
      "Clip Fraction: 0.385416668959153\n",
      "Explained Variance: 0.0023258328437805176\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 181\n",
      "Episodic Return: -5.744000434875488\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 837.6551513671875\n",
      "Policy Loss: 28.67902183532715\n",
      "Old Approx KL: 0.07322627305984497\n",
      "Approx KL: 0.011662845499813557\n",
      "Clip Fraction: 0.2854853494045062\n",
      "Explained Variance: 0.02020883560180664\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 182\n",
      "Episodic Return: -4.332000255584717\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 2399.609375\n",
      "Policy Loss: -23.210371017456055\n",
      "Old Approx KL: -0.010680360719561577\n",
      "Approx KL: 0.01724965311586857\n",
      "Clip Fraction: 0.37591575124324894\n",
      "Explained Variance: -0.004067897796630859\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 183\n",
      "Episodic Return: -3.992000102996826\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 3078.007568359375\n",
      "Policy Loss: -62.143714904785156\n",
      "Old Approx KL: -0.06897910684347153\n",
      "Approx KL: 0.020409971475601196\n",
      "Clip Fraction: 0.39571886643385273\n",
      "Explained Variance: -0.01353609561920166\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 184\n",
      "Episodic Return: -4.880000114440918\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 975.8185424804688\n",
      "Policy Loss: 2.0205605030059814\n",
      "Old Approx KL: 0.08591203391551971\n",
      "Approx KL: 0.019702844321727753\n",
      "Clip Fraction: 0.2842261913495186\n",
      "Explained Variance: 0.0033942461013793945\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 185\n",
      "Episodic Return: -4.068000316619873\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 533.8045043945312\n",
      "Policy Loss: -29.08168601989746\n",
      "Old Approx KL: -0.09825312346220016\n",
      "Approx KL: 0.012228132225573063\n",
      "Clip Fraction: 0.29922161193994373\n",
      "Explained Variance: -0.005895256996154785\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 186\n",
      "Episodic Return: -5.272000312805176\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1997.8896484375\n",
      "Policy Loss: 20.693525314331055\n",
      "Old Approx KL: 0.11655393242835999\n",
      "Approx KL: 0.02419445849955082\n",
      "Clip Fraction: 0.3809523826990372\n",
      "Explained Variance: 0.0002865791320800781\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 187\n",
      "Episodic Return: -6.656000137329102\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 5028.9482421875\n",
      "Policy Loss: 83.43930053710938\n",
      "Old Approx KL: 0.2808455526828766\n",
      "Approx KL: 0.04873622581362724\n",
      "Clip Fraction: 0.5124771090654227\n",
      "Explained Variance: 0.00037938356399536133\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 188\n",
      "Episodic Return: -5.264000415802002\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 2557.969970703125\n",
      "Policy Loss: 2.153898000717163\n",
      "Old Approx KL: -0.0407286211848259\n",
      "Approx KL: 0.023904627189040184\n",
      "Clip Fraction: 0.3715659349392622\n",
      "Explained Variance: -0.007064461708068848\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 189\n",
      "Episodic Return: -3.9040002822875977\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1301.92431640625\n",
      "Policy Loss: -47.51858901977539\n",
      "Old Approx KL: -0.04709669575095177\n",
      "Approx KL: 0.004439179785549641\n",
      "Clip Fraction: 0.23145604458374855\n",
      "Explained Variance: -0.02469348907470703\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 190\n",
      "Episodic Return: -4.2920002937316895\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 866.4719848632812\n",
      "Policy Loss: -4.4415764808654785\n",
      "Old Approx KL: 0.048203613609075546\n",
      "Approx KL: 0.005822454579174519\n",
      "Clip Fraction: 0.3091804041312291\n",
      "Explained Variance: -0.005520224571228027\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 191\n",
      "Episodic Return: -4.9760003089904785\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1286.743896484375\n",
      "Policy Loss: -28.959001541137695\n",
      "Old Approx KL: -0.0077631049789488316\n",
      "Approx KL: 0.008404264226555824\n",
      "Clip Fraction: 0.3249771067729363\n",
      "Explained Variance: -0.010253071784973145\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 192\n",
      "Episodic Return: -3.4760000705718994\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1174.6077880859375\n",
      "Policy Loss: -40.25489807128906\n",
      "Old Approx KL: -0.0676293596625328\n",
      "Approx KL: 0.012366057373583317\n",
      "Clip Fraction: 0.3353937742037651\n",
      "Explained Variance: -0.0006477832794189453\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 193\n",
      "Episodic Return: -4.4760003089904785\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1573.9010009765625\n",
      "Policy Loss: -2.40386700630188\n",
      "Old Approx KL: 0.09653360396623611\n",
      "Approx KL: 0.024760344997048378\n",
      "Clip Fraction: 0.42525183390348387\n",
      "Explained Variance: 0.0019249320030212402\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 194\n",
      "Episodic Return: -5.75600004196167\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 2070.073974609375\n",
      "Policy Loss: 40.89824676513672\n",
      "Old Approx KL: 0.07511183619499207\n",
      "Approx KL: 0.034110743552446365\n",
      "Clip Fraction: 0.45821886643385273\n",
      "Explained Variance: -0.0033922195434570312\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 195\n",
      "Episodic Return: -4.656000137329102\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 676.7296752929688\n",
      "Policy Loss: 17.57808494567871\n",
      "Old Approx KL: 0.07983215153217316\n",
      "Approx KL: 0.009392542764544487\n",
      "Clip Fraction: 0.26568223516910505\n",
      "Explained Variance: 0.010885655879974365\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 196\n",
      "Episodic Return: -4.560000419616699\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 1751.944091796875\n",
      "Policy Loss: 7.622918605804443\n",
      "Old Approx KL: 0.03918018564581871\n",
      "Approx KL: 0.010761666111648083\n",
      "Clip Fraction: 0.3424908427091745\n",
      "Explained Variance: 0.00880134105682373\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 197\n",
      "Episodic Return: -6.448000431060791\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 3087.604248046875\n",
      "Policy Loss: 65.16151428222656\n",
      "Old Approx KL: 0.19591256976127625\n",
      "Approx KL: 0.047976214438676834\n",
      "Clip Fraction: 0.5462454236470736\n",
      "Explained Variance: 0.020954668521881104\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 198\n",
      "Episodic Return: -3.568000078201294\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 7552.1552734375\n",
      "Policy Loss: -119.02680969238281\n",
      "Old Approx KL: -0.16120801866054535\n",
      "Approx KL: 0.024546785280108452\n",
      "Clip Fraction: 0.5262133723650223\n",
      "Explained Variance: 0.005376338958740234\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Training episode 199\n",
      "Episodic Return: -4.776000022888184\n",
      "Episode Length: 199\n",
      "\n",
      "Value Loss: 3334.426025390625\n",
      "Policy Loss: -8.783522605895996\n",
      "Old Approx KL: -0.018320679664611816\n",
      "Approx KL: 0.050495583564043045\n",
      "Clip Fraction: 0.46943681515180147\n",
      "Explained Variance: 0.0016328096389770508\n",
      "\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\"\"\" RENDER THE POLICY \"\"\"\\n\\nenv = parallel.parallel_env(render_mode=\"human\",grid_size=7)\\n\\nagent.eval()\\n\\nwith torch.no_grad():\\n    # render 5 episodes out\\n    for episode in range(5):\\n        obs, infos = env.reset(seed=None)\\n        obs = batchify_obs(obs, device)\\n        terms = [False]\\n        truncs = [False]\\n        while not any(terms) and not any(truncs):\\n            # First agent uses trained policy\\n            first_agent_obs = obs[0].unsqueeze(0)\\n            actions, logprobs, _, values = agent.get_action_and_value(first_agent_obs)\\n\\n            # Other agents use random actions\\n            other_actions = torch.randint(0, num_actions, (num_agents-1,))\\n            full_actions = torch.cat([actions, other_actions])\\n\\n            obs, rewards, terms, truncs, infos = env.step(unbatchify(full_actions, env))\\n            obs = batchify_obs(obs, device)\\n            terms = [terms[a] for a in terms]\\n            truncs = [truncs[a] for a in truncs]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"ALGO PARAMS\"\"\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ent_coef = 0.1\n",
    "vf_coef = 0.1\n",
    "clip_coef = 0.1\n",
    "gamma = 0.99\n",
    "batch_size = 32\n",
    "stack_size = 4\n",
    "frame_size = (64, 64)\n",
    "max_cycles = 250\n",
    "total_episodes = 200\n",
    "\n",
    "\"\"\" ENV SETUP \"\"\"\n",
    "env = parallel.parallel_env(grid_size=7)\n",
    "\n",
    "num_agents = len(env.possible_agents)\n",
    "num_actions = env.action_space(env.possible_agents[0]).n\n",
    "observation_size = env.observation_space(env.possible_agents[0]).shape\n",
    "\n",
    "\"\"\" LEARNER SETUP \"\"\"\n",
    "agent = Super_Agent(num_actions=num_actions, num_agents=2).to(device)\n",
    "optimizer = optim.Adam(agent.parameters(), lr=0.001, eps=1e-5)\n",
    "\n",
    "\"\"\" ALGO LOGIC: EPISODE STORAGE\"\"\"\n",
    "end_step = 0\n",
    "total_episodic_return = 0\n",
    "rb_obs = torch.zeros((max_cycles, num_agents, 5,7,7)).to(device)\n",
    "rb_actions = torch.zeros((max_cycles, num_agents)).to(device)\n",
    "rb_logprobs = torch.zeros((max_cycles, num_agents)).to(device)\n",
    "rb_rewards = torch.zeros((max_cycles, num_agents)).to(device)\n",
    "rb_terms = torch.zeros((max_cycles, num_agents)).to(device)\n",
    "rb_values = torch.zeros((max_cycles, num_agents)).to(device)\n",
    "\n",
    "\"\"\" TRAINING LOGIC \"\"\"\n",
    "# train for n number of episodes\n",
    "for episode in range(total_episodes):\n",
    "    # collect an episode\n",
    "    with torch.no_grad():\n",
    "        # collect observations and convert to batch of torch tensors\n",
    "        next_obs, info = env.reset(seed=None)\n",
    "        # reset the episodic return\n",
    "        total_episodic_return = 0\n",
    "\n",
    "        # each episode has num_steps\n",
    "        for step in range(0, max_cycles):\n",
    "            # rollover the observation\n",
    "            obs = batchify_obs(next_obs, device)\n",
    "            # get action for first agent from the trained agent\n",
    "            # get random actions for other agents\n",
    "            actions = torch.zeros(num_agents, dtype=torch.long).to(device)\n",
    "            logprobs = torch.zeros(num_agents).to(device)\n",
    "            values = torch.zeros(num_agents).to(device)\n",
    "                \n",
    "            for i in range(2):\n",
    "                # First agent uses policy network\n",
    "                first_agent = env.possible_agents[i]\n",
    "                first_agent_obs = obs[i].unsqueeze(0)\n",
    "                actions[i], logprobs[i], _, values[i] = agent.get_action_and_value(first_agent_obs)\n",
    "\n",
    "            # Other agents use random policy\n",
    "            for i in range(2, num_agents):\n",
    "                actions[i] = torch.randint(0, num_actions, (1,)).to(device)\n",
    "                logprobs[i] = torch.log(torch.tensor(1.0/num_actions))\n",
    "                values[i] = 0.0  # No value estimation for random agents\n",
    "\n",
    "            # execute the environment and log data\n",
    "            next_obs, rewards, terms, truncs, infos = env.step(\n",
    "                unbatchify(actions, env)\n",
    "            )\n",
    "\n",
    "            # add to episode storage\n",
    "            rb_obs[step] = obs\n",
    "            rb_rewards[step] = batchify(rewards, device)\n",
    "            rb_terms[step] = batchify(terms, device)\n",
    "            rb_actions[step] = actions\n",
    "            rb_logprobs[step] = logprobs\n",
    "            rb_values[step] = values\n",
    "\n",
    "            # compute episodic return\n",
    "            total_episodic_return += rb_rewards[step].cpu().numpy()\n",
    "\n",
    "            # if we reach termination or truncation, end\n",
    "            if any([terms[a] for a in terms]) or any([truncs[a] for a in truncs]):\n",
    "                end_step = step\n",
    "                break\n",
    "\n",
    "    # Bootstrap value and advantages only for the first agent\n",
    "    with torch.no_grad():\n",
    "        rb_advantages = torch.zeros_like(rb_rewards).to(device)\n",
    "        for t in reversed(range(end_step)):\n",
    "            for i in range(2):\n",
    "                delta = (\n",
    "                    rb_rewards[t, i]  # Only first agent's reward\n",
    "                    + gamma * rb_values[t + 1, i] * rb_terms[t + 1, i]\n",
    "                    - rb_values[t, i]\n",
    "                )\n",
    "                rb_advantages[t, i] = delta + gamma * gamma * rb_advantages[t + 1, i]\n",
    "        rb_returns = rb_advantages + rb_values\n",
    "\n",
    "    # convert our episodes to batch of individual transitions (only for first agent)\n",
    "    b_obs = torch.cat([rb_obs[:end_step, 0], rb_obs[:end_step, 1]], dim=0)\n",
    "    b_logprobs = torch.cat([rb_logprobs[:end_step, 0], rb_logprobs[:end_step, 1]], dim=0)\n",
    "    b_actions = torch.cat([rb_actions[:end_step, 0], rb_actions[:end_step, 1]], dim=0)\n",
    "    b_returns = torch.cat([rb_returns[:end_step, 0], rb_returns[:end_step, 1]], dim=0)\n",
    "    b_values = torch.cat([rb_values[:end_step, 0], rb_values[:end_step, 1]], dim=0)\n",
    "    b_advantages = torch.cat([rb_advantages[:end_step, 0], rb_advantages[:end_step, 1]], dim=0)\n",
    "\n",
    "    # Optimizing the policy and value network\n",
    "    b_index = np.arange(len(b_obs))\n",
    "    clip_fracs = []\n",
    "    for repeat in range(3):\n",
    "        # shuffle the indices we use to access the data\n",
    "        np.random.shuffle(b_index)\n",
    "        for start in range(0, len(b_obs), batch_size):\n",
    "            # select the indices we want to train on\n",
    "            end = start + batch_size\n",
    "            batch_index = b_index[start:end]\n",
    "\n",
    "            _, newlogprob, entropy, value = agent.get_action_and_value(\n",
    "                b_obs[batch_index], b_actions.long()[batch_index]\n",
    "            )\n",
    "            logratio = newlogprob - b_logprobs[batch_index]\n",
    "            ratio = logratio.exp()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # calculate approx_kl http://joschu.net/blog/kl-approx.html\n",
    "                old_approx_kl = (-logratio).mean()\n",
    "                approx_kl = ((ratio - 1) - logratio).mean()\n",
    "                clip_fracs += [\n",
    "                    ((ratio - 1.0).abs() > clip_coef).float().mean().item()\n",
    "                ]\n",
    "\n",
    "            # normalize advantages\n",
    "            advantages = b_advantages[batch_index]\n",
    "            advantages = (advantages - advantages.mean()) / (\n",
    "                advantages.std() + 1e-8\n",
    "            )\n",
    "\n",
    "            # Policy loss\n",
    "            pg_loss1 = -b_advantages[batch_index] * ratio\n",
    "            pg_loss2 = -b_advantages[batch_index] * torch.clamp(\n",
    "                ratio, 1 - clip_coef, 1 + clip_coef\n",
    "            )\n",
    "            pg_loss = torch.max(pg_loss1, pg_loss2).mean()\n",
    "\n",
    "            # Value loss\n",
    "            value = value.flatten()\n",
    "            v_loss_unclipped = (value - b_returns[batch_index]) ** 2\n",
    "            v_clipped = b_values[batch_index] + torch.clamp(\n",
    "                value - b_values[batch_index],\n",
    "                -clip_coef,\n",
    "                clip_coef,\n",
    "            )\n",
    "            v_loss_clipped = (v_clipped - b_returns[batch_index]) ** 2\n",
    "            v_loss_max = torch.max(v_loss_unclipped, v_loss_clipped)\n",
    "            v_loss = 0.5 * v_loss_max.mean()\n",
    "\n",
    "            entropy_loss = entropy.mean()\n",
    "            loss = pg_loss - ent_coef * entropy_loss + v_loss * vf_coef\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    y_pred, y_true = b_values.cpu().numpy(), b_returns.cpu().numpy()\n",
    "    var_y = np.var(y_true)\n",
    "    explained_var = np.nan if var_y == 0 else 1 - np.var(y_true - y_pred) / var_y\n",
    "\n",
    "    print(f\"Training episode {episode}\")\n",
    "    print(f\"Episodic Return: {rb_rewards[:, 0].mean().item()}\")\n",
    "    print(f\"Episode Length: {end_step}\")\n",
    "    print(\"\")\n",
    "    print(f\"Value Loss: {v_loss.item()}\")\n",
    "    print(f\"Policy Loss: {pg_loss.item()}\")\n",
    "    print(f\"Old Approx KL: {old_approx_kl.item()}\")\n",
    "    print(f\"Approx KL: {approx_kl.item()}\")\n",
    "    print(f\"Clip Fraction: {np.mean(clip_fracs)}\")\n",
    "    print(f\"Explained Variance: {explained_var.item()}\")\n",
    "    print(\"\\n-------------------------------------------\\n\")\n",
    "'''\n",
    "\"\"\" RENDER THE POLICY \"\"\"\n",
    "\n",
    "env = parallel.parallel_env(render_mode=\"human\",grid_size=7)\n",
    "\n",
    "agent.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # render 5 episodes out\n",
    "    for episode in range(5):\n",
    "        obs, infos = env.reset(seed=None)\n",
    "        obs = batchify_obs(obs, device)\n",
    "        terms = [False]\n",
    "        truncs = [False]\n",
    "        while not any(terms) and not any(truncs):\n",
    "            # First agent uses trained policy\n",
    "            first_agent_obs = obs[0].unsqueeze(0)\n",
    "            actions, logprobs, _, values = agent.get_action_and_value(first_agent_obs)\n",
    "\n",
    "            # Other agents use random actions\n",
    "            other_actions = torch.randint(0, num_actions, (num_agents-1,))\n",
    "            full_actions = torch.cat([actions, other_actions])\n",
    "\n",
    "            obs, rewards, terms, truncs, infos = env.step(unbatchify(full_actions, env))\n",
    "            obs = batchify_obs(obs, device)\n",
    "            terms = [terms[a] for a in terms]\n",
    "            truncs = [truncs[a] for a in truncs]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9811a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c8ea2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DRL project env",
   "language": "python",
   "name": "drl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
